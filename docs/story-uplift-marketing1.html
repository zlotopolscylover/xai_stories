<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Story Uplift Modeling: eXplainable predictions for optimized marketing campaigns | XAI Stories</title>
  <meta name="description" content="Case studies for eXplainable Artificial Intelligence" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Story Uplift Modeling: eXplainable predictions for optimized marketing campaigns | XAI Stories" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="images/cover.png" />
  <meta property="og:description" content="Case studies for eXplainable Artificial Intelligence" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Story Uplift Modeling: eXplainable predictions for optimized marketing campaigns | XAI Stories" />
  
  <meta name="twitter:description" content="Case studies for eXplainable Artificial Intelligence" />
  <meta name="twitter:image" content="images/cover.png" />



<meta name="date" content="2020-10-14" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="story-uplift-modelling.html"/>
<link rel="next" href="story-meps-explainable-predictions-for-healthcare-expenditures.html"/>
<script src="libs/header-attrs/header-attrs.js"></script>
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"><h3>XAI Stories</h3> Case studies</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="" data-path="foreword.html"><a href="foreword.html"><i class="fa fa-check"></i>Foreword</a>
<ul>
<li class="chapter" data-level="0.1" data-path="foreword.html"><a href="foreword.html#why"><i class="fa fa-check"></i><b>0.1</b> Why?</a></li>
<li class="chapter" data-level="0.2" data-path="foreword.html"><a href="foreword.html#what"><i class="fa fa-check"></i><b>0.2</b> What?</a></li>
<li class="chapter" data-level="0.3" data-path="foreword.html"><a href="foreword.html#how"><i class="fa fa-check"></i><b>0.3</b> How?</a></li>
<li class="chapter" data-level="0.4" data-path="foreword.html"><a href="foreword.html#about-academic-partners"><i class="fa fa-check"></i><b>0.4</b> About academic partners</a></li>
<li class="chapter" data-level="0.5" data-path="foreword.html"><a href="foreword.html#about-business-partner"><i class="fa fa-check"></i><b>0.5</b> About business partner</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="story-house-sale-prices.html"><a href="story-house-sale-prices.html"><i class="fa fa-check"></i><b>1</b> Story House Sale Prices: eXplainable predictions for house sale</a>
<ul>
<li class="chapter" data-level="" data-path="story-house-sale-prices.html"><a href="story-house-sale-prices.html#take-away-messages"><i class="fa fa-check"></i>Take-away messages</a></li>
<li class="chapter" data-level="1.1" data-path="story-house-sale-prices.html"><a href="story-house-sale-prices.html#introduction"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="story-house-sale-prices.html"><a href="story-house-sale-prices.html#data"><i class="fa fa-check"></i><b>1.2</b> Data</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="story-house-sale-prices.html"><a href="story-house-sale-prices.html#data-preperation"><i class="fa fa-check"></i><b>1.2.1</b> Data preperation</a></li>
<li class="chapter" data-level="1.2.2" data-path="story-house-sale-prices.html"><a href="story-house-sale-prices.html#external-data"><i class="fa fa-check"></i><b>1.2.2</b> External data</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="story-house-sale-prices.html"><a href="story-house-sale-prices.html#model"><i class="fa fa-check"></i><b>1.3</b> Model</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="story-house-sale-prices.html"><a href="story-house-sale-prices.html#linear-models"><i class="fa fa-check"></i><b>1.3.1</b> Linear models</a></li>
<li class="chapter" data-level="1.3.2" data-path="story-house-sale-prices.html"><a href="story-house-sale-prices.html#linear-models-assessment"><i class="fa fa-check"></i><b>1.3.2</b> Linear models assessment</a></li>
<li class="chapter" data-level="1.3.3" data-path="story-house-sale-prices.html"><a href="story-house-sale-prices.html#machine-learning-models"><i class="fa fa-check"></i><b>1.3.3</b> Machine Learning models</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="story-house-sale-prices.html"><a href="story-house-sale-prices.html#explanations"><i class="fa fa-check"></i><b>1.4</b> Explanations</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="story-house-sale-prices.html"><a href="story-house-sale-prices.html#xai-for-geographical-location"><i class="fa fa-check"></i><b>1.4.1</b> XAI for geographical location</a></li>
<li class="chapter" data-level="1.4.2" data-path="story-house-sale-prices.html"><a href="story-house-sale-prices.html#feature-importance"><i class="fa fa-check"></i><b>1.4.2</b> Feature importance</a></li>
<li class="chapter" data-level="1.4.3" data-path="story-house-sale-prices.html"><a href="story-house-sale-prices.html#partial-dependence-plots-pdp"><i class="fa fa-check"></i><b>1.4.3</b> Partial Dependence Plots (PDP)</a></li>
<li class="chapter" data-level="1.4.4" data-path="story-house-sale-prices.html"><a href="story-house-sale-prices.html#new-possibilities-with-pdp"><i class="fa fa-check"></i><b>1.4.4</b> New possibilities with PDP</a></li>
<li class="chapter" data-level="1.4.5" data-path="story-house-sale-prices.html"><a href="story-house-sale-prices.html#instance-level-explanations."><i class="fa fa-check"></i><b>1.4.5</b> Instance level explanations.</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="story-house-sale-prices.html"><a href="story-house-sale-prices.html#use-case-of-the-model"><i class="fa fa-check"></i><b>1.5</b> Use case of the model</a></li>
<li class="chapter" data-level="1.6" data-path="story-house-sale-prices.html"><a href="story-house-sale-prices.html#summary-and-conclusions"><i class="fa fa-check"></i><b>1.6</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="story-hotel-booking.html"><a href="story-hotel-booking.html"><i class="fa fa-check"></i><b>2</b> Story Hotel Booking: eXplainable predictions of booking cancellation and guests coming back</a>
<ul>
<li class="chapter" data-level="2.1" data-path="story-hotel-booking.html"><a href="story-hotel-booking.html#introduction-1"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="story-hotel-booking.html"><a href="story-hotel-booking.html#booking-cancellation"><i class="fa fa-check"></i><b>2.2</b> Booking Cancellation</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="story-hotel-booking.html"><a href="story-hotel-booking.html#booking-cancellation-model"><i class="fa fa-check"></i><b>2.2.1</b> Booking Cancellation: Model</a></li>
<li class="chapter" data-level="2.2.2" data-path="story-hotel-booking.html"><a href="story-hotel-booking.html#booking-cancellation-explanation-dataset-level"><i class="fa fa-check"></i><b>2.2.2</b> Booking Cancellation: Explanation, dataset level</a></li>
<li class="chapter" data-level="2.2.3" data-path="story-hotel-booking.html"><a href="story-hotel-booking.html#booking-cancellation-explanations-instance-level"><i class="fa fa-check"></i><b>2.2.3</b> Booking Cancellation: Explanations, instance level</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="story-hotel-booking.html"><a href="story-hotel-booking.html#repeated-guests"><i class="fa fa-check"></i><b>2.3</b> Repeated guests</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="story-hotel-booking.html"><a href="story-hotel-booking.html#repeated-guests-imbalanced-dataset"><i class="fa fa-check"></i><b>2.3.1</b> Repeated guests: Imbalanced dataset</a></li>
<li class="chapter" data-level="2.3.2" data-path="story-hotel-booking.html"><a href="story-hotel-booking.html#repeated-guests-model"><i class="fa fa-check"></i><b>2.3.2</b> Repeated guests: Model</a></li>
<li class="chapter" data-level="2.3.3" data-path="story-hotel-booking.html"><a href="story-hotel-booking.html#repeated-guests-explanations-instance-level"><i class="fa fa-check"></i><b>2.3.3</b> Repeated guests: Explanations, instance level</a></li>
<li class="chapter" data-level="2.3.4" data-path="story-hotel-booking.html"><a href="story-hotel-booking.html#repeated-guests-explanations-dataset-level"><i class="fa fa-check"></i><b>2.3.4</b> Repeated guests: Explanations, dataset level</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="story-hotel-booking.html"><a href="story-hotel-booking.html#summary-and-conclusions-1"><i class="fa fa-check"></i><b>2.4</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="story-hotel-booking-cancellations-explainable-predictions-for-booking-cancellation.html"><a href="story-hotel-booking-cancellations-explainable-predictions-for-booking-cancellation.html"><i class="fa fa-check"></i><b>3</b> Story Hotel Booking Cancellations: eXplainable predictions for booking cancellation</a>
<ul>
<li class="chapter" data-level="3.1" data-path="story-hotel-booking-cancellations-explainable-predictions-for-booking-cancellation.html"><a href="story-hotel-booking-cancellations-explainable-predictions-for-booking-cancellation.html#introduction-2"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="story-hotel-booking-cancellations-explainable-predictions-for-booking-cancellation.html"><a href="story-hotel-booking-cancellations-explainable-predictions-for-booking-cancellation.html#problem-specification"><i class="fa fa-check"></i><b>3.2</b> Problem specification</a></li>
<li class="chapter" data-level="3.3" data-path="story-hotel-booking-cancellations-explainable-predictions-for-booking-cancellation.html"><a href="story-hotel-booking-cancellations-explainable-predictions-for-booking-cancellation.html#target-leak-detection"><i class="fa fa-check"></i><b>3.3</b> Target leak detection</a></li>
<li class="chapter" data-level="3.4" data-path="story-hotel-booking-cancellations-explainable-predictions-for-booking-cancellation.html"><a href="story-hotel-booking-cancellations-explainable-predictions-for-booking-cancellation.html#bias-correction"><i class="fa fa-check"></i><b>3.4</b> Bias correction</a></li>
<li class="chapter" data-level="3.5" data-path="story-hotel-booking-cancellations-explainable-predictions-for-booking-cancellation.html"><a href="story-hotel-booking-cancellations-explainable-predictions-for-booking-cancellation.html#offering-different-conditions"><i class="fa fa-check"></i><b>3.5</b> Offering different conditions</a></li>
<li class="chapter" data-level="3.6" data-path="story-hotel-booking-cancellations-explainable-predictions-for-booking-cancellation.html"><a href="story-hotel-booking-cancellations-explainable-predictions-for-booking-cancellation.html#conclusions"><i class="fa fa-check"></i><b>3.6</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="story-uplift-modelling.html"><a href="story-uplift-modelling.html"><i class="fa fa-check"></i><b>4</b> Story Uplift Modelling: eXplaining colon cancer survival rate after treatment</a>
<ul>
<li class="chapter" data-level="4.1" data-path="story-uplift-modelling.html"><a href="story-uplift-modelling.html#introduction-3"><i class="fa fa-check"></i><b>4.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="story-uplift-modelling.html"><a href="story-uplift-modelling.html#what-is-uplift-modelling"><i class="fa fa-check"></i><b>4.1.1</b> What is Uplift Modelling?</a></li>
<li class="chapter" data-level="4.1.2" data-path="story-uplift-modelling.html"><a href="story-uplift-modelling.html#dataset-description"><i class="fa fa-check"></i><b>4.1.2</b> Dataset Description</a></li>
<li class="chapter" data-level="4.1.3" data-path="story-uplift-modelling.html"><a href="story-uplift-modelling.html#ideas"><i class="fa fa-check"></i><b>4.1.3</b> Ideas</a></li>
<li class="chapter" data-level="4.1.4" data-path="story-uplift-modelling.html"><a href="story-uplift-modelling.html#why-is-it-worth-the-hassle"><i class="fa fa-check"></i><b>4.1.4</b> Why is it worth the hassle?</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="story-uplift-modelling.html"><a href="story-uplift-modelling.html#data-preprocessing"><i class="fa fa-check"></i><b>4.2</b> Data Preprocessing</a></li>
<li class="chapter" data-level="4.3" data-path="story-uplift-modelling.html"><a href="story-uplift-modelling.html#model-1"><i class="fa fa-check"></i><b>4.3</b> Model</a></li>
<li class="chapter" data-level="4.4" data-path="story-uplift-modelling.html"><a href="story-uplift-modelling.html#explanations-1"><i class="fa fa-check"></i><b>4.4</b> Explanations</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="story-uplift-modelling.html"><a href="story-uplift-modelling.html#feature-importance-1"><i class="fa fa-check"></i><b>4.4.1</b> Feature Importance</a></li>
<li class="chapter" data-level="4.4.2" data-path="story-uplift-modelling.html"><a href="story-uplift-modelling.html#ceteris-paribus-and-partial-dependence-profiles"><i class="fa fa-check"></i><b>4.4.2</b> Ceteris Paribus and Partial Dependence Profiles</a></li>
<li class="chapter" data-level="4.4.3" data-path="story-uplift-modelling.html"><a href="story-uplift-modelling.html#instance-level-explainations"><i class="fa fa-check"></i><b>4.4.3</b> Instance Level Explainations</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="story-uplift-modelling.html"><a href="story-uplift-modelling.html#summary-and-conclusions-2"><i class="fa fa-check"></i><b>4.5</b> Summary and Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="story-uplift-marketing1.html"><a href="story-uplift-marketing1.html"><i class="fa fa-check"></i><b>5</b> Story Uplift Modeling: eXplainable predictions for optimized marketing campaigns</a>
<ul>
<li class="chapter" data-level="5.1" data-path="story-uplift-marketing1.html"><a href="story-uplift-marketing1.html#introduction-4"><i class="fa fa-check"></i><b>5.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="story-uplift-marketing1.html"><a href="story-uplift-marketing1.html#approaches-towards-uplift-modeling"><i class="fa fa-check"></i><b>5.1.1</b> Approaches towards uplift modeling</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="story-uplift-marketing1.html"><a href="story-uplift-marketing1.html#dataset"><i class="fa fa-check"></i><b>5.2</b> Dataset</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="story-uplift-marketing1.html"><a href="story-uplift-marketing1.html#explanatory-data-analysis"><i class="fa fa-check"></i><b>5.2.1</b> Explanatory Data Analysis</a></li>
<li class="chapter" data-level="5.2.2" data-path="story-uplift-marketing1.html"><a href="story-uplift-marketing1.html#feature-engineering"><i class="fa fa-check"></i><b>5.2.2</b> Feature engineering</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="story-uplift-marketing1.html"><a href="story-uplift-marketing1.html#model-exploration-and-metrics"><i class="fa fa-check"></i><b>5.3</b> Model exploration and metrics</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="story-uplift-marketing1.html"><a href="story-uplift-marketing1.html#model-2"><i class="fa fa-check"></i><b>5.3.1</b> Model</a></li>
<li class="chapter" data-level="5.3.2" data-path="story-uplift-marketing1.html"><a href="story-uplift-marketing1.html#comparing-metrics"><i class="fa fa-check"></i><b>5.3.2</b> Comparing metrics</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="story-uplift-marketing1.html"><a href="story-uplift-marketing1.html#explanations-2"><i class="fa fa-check"></i><b>5.4</b> Explanations</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="story-uplift-marketing1.html"><a href="story-uplift-marketing1.html#instance-level"><i class="fa fa-check"></i><b>5.4.1</b> Instance-level</a></li>
<li class="chapter" data-level="5.4.2" data-path="story-uplift-marketing1.html"><a href="story-uplift-marketing1.html#difference---approach"><i class="fa fa-check"></i><b>5.4.2</b> Difference - approach</a></li>
<li class="chapter" data-level="5.4.3" data-path="story-uplift-marketing1.html"><a href="story-uplift-marketing1.html#dataset--subset--level"><i class="fa fa-check"></i><b>5.4.3</b> Dataset- (subset-) level</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="story-uplift-marketing1.html"><a href="story-uplift-marketing1.html#conclusions-1"><i class="fa fa-check"></i><b>5.5</b> Conclusions</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="story-uplift-marketing1.html"><a href="story-uplift-marketing1.html#sweet-spot"><i class="fa fa-check"></i><b>5.5.1</b> Sweet-spot</a></li>
<li class="chapter" data-level="5.5.2" data-path="story-uplift-marketing1.html"><a href="story-uplift-marketing1.html#bigger-influence"><i class="fa fa-check"></i><b>5.5.2</b> Bigger influence</a></li>
<li class="chapter" data-level="5.5.3" data-path="story-uplift-marketing1.html"><a href="story-uplift-marketing1.html#influence-from-other-factors"><i class="fa fa-check"></i><b>5.5.3</b> Influence from other factors</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="story-uplift-marketing1.html"><a href="story-uplift-marketing1.html#summary"><i class="fa fa-check"></i><b>5.6</b> Summary</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="story-uplift-marketing1.html"><a href="story-uplift-marketing1.html#individual-perspective"><i class="fa fa-check"></i><b>5.6.1</b> Individual perspective</a></li>
<li class="chapter" data-level="5.6.2" data-path="story-uplift-marketing1.html"><a href="story-uplift-marketing1.html#data-scientists-perspective"><i class="fa fa-check"></i><b>5.6.2</b> Data scientist’s perspective</a></li>
<li class="chapter" data-level="5.6.3" data-path="story-uplift-marketing1.html"><a href="story-uplift-marketing1.html#executive-perspective"><i class="fa fa-check"></i><b>5.6.3</b> Executive perspective</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="story-uplift-marketing1.html"><a href="story-uplift-marketing1.html#future-works"><i class="fa fa-check"></i><b>5.7</b> Future works</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="story-meps-explainable-predictions-for-healthcare-expenditures.html"><a href="story-meps-explainable-predictions-for-healthcare-expenditures.html"><i class="fa fa-check"></i><b>6</b> Story MEPS: Explainable predictions for healthcare expenditures</a>
<ul>
<li class="chapter" data-level="6.1" data-path="story-meps-explainable-predictions-for-healthcare-expenditures.html"><a href="story-meps-explainable-predictions-for-healthcare-expenditures.html#introduction-5"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="story-meps-explainable-predictions-for-healthcare-expenditures.html"><a href="story-meps-explainable-predictions-for-healthcare-expenditures.html#model-3"><i class="fa fa-check"></i><b>6.2</b> Model</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="story-meps-explainable-predictions-for-healthcare-expenditures.html"><a href="story-meps-explainable-predictions-for-healthcare-expenditures.html#data-1"><i class="fa fa-check"></i><b>6.2.1</b> Data</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="story-meps-explainable-predictions-for-healthcare-expenditures.html"><a href="story-meps-explainable-predictions-for-healthcare-expenditures.html#model-4"><i class="fa fa-check"></i><b>6.3</b> Model</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="story-meps-explainable-predictions-for-healthcare-expenditures.html"><a href="story-meps-explainable-predictions-for-healthcare-expenditures.html#data-2"><i class="fa fa-check"></i><b>6.3.1</b> Data</a></li>
<li class="chapter" data-level="6.3.2" data-path="story-meps-explainable-predictions-for-healthcare-expenditures.html"><a href="story-meps-explainable-predictions-for-healthcare-expenditures.html#model-5"><i class="fa fa-check"></i><b>6.3.2</b> Model</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="story-meps-explainable-predictions-for-healthcare-expenditures.html"><a href="story-meps-explainable-predictions-for-healthcare-expenditures.html#model-level-explainations"><i class="fa fa-check"></i><b>6.4</b> Model Level Explainations</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="story-meps-explainable-predictions-for-healthcare-expenditures.html"><a href="story-meps-explainable-predictions-for-healthcare-expenditures.html#permutation-variable-importances"><i class="fa fa-check"></i><b>6.4.1</b> Permutation Variable Importances</a></li>
<li class="chapter" data-level="6.4.2" data-path="story-meps-explainable-predictions-for-healthcare-expenditures.html"><a href="story-meps-explainable-predictions-for-healthcare-expenditures.html#partial-dependence-profiles"><i class="fa fa-check"></i><b>6.4.2</b> Partial Dependence Profiles</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="story-meps-explainable-predictions-for-healthcare-expenditures.html"><a href="story-meps-explainable-predictions-for-healthcare-expenditures.html#instance-level-explanations"><i class="fa fa-check"></i><b>6.5</b> Instance Level Explanations</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="story-meps-explainable-predictions-for-healthcare-expenditures.html"><a href="story-meps-explainable-predictions-for-healthcare-expenditures.html#business-approach"><i class="fa fa-check"></i><b>6.5.1</b> Business approach</a></li>
<li class="chapter" data-level="6.5.2" data-path="story-meps-explainable-predictions-for-healthcare-expenditures.html"><a href="story-meps-explainable-predictions-for-healthcare-expenditures.html#instance-level-explanations---instance-specific-approach"><i class="fa fa-check"></i><b>6.5.2</b> Instance Level Explanations - instance specific approach</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="story-meps-explainable-predictions-for-healthcare-expenditures.html"><a href="story-meps-explainable-predictions-for-healthcare-expenditures.html#summary-and-conclusions-3"><i class="fa fa-check"></i><b>6.6</b> Summary and conclusions</a></li>
<li class="chapter" data-level="6.7" data-path="story-meps-explainable-predictions-for-healthcare-expenditures.html"><a href="story-meps-explainable-predictions-for-healthcare-expenditures.html#references"><i class="fa fa-check"></i><b>6.7</b> References</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="story-meps-healthcare-expenditures-of-individuals.html"><a href="story-meps-healthcare-expenditures-of-individuals.html"><i class="fa fa-check"></i><b>7</b> Story MEPS: Healthcare expenditures of individuals</a>
<ul>
<li class="chapter" data-level="7.1" data-path="story-meps-healthcare-expenditures-of-individuals.html"><a href="story-meps-healthcare-expenditures-of-individuals.html#introduction-6"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="story-meps-healthcare-expenditures-of-individuals.html"><a href="story-meps-healthcare-expenditures-of-individuals.html#data-set"><i class="fa fa-check"></i><b>7.2</b> Data set</a></li>
<li class="chapter" data-level="7.3" data-path="story-meps-healthcare-expenditures-of-individuals.html"><a href="story-meps-healthcare-expenditures-of-individuals.html#models"><i class="fa fa-check"></i><b>7.3</b> Models</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="story-meps-healthcare-expenditures-of-individuals.html"><a href="story-meps-healthcare-expenditures-of-individuals.html#model-1-ridge-regression"><i class="fa fa-check"></i><b>7.3.1</b> Model 1: Ridge regression</a></li>
<li class="chapter" data-level="7.3.2" data-path="story-meps-healthcare-expenditures-of-individuals.html"><a href="story-meps-healthcare-expenditures-of-individuals.html#model-2-artificial-neural-network"><i class="fa fa-check"></i><b>7.3.2</b> Model 2: Artificial Neural Network</a></li>
<li class="chapter" data-level="7.3.3" data-path="story-meps-healthcare-expenditures-of-individuals.html"><a href="story-meps-healthcare-expenditures-of-individuals.html#model-3-gradient-boosting"><i class="fa fa-check"></i><b>7.3.3</b> Model 3: Gradient Boosting</a></li>
<li class="chapter" data-level="7.3.4" data-path="story-meps-healthcare-expenditures-of-individuals.html"><a href="story-meps-healthcare-expenditures-of-individuals.html#results"><i class="fa fa-check"></i><b>7.3.4</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="story-meps-healthcare-expenditures-of-individuals.html"><a href="story-meps-healthcare-expenditures-of-individuals.html#analysis-with-xai-methods"><i class="fa fa-check"></i><b>7.4</b> Analysis with XAI methods</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="story-meps-healthcare-expenditures-of-individuals.html"><a href="story-meps-healthcare-expenditures-of-individuals.html#analysis-of-patients-with-zero-expenditures"><i class="fa fa-check"></i><b>7.4.1</b> Analysis of patients with zero expenditures</a></li>
<li class="chapter" data-level="7.4.2" data-path="story-meps-healthcare-expenditures-of-individuals.html"><a href="story-meps-healthcare-expenditures-of-individuals.html#interpretation-of-self-reported-health-status-and-survey-questions-design"><i class="fa fa-check"></i><b>7.4.2</b> Interpretation of self-reported health status and survey questions design</a></li>
<li class="chapter" data-level="7.4.3" data-path="story-meps-healthcare-expenditures-of-individuals.html"><a href="story-meps-healthcare-expenditures-of-individuals.html#the-relationship-between-age-and-health-expenditure"><i class="fa fa-check"></i><b>7.4.3</b> The relationship between age and health expenditure</a></li>
<li class="chapter" data-level="7.4.4" data-path="story-meps-healthcare-expenditures-of-individuals.html"><a href="story-meps-healthcare-expenditures-of-individuals.html#using-shap-for-encoding-and-grouping-of-categorical-variables"><i class="fa fa-check"></i><b>7.4.4</b> Using SHAP for encoding and grouping of categorical variables</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="story-meps-healthcare-expenditures-of-individuals.html"><a href="story-meps-healthcare-expenditures-of-individuals.html#conclusion"><i class="fa fa-check"></i><b>7.5</b> Conclusion</a></li>
<li class="chapter" data-level="7.6" data-path="story-meps-healthcare-expenditures-of-individuals.html"><a href="story-meps-healthcare-expenditures-of-individuals.html#appendix"><i class="fa fa-check"></i><b>7.6</b> Appendix</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="story-meps-healthcare-expenditures-of-individuals.html"><a href="story-meps-healthcare-expenditures-of-individuals.html#additionall-plots"><i class="fa fa-check"></i><b>7.6.1</b> Additionall plots</a></li>
<li class="chapter" data-level="7.6.2" data-path="story-meps-healthcare-expenditures-of-individuals.html"><a href="story-meps-healthcare-expenditures-of-individuals.html#variables-descriptions"><i class="fa fa-check"></i><b>7.6.2</b> Variables descriptions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="story-lungs.html"><a href="story-lungs.html"><i class="fa fa-check"></i><b>8</b> Story Lungs: eXplainable predictions for post operational risks</a>
<ul>
<li class="chapter" data-level="8.1" data-path="story-lungs.html"><a href="story-lungs.html#introduction-7"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="story-lungs.html"><a href="story-lungs.html#data-set-1"><i class="fa fa-check"></i><b>8.2</b> Data set</a></li>
<li class="chapter" data-level="8.3" data-path="story-lungs.html"><a href="story-lungs.html#models-1"><i class="fa fa-check"></i><b>8.3</b> Models</a></li>
<li class="chapter" data-level="8.4" data-path="story-lungs.html"><a href="story-lungs.html#explanations-3"><i class="fa fa-check"></i><b>8.4</b> Explanations</a></li>
<li class="chapter" data-level="8.5" data-path="story-lungs.html"><a href="story-lungs.html#summary-and-conclusions-4"><i class="fa fa-check"></i><b>8.5</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="story-heloc-credits.html"><a href="story-heloc-credits.html"><i class="fa fa-check"></i><b>9</b> Story HELOC Credits</a>
<ul>
<li class="chapter" data-level="9.1" data-path="story-heloc-credits.html"><a href="story-heloc-credits.html#introduction-8"><i class="fa fa-check"></i><b>9.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="story-heloc-credits.html"><a href="story-heloc-credits.html#dataset-1"><i class="fa fa-check"></i><b>9.1.1</b> Dataset</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="story-heloc-credits.html"><a href="story-heloc-credits.html#model-6"><i class="fa fa-check"></i><b>9.2</b> Model</a></li>
<li class="chapter" data-level="9.3" data-path="story-heloc-credits.html"><a href="story-heloc-credits.html#explanations-4"><i class="fa fa-check"></i><b>9.3</b> Explanations</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="story-heloc-credits.html"><a href="story-heloc-credits.html#model-explanations"><i class="fa fa-check"></i><b>9.3.1</b> Model explanations</a></li>
<li class="chapter" data-level="9.3.2" data-path="story-heloc-credits.html"><a href="story-heloc-credits.html#explanation-for-clients"><i class="fa fa-check"></i><b>9.3.2</b> Explanation for clients</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="story-heloc-credits.html"><a href="story-heloc-credits.html#summary-and-conclusion"><i class="fa fa-check"></i><b>9.4</b> Summary and conclusion</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="story-compas.html"><a href="story-compas.html"><i class="fa fa-check"></i><b>10</b> Story COMPAS: recidivism reloaded</a>
<ul>
<li class="chapter" data-level="" data-path="story-compas.html"><a href="story-compas.html#take-away-messages-1"><i class="fa fa-check"></i>Take-away messages</a></li>
<li class="chapter" data-level="10.1" data-path="story-compas.html"><a href="story-compas.html#introduction-9"><i class="fa fa-check"></i><b>10.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="story-compas.html"><a href="story-compas.html#previous-work-on-compas-algorithm"><i class="fa fa-check"></i><b>10.1.1</b> Previous work on COMPAS algorithm</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="story-compas.html"><a href="story-compas.html#data-3"><i class="fa fa-check"></i><b>10.2</b> Data</a></li>
<li class="chapter" data-level="10.3" data-path="story-compas.html"><a href="story-compas.html#models-2"><i class="fa fa-check"></i><b>10.3</b> Models</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="story-compas.html"><a href="story-compas.html#results---compas-regression"><i class="fa fa-check"></i><b>10.3.1</b> Results - COMPAS Regression</a></li>
<li class="chapter" data-level="10.3.2" data-path="story-compas.html"><a href="story-compas.html#results---recidivism-classification"><i class="fa fa-check"></i><b>10.3.2</b> Results - Recidivism Classification</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="story-compas.html"><a href="story-compas.html#explanations-5"><i class="fa fa-check"></i><b>10.4</b> Explanations</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="story-compas.html"><a href="story-compas.html#model-specific"><i class="fa fa-check"></i><b>10.4.1</b> Model specific</a></li>
<li class="chapter" data-level="10.4.2" data-path="story-compas.html"><a href="story-compas.html#instance-specific"><i class="fa fa-check"></i><b>10.4.2</b> Instance specific</a></li>
<li class="chapter" data-level="10.4.3" data-path="story-compas.html"><a href="story-compas.html#models-without-protected-attributes"><i class="fa fa-check"></i><b>10.4.3</b> Models without protected attributes</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="story-compas.html"><a href="story-compas.html#fairness"><i class="fa fa-check"></i><b>10.5</b> Fairness</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="story-compas.html"><a href="story-compas.html#overview"><i class="fa fa-check"></i><b>10.5.1</b> Overview</a></li>
<li class="chapter" data-level="10.5.2" data-path="story-compas.html"><a href="story-compas.html#models-3"><i class="fa fa-check"></i><b>10.5.2</b> Models</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="story-compas.html"><a href="story-compas.html#summary-and-conclusions-5"><i class="fa fa-check"></i><b>10.6</b> Summary and conclusions</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="story-compas.html"><a href="story-compas.html#next-steps"><i class="fa fa-check"></i><b>10.6.1</b> Next steps</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="references-1.html"><a href="references-1.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">XAI Stories</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="story-uplift-marketing1" class="section level1" number="5">
<h1><span class="header-section-number">Chapter 5</span> Story Uplift Modeling: eXplainable predictions for optimized marketing campaigns</h1>
<p><em>Authors: Jan Ludziejewski (Warsaw University), Paulina Tomaszewska (Warsaw University of Technology), Andżelika Zalewska (Warsaw University of Technology)</em></p>
<p><em>Mentors: Łukasz Frydrych (McKinsey), Łukasz Pająk (McKinsey)</em></p>
<p><strong>Key points</strong>:</p>
<ul>
<li><p>uplift models thanks to linear definition give wide range of possibilities while using XAI<br />
</p></li>
<li><p>SHAP values can be used to explain model both in local and global aspects - they can be generalized in order to estimate Variable Importance and Dependence Plots</p></li>
<li><p>in the case of analysed dataset, marketing campaign should be sent two months after last purchase to be the most effective</p></li>
<li><p>XAI analysis can help in creating personalized marketing campaigns</p></li>
</ul>
<div id="introduction-4" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Introduction</h2>
<p>Running a business is a challenge. It involves making a lot of decisions to maximize profits and cut down costs - finding the tradeoff is not a straightforward task.
Here come Machine Learning and uplift models that can help in optimizing marketing costs.</p>
<p>It is widely believed that it is a good idea to send marketing offer to all company’s customers. From one point of view, we think the probability that the customer will buy our product is higher - in fact it is not always the case (the matter will be described in details later). On the other hand, making a large-scale campaign is costly. Therefore, it is important to consider in decision-making what is the Return on Investment (ROI).</p>
<p>Is it true that by sending the marketing offer we only increase the chance for the customer to buy our product and therefore extend our profit? The issue was already investigated <span class="citation">(Verbeke and Bravo <a href="#ref-book_uplift" role="doc-biblioref">2017</a>)</span> and it was pointed out that customers of any company can be divided into 4 groups (Figure: <a href="story-uplift-marketing1.html#fig:4groups">5.1</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:4groups"></span>
<img src="images/09_e45e2d97-confmatrix_alt.png" alt="Customer types taking into consideration their response to treatment [@4groups_chart]" width="50%" />
<p class="caption">
FIGURE 5.1: Customer types taking into consideration their response to treatment <span class="citation">(Yi and Frost <a href="#ref-4groups_chart" role="doc-biblioref">2018</a><a href="#ref-4groups_chart" role="doc-biblioref">a</a>)</span>
</p>
</div>
<p>The matrix (Figure: <a href="story-uplift-marketing1.html#fig:4groups">5.1</a>) was created based on customer decision to buy a product depending on the fact that they were addressed by a marketing campaign or not. The action used for triggering in customers the particular behaviour is called treatment. In the 4 groups we distinguish:</p>
<ul>
<li><span style="color:darkgreen"><strong>‘persuadables’</strong>*</span>: the customers that without being exposed to marketing campaign would not buy a product</li>
<li><span style="color:grey"><strong><em>‘sure things’</em></strong></span>: the customers that irrespective of the fact that they experienced treatment or not are going to buy a product</li>
<li><span style="color:grey"><strong><em>‘lost causes’</em></strong></span>: the customers that irrespective of the fact that they experienced treatment or not are <strong>NOT</strong> going to buy a product</li>
<li><span style="color:darkred"> <strong><em>‘sleeping dogs’</em></strong></span>: the customers that without being exposed to marketing campaign would buy a product but in case they receive a marketing offer they resign</li>
</ul>
<p>It can be then observed that in case of <em>‘lost causes’</em> and <em>‘sure things’</em>, sending a marketing offer makes no impact therefore it doesn’t make sense to spend money on targeting these customers. As the company, we should however pay more attention to the groups <em>‘persuadables’</em> and <em>‘sleeping dogs’</em>. In the case of the first group, bearing the costs of the marketing campaign will bring benefits. In the case of the latter, we not only spend money on targeting them but as a result, we will also discourage them from buying the product therefore as a company we loose twice. The case of <em>‘sleeping dogs’</em> may seem irrealistic, therefore we present an example.</p>
<blockquote>
<p><em>Let’s imagine there is a customer that subscribed to our paid newsletter. He forgot that he pays each month fixed fee. He would continue paying unless a company sends him a discount offer. At this moment, the customer realizes that he doesn’t need the product and unsubscribes.</em></p>
</blockquote>
<p>By understanding the structure of the customers, company can target its offer more effectively.</p>
<div id="approaches-towards-uplift-modeling" class="section level3" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Approaches towards uplift modeling</h3>
<p>In <span class="citation">(Akshay Kumar <a href="#ref-uplift_stanford" role="doc-biblioref">2018</a>)</span> it was pointed out that the problem of deciding whether it is profitable to send an offer to a particular customer, can be tackled from two different perspectives:</p>
<ul>
<li>predictive response modeling (it is common classification task where model assigns a probability to each of the classes)<br />
</li>
<li>uplift modeling (where the ‘incremental’ probability of purchase is modeled)</li>
</ul>
<p>The latter is tailored to this particular task and is more challenging.
<strong>Uplift modeling is a technique that helps to determine probability gain that the customer by getting the marketing materials will buy a product.</strong>
The field is relatively new. The two most common approaches are <span class="citation">(Lee <a href="#ref-uplift_approaches" role="doc-biblioref">2018</a>)</span>:</p>
<ul>
<li><p><strong>Two Model</strong><br />
In this method two classifiers are built. The one is trained on observations that received treatment (called <em>model_T1</em>) and the second is trained on observations that didn’t receive treatment (called <em>model_T0</em>). Later, the uplift for particular observations is calculated. If the observation experienced treatment then it is an input to the <em>model_T1</em> and the probability that the customer will buy a product is predicted. Next, it is investigated what could happen if the customer didn’t receive treatment. In that case, the treatment indicator in observation’s feature is changed to ‘zero’. This kind of modified record is an input to the <em>model_T0</em> that predicts the probability that particular customer will buy a product. The uplift is calculated as the difference between the outputs of the <em>model_T1</em> and <em>model_T0</em>. The higher the difference, the more profitable it is to address marketing campaign to a particular customer. Analogically, uplift is computed for the people that didn’t experienced treatment.</p></li>
<li><p><strong>One Model</strong><br />
This approach is similar conceptually to the <em>Two Model</em> method with such a difference that instead of building two classifiers only one is used. Therefore, every observation is an input to the model that generates prediction. Later, the indicator in the treatment column is changed into the negation and such a vector is used as input to the model that once again outputs probability that the customer buys a product. The uplift is the difference between the two predicted probabilities.</p></li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:approches"></span>
<img src="images/09_one_two_model.png" alt="Two Model vs One Model approach (own elaboration), where `P1=P(purchase|T=1)` and `P0=P(purchase|T=0)`" width="100%" />
<p class="caption">
FIGURE 5.2: Two Model vs One Model approach (own elaboration), where <code>P1=P(purchase|T=1)</code> and <code>P0=P(purchase|T=0)</code>
</p>
</div>
<p>As uplift modeling is an emerging field there isn’t a clear evidence what method is better to use.</p>
</div>
</div>
<div id="dataset" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Dataset</h2>
<p>There is a scarcity of well-documented datasets dedicated to uplift modeling. Therefore, in <span class="citation">(Rzepakowski and Jaroszewicz <a href="#ref-uplift_dataset_modification" role="doc-biblioref">2012</a>)</span> in order to extract information about treatment, artificial modifications to available datasets were proposed. As the purpose of this story is to investigate XAI techniques in the domain of uplift modeling, we decided to use real-life dataset.
We chose Kevin Hillstrom’s dataset from E-Mail Analytics And Data Mining Challenge <span class="citation">(Hillstrom <a href="#ref-uplift_dataset_marketing" role="doc-biblioref">2008</a>)</span>. The dataset consists of 64000 records reflecting customers that last purchased within 12 months. As a treatment, an e-mail campaign was addressed:</p>
<ul>
<li>1/3 of customers were randomly chosen to receive an e-mail campaign featuring Men’s merchandise</li>
<li>1/3 were randomly chosen to receive an e-mail campaign featuring Women’s merchandise</li>
<li>1/3 were randomly chosen to not receive any e-mail campaign <em>(‘control group’)</em></li>
</ul>
<p>The following actions were determined as an expected behavior:</p>
<ul>
<li>visit the company’s website within 2 weeks after sending to the customers a marketing campaign</li>
<li>purchase a product from the website within 2 weeks after sending to the customers a marketing campaign</li>
</ul>
<p>In the challenge, the task was to determine whether the men’s or women’s e-mail campaign was successful. In order to simplify the problem, we reformulated the task - we have focused on answering the question of whether any e-mail campaign persuaded customers to buy a product.</p>
<p>The features about customers in the dataset are specified in Figure <a href="story-uplift-marketing1.html#fig:dataset">5.3</a>:</p>
<div class="figure" style="text-align: center"><span id="fig:dataset"></span>
<img src="images/09_xai_customer.jpg" alt="Customer features in the dataset (own elaboration)" width="100%" />
<p class="caption">
FIGURE 5.3: Customer features in the dataset (own elaboration)
</p>
</div>
<p>In the dataset, there is also information about customer activity in the two weeks following delivery of the e-mail campaign (these can be interpreted as labels):</p>
<ul>
<li><em>Visit</em>: 1/0 indicator, 1 = Customer visited website in the following two weeks</li>
<li><em>Conversion</em>: 1/0 indicator, 1 = Customer purchased merchandise in the following two weeks</li>
<li><em>Spent</em>: Actual dollars spent in the following two weeks</li>
</ul>
<div id="explanatory-data-analysis" class="section level3" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> Explanatory Data Analysis</h3>
First, we decided to investigate variables that have more than 3 unique values. At the same time, these variables (<em>recency</em> and <em>history</em>) intuitively seem to be the most important while predicting whether someone will buy a product or not.
<div class="figure" style="text-align: center"><span id="fig:histogram"></span>
<img src="images/09_recency.png" alt="Histograms of *recency* (left) and *history* (right)" width="40%" /><img src="images/09_history.png" alt="Histograms of *recency* (left) and *history* (right)" width="40%" />
<p class="caption">
FIGURE 5.4: Histograms of <em>recency</em> (left) and <em>history</em> (right)
</p>
</div>
<p>It can be seen that <em>history</em> variable has heavy-tailed distribution therefore it may be reasonable to use Box-Cox transformation. However, we decided to keep the variable without any preprocessing for easier interpretation.</p>
<div class="figure" style="text-align: center"><span id="fig:countplots"></span>
<img src="images/09_count_plot.png" alt="Count plots" width="100%" />
<p class="caption">
FIGURE 5.5: Count plots
</p>
</div>
<p>In the case of <em>mens</em>, <em>womens</em> and <em>newbie</em> variables the proportion of 0’s to 1’s is almost equal. There is much fewer records of people living in the countryside than in urban or suburban areas. Most of the company customers buy via phone or web. It is rare that someone uses a mulitchannel option. In the dataset, most of the customers received treatment in the form of marketing E-mail.</p>
</div>
<div id="feature-engineering" class="section level3" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> Feature engineering</h3>
<p>The dataset is largely imbalanced - there are only about 15% of positive cases in column <em>Visit</em> and 9% in column <em>Conversion</em>.
In such a situation, we decided to use column <em>Visit</em> as a target for the classifier.
As the number of columns is small, therefore, we decided to use one-hot encoding for transforming categorical variables instead of target encoding.</p>
</div>
</div>
<div id="model-exploration-and-metrics" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> Model exploration and metrics</h2>
<p>There are not many packages dedicated to uplift modeling in python. We investigated the two: pylift <span class="citation">(Yi and Frost <a href="#ref-pylift" role="doc-biblioref">2018</a><a href="#ref-pylift" role="doc-biblioref">b</a>)</span> and pyuplift <span class="citation">(Kuchumov <a href="#ref-pyuplift" role="doc-biblioref">2018</a>)</span>. The latter enables usage of 4 types of models - one of those is the Two Model approach. In the pylift package there is the TransformedOutcome class that generates predictions. However, the model itself is not well described and uses XGBRegressor underneath that is not intuitive. Fortunately, the package offers also the class UpliftEval that allows uplift metrics visualization.
In the scene, we decided to create own classifier (as in the One Model approach) and use UpliftEval class from the pylift package for metric evaluation.
In our project, we used XGBoost classifier. In order to optimize its parameters, we applied the area under the cumulative gain chart (described below) as score function. In the Figure <a href="story-uplift-marketing1.html#fig:upliftRES">5.6</a>, we show the cumulative gain chart for train and test sets.</p>
<div class="figure" style="text-align: center"><span id="fig:upliftRES"></span>
<img src="images/09_uplift_train_robust.png" alt="Cumulative gain chart: (left) train set, (right) test set" width="50%" /><img src="images/09_uplift_test_robust.png" alt="Cumulative gain chart: (left) train set, (right) test set" width="50%" />
<p class="caption">
FIGURE 5.6: Cumulative gain chart: (left) train set, (right) test set
</p>
</div>
<p>The Qini curve is not suggested for performance evaluation of uplift models as it is vulnerable to overfitting to the treatment label. Therefore, the Cumulative gain chart is used. It is the least biased estimate of the uplift. In the pylift package, it is implemented based on the formula:
<span class="math inline">\(Cumulative\ gain(\phi) = (\frac {n_{t,1}(\phi)}{n_{t,1}}-\frac {n_{c,1}(\phi)}{n_{c,1}})(\frac{n_t(\phi)+n_c(\phi)}{N_t+N_c})\)</span><br />
where<br />
<span class="math inline">\(n_{t,1} (\phi)\)</span> is the number of observations in the treatment group at cutoff level <span class="math inline">\(\phi\)</span> with label 1<br />
<span class="math inline">\(n_{c,1} (\phi)\)</span> is the number of observations in the control group at cutoff level <span class="math inline">\(\phi\)</span> with label 1<br />
<span class="math inline">\(n_{t,1}\)</span> is the total number of observations in the treatment group with label 1 (analogically <span class="math inline">\(n_{c,1}\)</span>)<br />
<span class="math inline">\(N_t\)</span> is the total number of observations in treatment group (analogically <span class="math inline">\(N_c\)</span>)</p>
<p>The theoretical plot is created according to the following scheme:<br />
First, the customers are sorted in descending order based on predicted uplift. Later, some fraction of data is taken for the analysis (e.g. 10% of the people with the highest score). This cutoff is represented as <span class="math inline">\(\phi\)</span> in the formula. Next, the uplift gain is verified for the subset. At the beginning of the curve, the gain is the biggest as it refers to the <em>‘persuadables’</em> group. Later, the curve stabilizes as it depicts the groups: <em>‘lost causes’</em> and <em>‘sure things’</em>. At the end the curve decreases as there are <em>‘sleeping dogs’</em> with negative uplift.</p>
<div id="model-2" class="section level3" number="5.3.1">
<h3><span class="header-section-number">5.3.1</span> Model</h3>
<p>It can be seen that our model is better than random choice but much worse than the practical/theoretical maximum possible. It is also worse than the case without <em>‘sleeping dogs’</em>.
Comparing to uplift modeling in different domains, i. e. medical applications, treatment in marketing has generally smaller impact on individual, therefore dataset itself is more noisy and cumulative gains are smaller. It is also worth noting, that due to small number of features, there are multiple cases in the dataset where two observations with same features have different answers. This kind of noise in data also tremendously impacts the score and requires caution when training models. Also, since uplift itself is an interaction, our model do have to take them into consideration.</p>
<p>Considering previous observations, model was found using so called local search procedure, which means that we choose some meta-parameters of the model and iteratively, for every meta-parameter approximate derivative by sampling the local neighborhood of current value and follow the ascending gradient. Local search stops naturally, when in previous iteration, we did not change any parameter, hence we hit one of the local minima. To be clear, if meta-parameter is discrete, by approximating local neighborhood we mean just checking close values. For our score function, we’ve chosen cross-validation on cumulative gains. This kind of procedure should seek for highly robust models. Therefore, it is worth noticing that our model didn’t experience any overfitting as its quality on the train and test sets is similar. The resulting major parameters were: maximum depth of 5, high learning rate of 0.7 and only 12 estimators.</p>
</div>
<div id="comparing-metrics" class="section level3" number="5.3.2">
<h3><span class="header-section-number">5.3.2</span> Comparing metrics</h3>
<p>We tried to employ the same local search procedure (as described in Model section) using accuracy as score function. However, it failed to converge with any decent quality, because this metric is much less informative in case of largely imbalanced dataset. Since only a small number of customers actually made a purchase, it’s hard to correctly predict a positive case using non-overfitted model. Therefore within the local search with accuracy function, starting local neighborhood was always flat. This might be because in the dataset there is more noise than positive cases. But fortunately, only important factor, from our perspective is probability of the purchase, since uplift is an increase of purchase probability after treatment, and it directly transfers into money gain.
To visualize it in a straightforward manner, we present a table comparing our current robust XGBoost model with overfitted one (deep trees, 100 estimators).</p>
<table>
<caption><span id="tab:overfitTable">TABLE 5.1: </span>Metrics comparison</caption>
<colgroup>
<col width="20%" />
<col width="15%" />
<col width="15%" />
<col width="24%" />
<col width="24%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Model</th>
<th align="right">Train accuracy</th>
<th align="right">Valid accuracy</th>
<th align="right">Train cummulative gain</th>
<th align="right">Valid cummulative gain</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Overfitted XGBoost</td>
<td align="right">0.8755</td>
<td align="right">0.8473</td>
<td align="right">0.7190</td>
<td align="right">0.0204</td>
</tr>
<tr class="even">
<td align="left">Robust XGBoost</td>
<td align="right">0.8532</td>
<td align="right">0.8532</td>
<td align="right">0.0398</td>
<td align="right">0.0425</td>
</tr>
</tbody>
</table>
<p>As we can see (Table <a href="story-uplift-marketing1.html#tab:overfitTable">5.1</a>) for the overfitted model, cumulative gain drops by 97% while the overfit gap in accuracy scores is only around 2%.</p>
</div>
</div>
<div id="explanations-2" class="section level2" number="5.4">
<h2><span class="header-section-number">5.4</span> Explanations</h2>
<p>The Cumulative gain chart (Figure <a href="story-uplift-marketing1.html#fig:upliftRES">5.6</a>) shows that the proposed model brings additional value as its performance is always above random system. Here comes the question of whether the model is reliable. Does it make the decision based on the features that are important from an expert perspective? Such judgment can be done using XAI tools.
We decided to investigate model interpretability from instance-level and dataset-level perspective.</p>
<div id="instance-level" class="section level3" number="5.4.1">
<h3><span class="header-section-number">5.4.1</span> Instance-level</h3>
<p>In order to explain model output for a particular customer, we employed SHAP (SHapley Additive exPlanations) values <span class="citation">(Lundberg and Lee <a href="#ref-feature_importance_shap" role="doc-biblioref">2017</a>)</span>.</p>
<p>Before we move to the investigation of SHAP values, let’s get to know customers that got the highest and the lowest uplift prediction. In this section, we will analyse the reliability of predictions for these particular instances. In the table <a href="story-uplift-marketing1.html#tab:personalTABLE">5.2</a>, there is all the information provided to the system about the customers.</p>
<table>
<caption><span id="tab:personalTABLE">TABLE 5.2: </span>Customer with the highest and the lowest uplift - features</caption>
<thead>
<tr class="header">
<th align="left">Column.name</th>
<th align="left">customer_with_biggest_uplift</th>
<th align="left">customer_with_lowest_uplift</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">recency</td>
<td align="left">2.0</td>
<td align="left">5.0</td>
</tr>
<tr class="even">
<td align="left">history</td>
<td align="left">228.93</td>
<td align="left">243.95</td>
</tr>
<tr class="odd">
<td align="left">mens</td>
<td align="left">1.0</td>
<td align="left">0.0</td>
</tr>
<tr class="even">
<td align="left">womens</td>
<td align="left">1.0</td>
<td align="left">1.0</td>
</tr>
<tr class="odd">
<td align="left">zip_code_Surburban</td>
<td align="left">1.0</td>
<td align="left">0.0</td>
</tr>
<tr class="even">
<td align="left">zip_code_Rural</td>
<td align="left">0.0</td>
<td align="left">1.0</td>
</tr>
<tr class="odd">
<td align="left">zip_code_Urban</td>
<td align="left">0.0</td>
<td align="left">0.0</td>
</tr>
<tr class="even">
<td align="left">newbie</td>
<td align="left">0.0</td>
<td align="left">1.0</td>
</tr>
<tr class="odd">
<td align="left">channel_Phone</td>
<td align="left">0.0</td>
<td align="left">1.0</td>
</tr>
<tr class="even">
<td align="left">channel_Web</td>
<td align="left">1.0</td>
<td align="left">0.0</td>
</tr>
<tr class="odd">
<td align="left">channel_Multichannel</td>
<td align="left">0.0</td>
<td align="left">0.0</td>
</tr>
<tr class="even">
<td align="left">segment</td>
<td align="left">0.0</td>
<td align="left">1.0</td>
</tr>
</tbody>
</table>
<p>As can be seen (Table <a href="story-uplift-marketing1.html#tab:personalTABLE">5.2</a>) the customers spent almost the same amount of money during the last 12 months on our company’s products.
The person with the highest uplift did last shopping 2 months ago whereas the person with the lowest uplift did it 5 months ago. In the dataset, some people purchased the product for the last time even 12 months ago so the person with the lowest uplift is not the edge case in that sense. Apart from many other differences among the two customers, the key is that the person with the highest uplift received treatment whereas the second customer didn’t.</p>
Below we present SHAP values for the customer described in Table <a href="story-uplift-marketing1.html#tab:personalTABLE">5.2</a>. The values were computed directly on uplift model <a href="story-uplift-marketing1.html#fig:upliftSHAP">5.7</a>.
<div class="figure"><span id="fig:upliftSHAP"></span>
<img src="images/09_shap_min_uplift_pred.png" alt="SHAP values: (left) customer with the lowest uplift, (right) customer with the highest uplift" width="50%" /><img src="images/09_shap_max_uplift_pred.png" alt="SHAP values: (left) customer with the lowest uplift, (right) customer with the highest uplift" width="50%" />
<p class="caption">
FIGURE 5.7: SHAP values: (left) customer with the lowest uplift, (right) customer with the highest uplift
</p>
</div>
<p>In can be seen that in both cases, big contribution to the final result has information about customer history (about 235 USD) and the fact that the customer bought products from women’s collection. What is interesting, is the fact that the customers have almost the same values of these two attributes but opposite sign of its contribution (SHAP value).</p>
</div>
<div id="difference---approach" class="section level3" number="5.4.2">
<h3><span class="header-section-number">5.4.2</span> Difference - approach</h3>
<p><strong>We can benefit from additive feature attribution property of SHAP values to model the uplift:</strong></p>
<p><span class="math inline">\(uplift=P(purchase|\ T=1) - P(purchase|\ T=0))\)</span>
<span class="math inline">\(SHAP(uplift)= SHAP(P(purchase|\ T=1)) - SHAP(P(purchase|\ T=0))\)</span></p>
<p>This property gives us a great opportunity to evaluate these two vectors of SHAP values independently. For example, if we use any tree-based model, we can make use of tree-based kernel for SHAP value estimation (faster and better convergent) instead of modeling it directly as a black-box (uplift) model.</p>
<p>In a table <a href="story-uplift-marketing1.html#tab:upliftTABLE">5.3</a> there is a comparison of SHAP values obtained using two methods for the customer with the lowest uplift.</p>
<table>
<caption><span id="tab:upliftTABLE">TABLE 5.3: </span>SHAP values obtained using two methods</caption>
<thead>
<tr class="header">
<th align="left">Column_name</th>
<th align="left">Uplift_approach</th>
<th align="left">Diff_approach</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">recency</td>
<td align="left">-0.00593</td>
<td align="left">-0.00535</td>
</tr>
<tr class="even">
<td align="left">history</td>
<td align="left">-0.27282</td>
<td align="left">-0.27270</td>
</tr>
<tr class="odd">
<td align="left">mens</td>
<td align="left">-0.00961</td>
<td align="left">-0.00928</td>
</tr>
<tr class="even">
<td align="left">womens</td>
<td align="left">-0.05628</td>
<td align="left">-0.05692</td>
</tr>
<tr class="odd">
<td align="left">zip_code_Surburban</td>
<td align="left">0.00076</td>
<td align="left">-0.00055</td>
</tr>
<tr class="even">
<td align="left">zip_code_Rural</td>
<td align="left">-0.03313</td>
<td align="left">-0.03257</td>
</tr>
<tr class="odd">
<td align="left">zip_code_Urban</td>
<td align="left">-0.00148</td>
<td align="left">-0.00179</td>
</tr>
<tr class="even">
<td align="left">newbie</td>
<td align="left">0.00365</td>
<td align="left">0.00351</td>
</tr>
<tr class="odd">
<td align="left">channel_Phone</td>
<td align="left">0.00024</td>
<td align="left">-0.00036</td>
</tr>
<tr class="even">
<td align="left">channel_Web</td>
<td align="left">0.00188</td>
<td align="left">0.00200</td>
</tr>
<tr class="odd">
<td align="left">channel_Multichannel</td>
<td align="left">-0.00067</td>
<td align="left">0.00029</td>
</tr>
<tr class="even">
<td align="left">segment</td>
<td align="left">0.00010</td>
<td align="left">0.00043</td>
</tr>
</tbody>
</table>
<p>Experimental results proved that these two ways of calculating SHAP values provide similar estimations with precision to numerical errors. There are few features, that depending on the method, have a small positive or negative value. This is caused by the fact that for the estimation of SHAP values directly using uplift model the KernelExplainer was used. The source of randomness is the fact that we took subset of records instead of whole dataset as such behavior is recommended in documentation due to algorithm’s complexity. Also, KernelExplainer is by nature less precise. Nevertheless, we proved that in the case of our example the two methods lead to similar values.</p>
<p>The specificity of uplift models in terms of the possibility to analyse them through additivity of SHAP values gives room for another valuable inspection.
Below we present how SHAP values differ depending on the fact that the customer was or wasn’t addressed by treatment. On <em>x</em> axis, there are SHAP values in case T=0 and on <em>y</em> axis in case T=1. In each chart, there is SHAP value referring to one variable. In situation when the SHAP values are the same irrespective of the presence or absence of treatment, they would lie on identity line. Moreover, there is color used as third dimension indicating the group that the particular customer belongs to. We decided to merge two groups (<em>‘sure things’</em> and <em>‘lost causes’</em>) as they have uplift almost equal to zero, therefore now we can distinguish 3 groups: <em>‘sleeping dogs’</em>, <em>‘persuadables’</em> and <em>‘sure things and lost causes’</em>. The division was based on the predicted uplift. <em>‘Sleeping dogs’</em> have considerable negative uplift, <em>‘sure things and lost causes’</em> have uplift in <span class="math inline">\([-0.01,0.01]\)</span> and <em>‘persuadables’</em> have uplift greater than 0.01. The group <em>‘sure things and lost causes’</em> should have zero uplift, but due to numerical issues we decided to set <span class="math inline">\(\epsilon\)</span> equal to 0.01. As almost all customers were categorized to <em>‘persuadables’</em>, we decided to show on the plot only 1000 records from this group to maintain chart readability.</p>
<div class="figure" style="text-align: center"><span id="fig:recencySHAP"></span>
<img src="images/09_shap_recency.png" alt="SHAP values on variable recency in case T=0 and T=1" width="50%" />
<p class="caption">
FIGURE 5.8: SHAP values on variable recency in case T=0 and T=1
</p>
</div>
It can be seen that <em>‘persuadables’</em> are slightly above and below identity line.
<div class="figure" style="text-align: center"><span id="fig:historySHAP"></span>
<img src="images/09_shap_history.png" alt="SHAP values on variable history in case T=0 and T=1" width="50%" />
<p class="caption">
FIGURE 5.9: SHAP values on variable history in case T=0 and T=1
</p>
</div>
<p>In Figure <a href="story-uplift-marketing1.html#fig:historySHAP">5.9</a> the three customer groups are distinctive. It would be interesting whether the result of clustering methods would be similar.</p>
We also investigated binary variables. Most of them looked similar as Figure <a href="story-uplift-marketing1.html#fig:historySHAP">5.9</a> but there was one exception - variable <em>womens</em>.
<div class="figure" style="text-align: center"><span id="fig:womensSHAP"></span>
<img src="images/09_shap_womens.png" alt="SHAP values on variable womens in case T=0 and T=1" width="50%" />
<p class="caption">
FIGURE 5.10: SHAP values on variable womens in case T=0 and T=1
</p>
</div>
<p>The customer groups on Figure <a href="story-uplift-marketing1.html#fig:womensSHAP">5.10</a> are overlapping. They constitute very homogeneous groups.</p>
<p>Note:<br />
In the case of our model, there is no need to apply LIME as its main advantages - sparsity - is not important when there are only few variables.</p>
</div>
<div id="dataset--subset--level" class="section level3" number="5.4.3">
<h3><span class="header-section-number">5.4.3</span> Dataset- (subset-) level</h3>
<p>In order to compute Variable Importance, most of the time the Permutation Feature Importance method is used.
Unfortunately, it’s impossible to use this approach directly in our case, because of the previously mentioned problem with lack of full information. We don’t know if the client would purchase product after treatment or he would buy without treatment as well. Because of having in disposal only historical data (not an oracle), we have only one of these two pieces of information. However, we can make use of the previously computed SHAP values of uplift to calculate the same value of permutational feature importance as an average of local SHAP importance (defined in a permutational way itself, however, calculated more smartly <span class="citation">(Lundberg and Lee <a href="#ref-feature_importance_shap" role="doc-biblioref">2017</a>)</span>).</p>
<p>We decided to evaluate feature importance not from the well-known dataset-level but from the subset-level perspective. As the subsets we mean 3 customer groups: <em>‘sleeping dogs’</em>, <em>‘sure things and lost causes’</em> and <em>‘persuadables’</em>.</p>
<p>Below we present the Variable Importance plots. The correlations between SHAP values of particular variable and variable itself were highlighted in colors. The red color means a positive correlation whereas blue means negative correlation.</p>
<div class="figure" style="text-align: center"><span id="fig:sleepingDOGS"></span>
<img src="images/09_sleeping_dogs_feature_importance_correlations.png" alt="Variable Importance - *'sleeping dogs'*" width="60%" />
<p class="caption">
FIGURE 5.11: Variable Importance - <em>‘sleeping dogs’</em>
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:noIMPACT"></span>
<img src="images/09_no_impact_feature_importance_correlations.png" alt="Variable Importance - *'sure things and lost causes'*" width="60%" />
<p class="caption">
FIGURE 5.12: Variable Importance - <em>‘sure things and lost causes’</em>
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:persuadables"></span>
<img src="images/09_persuadables_feature_importance_correlations.png" alt="Variable Importance - *'persuadables'*" width="60%" />
<p class="caption">
FIGURE 5.13: Variable Importance - <em>‘persuadables’</em>
</p>
</div>
<p>Conclusions:<br />
Regardless of the customer groups, always <em>history</em> and <em>womens</em> are among three most important features. For observations with considerable negative uplift (<em>‘sleeping dogs’</em>) both <em>history</em> and <em>womens</em> have negative correlation with their SHAP values. In the case of <em>‘sure things and lost causes’</em>, <em>womens</em> has positive correlation whereas <em>history</em> has negative. The same variables among <em>‘persuadables’</em> (considerable positive uplift) have positive correlation with SHAP values. <em>Correlation changes gradually with uplift value.</em> What is interesting is the fact that regarding <em>zip code</em> only the information whether someone is from rural area is important. Note that this category of dwelling place was the least popular among customers. Information about purchase channel in general has relatively small predictive power.</p>
<div id="dependence-plots" class="section level4" number="5.4.3.1">
<h4><span class="header-section-number">5.4.3.1</span> Dependence plots</h4>
<p>Another tool to investigate model are the dependence plots. There are two options. The most common method is the Partial Dependence Plot (PDP)/ Accumulated Local Effects (ALE) and the other one is the SHAP dependence plot. The Partial Dependence Plot shows the marginal effect that one or two features have on the predicted outcome of a machine learning model <span class="citation">(Friedman <a href="#ref-pdp" role="doc-biblioref">2000</a>)</span>. It tells whether the relationship between the target and a feature is linear, monotonic or more complex. In the SHAP dependence plot, we can show how a feature value (<em>x</em> axis) impacted the prediction (<em>y</em> axis) of every sample (each dot) in a dataset <span class="citation">(Lundberg et al. <a href="#ref-shap_dependence_plot" role="doc-biblioref">2019</a>)</span>. This provides richer information than the traditional Partial Dependence Plot, because we have at least two additional information: density and variance of observations.</p>
<p>The Partial Dependence Plots reflect the expected output of the model if only one feature value is changed and the rest stays the same. In contrast, the SHAP value for a feature represents how much that feature impacted the prediction for single sample, accounting for interaction effects. So while in general you would expect to see similar shapes in a SHAP dependence plot and a Partial Dependence Plot, they will be different if your model has multi-variable interaction effects (like AND or OR). A PDP has no vertical dispersion and so no indication of how much interaction effects are driving the models predictions <span class="citation">(Lundberg <a href="#ref-shap_dependence_plot_explained" role="doc-biblioref">2018</a>)</span>.</p>
<p>We generated the Partial Dependence Plot for all features and the SHAP dependence plot based on 1000 observations only for <em>history</em> and <em>recency</em> features due to large processing time.</p>
<div class="figure"><span id="fig:PDPhistory"></span>
<img src="images/09_history_PDP_ALE.png" alt="History (left) Partial Dependence Plot / Accumulated Local Effects plot, (right) The SHAP Dependence Plot based on 1000 observations" width="50%" /><img src="images/09_history_shap_dependence_plot.png" alt="History (left) Partial Dependence Plot / Accumulated Local Effects plot, (right) The SHAP Dependence Plot based on 1000 observations" width="50%" />
<p class="caption">
FIGURE 5.14: History (left) Partial Dependence Plot / Accumulated Local Effects plot, (right) The SHAP Dependence Plot based on 1000 observations
</p>
</div>
<p>For our model the SHAP Dependence Plot reflects the shape of the Partial Dependence Plot. Contribution of <em>history</em> to the final uplift prediction differs among people with the same value of <em>history</em>. It can be seen that there is a considerable peak on the chart for <em>history</em> value of about 230 USD. However, people that spent such amount of money have various SHAP values - some positive, some negative. This observation is not contradictory to PDP as in case of PDP, we compute the average. Note that on SHAP dependence plot we displayed a sample of size 1000.</p>
<div class="figure"><span id="fig:PDPrecency"></span>
<img src="images/09_recency_PDP_ALE.png" alt="Recency (left) Partial Dependence Plot / Accumulated Local Effects plot, (right) The SHAP Dependence Plot based on 1k observations" width="50%" /><img src="images/09_recency_shap_dependence_plot.png" alt="Recency (left) Partial Dependence Plot / Accumulated Local Effects plot, (right) The SHAP Dependence Plot based on 1k observations" width="50%" />
<p class="caption">
FIGURE 5.15: Recency (left) Partial Dependence Plot / Accumulated Local Effects plot, (right) The SHAP Dependence Plot based on 1k observations
</p>
</div>
<p>Due to the fact that <em>recency</em> can have only one of 12 values, only 12 ‘clusters’ can be seen on the SHAP Dependence Plot. Dispersion within the ‘clusters’ shows how much the observations in our dataset differ.</p>
<div class="figure" style="text-align: center"><span id="fig:PDPmenswomens"></span>
<img src="images/09_mens_womens_PDP_ALE.png" alt="Gender PDP" width="100%" />
<p class="caption">
FIGURE 5.16: Gender PDP
</p>
</div>
<p>It is surprising that the disproportion between the results shown in Figure <a href="story-uplift-marketing1.html#fig:PDPmenswomens">5.16</a> is so significant. In the PDP of <em>mens</em> feature, the lines are almost flat meaning that regardless of the fact whether someone bought or not a product from mens collection the uplift prediction stays the same.</p>
<div class="figure" style="text-align: center"><span id="fig:PDPnewbie"></span>
<img src="images/09_newbie_PDP_ALE.png" alt="Newbie PDP" width="50%" />
<p class="caption">
FIGURE 5.17: Newbie PDP
</p>
</div>
<p>According to the Figure <a href="story-uplift-marketing1.html#fig:PDPnewbie">5.17</a>, if a person is a <em>newbie</em>, it is harder to encourage him/her to buy a product through marketing campaign.</p>
<div class="figure" style="text-align: center"><span id="fig:PDPzip"></span>
<img src="images/09_zip_PDP_ALE.png" alt="Dwelling place PDP" width="100%" />
<p class="caption">
FIGURE 5.18: Dwelling place PDP
</p>
</div>
<p>It can be seen that PDP of <em>zip_code_Suburban</em> and <em>zip_code_Urban</em> look very similar. They both have decreasing trend, whereas PDP of <em>zip_code_Rural</em> has increasing trend. In this case, it can be seen that ALE and PDP crosses. As they aren’t parallel, it means there is a slight interaction in model.</p>
<div class="figure" style="text-align: center"><span id="fig:PDPchannel"></span>
<img src="images/09_channel_PDP_ALE.png" alt="Channel PDP" width="100%" />
<p class="caption">
FIGURE 5.19: Channel PDP
</p>
</div>
<p>The biggest gain in terms of uplift can be seen in case when the person uses Web channel. The PDP of <em>Phone_channel</em> is flat.</p>
</div>
</div>
</div>
<div id="conclusions-1" class="section level2" number="5.5">
<h2><span class="header-section-number">5.5</span> Conclusions</h2>
<p>Since Partial Dependence Plots are generally parallel to Accumulated Local Effects, we can safely assume that our model does not have (major) interactions. However, this does not mean that we can use some classifier without interactions, because here we model directly the uplift, which is the difference between predictions and it is an interaction itself.</p>
<div id="sweet-spot" class="section level3" number="5.5.1">
<h3><span class="header-section-number">5.5.1</span> Sweet-spot</h3>
<p>The most important observation here, should be that while at first glance we can only manipulate the treatment variable, dependence plots also give us the opportunity to <em>choose best time to contact the customer</em>. Intuitively, <em>recency</em> function should be concave, aiming to find some ‘sweet-spot’ between time when customer ‘just went out from the shop’ and ‘forgot about this’. The Figure <a href="story-uplift-marketing1.html#fig:PDPrecency">5.15</a> is indeed concave but only for <em>recency</em> values between 1 and 4. For larger <em>recency</em> there is sinusoidal noise observed. These fluctuations can be interpreted as small overfitting. The key message is that the sweet-spot appears to be two months after the last purchase.</p>
</div>
<div id="bigger-influence" class="section level3" number="5.5.2">
<h3><span class="header-section-number">5.5.2</span> Bigger influence</h3>
<p>Based on Figure <a href="story-uplift-marketing1.html#fig:PDPmenswomens">5.16</a>, bigger influence can be made on customers who bought women’s products than the ones who bought products from men’s collections. Initially we removed from the dataset information about treatment type (Woman’s/Man’s e-mail). But based on Variable Importance analysis (Figures: <a href="story-uplift-marketing1.html#fig:sleepingDOGS">5.11</a>, <a href="story-uplift-marketing1.html#fig:noIMPACT">5.12</a>, <a href="story-uplift-marketing1.html#fig:persuadables">5.13</a>), we can reason about the type of e-mail that maximizes uplift for particular person. Considering how important is <em>womens</em> variable, we propose a following policy: in the case when someone buys from men’s and women’s collections we should send e-mails dedicated to women.</p>
</div>
<div id="influence-from-other-factors" class="section level3" number="5.5.3">
<h3><span class="header-section-number">5.5.3</span> Influence from other factors</h3>
<p>Other PDPs can be used for better understanding of the customer persuadability. Since the only variable considerably reducing estimated uplift is <em>newbie</em>, we can safely conclude, that marketing campaigns have better impact on regular customers, which is quite an intuitive conclusion. Analysing other factors, one-hot encoded area of living (<em>zip_code_Rural</em>, <em>zip_code_Suburban</em>, <em>zip_code_Urban</em>) do not have influence bigger than statistical error maybe except <em>zip_code_Rural</em>. Customers living on the countryside are more likely to be persuaded. Surprisingly it is the only factor that may have some interactions. Referring to the purchase channel, it is best to target customers who bought only by web in past months. It may be connected to the fact that our treatment is conducted via e-mail. We suspect that in some cases the following situation can happen: someone buys via phone as he doesn’t use the internet often. In such cases e-mail campaigns will not be effective.</p>
</div>
</div>
<div id="summary" class="section level2" number="5.6">
<h2><span class="header-section-number">5.6</span> Summary</h2>
<p>Using XAI for uplift modeling helps to understand its complex models better. The analysis goes beyond just assessing whether the model is reliable.</p>
<div id="individual-perspective" class="section level3" number="5.6.1">
<h3><span class="header-section-number">5.6.1</span> Individual perspective</h3>
<p>In the case of our task, individual perspective doesn’t seem to be vital. The situation when a customer writes an e-mail to the company asking why he didn’t receive an e-mail with marketing campaign is highly unlikely. Even if he does, he wouldn’t change his feature like the dwelling area only in order to get the e-mail. The things that the customer can rather easily change are his value of <em>recency</em> or <em>history</em> variable.</p>
</div>
<div id="data-scientists-perspective" class="section level3" number="5.6.2">
<h3><span class="header-section-number">5.6.2</span> Data scientist’s perspective</h3>
<p>From the data scientist’s perspective the most important thing to check is whether the model is overfitted. The tool that can help in verifying model sensitivity is the Partial Dependence Plot. In the case of our model it can be seen that the model is slightly overfitted as there is a peak on PDP of <em>history</em>.</p>
</div>
<div id="executive-perspective" class="section level3" number="5.6.3">
<h3><span class="header-section-number">5.6.3</span> Executive perspective</h3>
<p>XAI techniques can help the executives to understand better the company’s customers behavior without paying for some extra surveys to investigate their attitude towards the company. Key findings:</p>
<ul>
<li>The campaign e-mail should be sent two months after last purchase in order to be more effective.</li>
<li>The most important variables in the model seem to be reasonable, e.g. <em>history</em> and <em>recency</em> (Figures: <a href="story-uplift-marketing1.html#fig:sleepingDOGS">5.11</a>, <a href="story-uplift-marketing1.html#fig:noIMPACT">5.12</a>, <a href="story-uplift-marketing1.html#fig:persuadables">5.13</a>). The only surprising thing is the high importance of <em>zip_code_Rural</em> feature.</li>
<li>In the case when someone buys from men’s and women’s collections we should send e-mails dedicated to women.</li>
<li>In the case of bigger number of treatment variants, it would be possible to create personalized marketing campaign.</li>
</ul>
<p>A vital part of our work was adjusting XAI techniques for the particularities of uplift modeling. We found out that thanks to its additivity, SHAP values are well suited for uplift modeling - we showed two methods of using it. We identified limitations of well-known Permutation Feature Importance in terms of explaining uplift models. It is caused by the fact that unlike the other supervised models, here we do not have exactly labels. Therefore. we used the generalization of SHAP values that converge to Permutation Feature Importance. Also, we analysed the SHAP Dependence Plots as an alternative to PDP. We employed the analysis for the three groups of customers based on the corresponding uplift.</p>
</div>
</div>
<div id="future-works" class="section level2" number="5.7">
<h2><span class="header-section-number">5.7</span> Future works</h2>
<p>During initial feature engineering, we simplified our problem by merging women’s treatment and men’s treatment into one. By analysing PDP, we were able to propose a policy for choosing the optimal treatment type. However, it is not the only possible approach. We can try going beyond standard uplift modeling and model directly uplift with 2 possible outcomes i.e. create purchase prediction, and then check if sending women’s or men’s e-mail is more profitable, resulting in the following equation:</p>
<p><span class="math inline">\(uplift=max{(P(purchase\ |\ w\_T=1) - P(purchase\ |\ w\_T=0,m\_T=0), \\ P(purchase\ |\ m\_T=1) - P(purchase\ |\ w\_T=0,m\_T=0))}\)</span></p>
<p>where:</p>
<ul>
<li>w_T is treatment dedicated to women</li>
<li>m_T is treatment dedicated to men</li>
</ul>
<p>However, this leaves us with several open-ended questions i.e.: can we now implicitly calculate SHAP values, using the previously presented efficient technique (based on additivity)? Surely the max function breaks the additivity of uplift function, but maybe it is possible using some other method?</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-uplift_stanford">
<p>Akshay Kumar, Rishabh Kumar. 2018. “Uplift Modeling : Predicting Incremental Gains.” 2018. <a href="http://cs229.stanford.edu/proj2018/report/296.pdf">http://cs229.stanford.edu/proj2018/report/296.pdf</a>.</p>
</div>
<div id="ref-pdp">
<p>Friedman, Jerome. 2000. “Greedy Function Approximation: A Gradient Boosting Machine.” <em>The Annals of Statistics</em> 29 (November). <a href="https://doi.org/10.1214/aos/1013203451">https://doi.org/10.1214/aos/1013203451</a>.</p>
</div>
<div id="ref-uplift_dataset_marketing">
<p>Hillstrom, Kevin. 2008. “The Minethatdata E-Mail Analytics and Data Mining Challenge Dataset.” 2008. <a href="https://blog.minethatdata.com/2008/03/minethatdata-e-mail-analytics-and-data.html">https://blog.minethatdata.com/2008/03/minethatdata-e-mail-analytics-and-data.html</a>.</p>
</div>
<div id="ref-pyuplift">
<p>Kuchumov, Artem. 2018. “Pyuplift Package - Documentation.” 2018. <a href="https://pyuplift.readthedocs.io/en/latest/index.html">https://pyuplift.readthedocs.io/en/latest/index.html</a>.</p>
</div>
<div id="ref-uplift_approaches">
<p>Lee, Josh Xin Jie. 2018. “Simple Machine Learning Techniques to Improve Your Marketing Strategy: Demystifying Uplift Models.” 2018. <a href="https://medium.com/datadriveninvestor/simple-machine-learning-techniques-to-improve-your-marketing-strategy-demystifying-uplift-models-dc4fb3f927a2">https://medium.com/datadriveninvestor/simple-machine-learning-techniques-to-improve-your-marketing-strategy-demystifying-uplift-models-dc4fb3f927a2</a>.</p>
</div>
<div id="ref-shap_dependence_plot_explained">
<p>Lundberg, Scott. 2018. “Interpretable Machine Learning with Xgboost.” 2018. <a href="https://towardsdatascience.com/interpretable-machine-learning-with-xgboost-9ec80d148d27">https://towardsdatascience.com/interpretable-machine-learning-with-xgboost-9ec80d148d27</a>.</p>
</div>
<div id="ref-feature_importance_shap">
<p>Lundberg, Scott, and Su-In Lee. 2017. “A Unified Approach to Interpreting Model Predictions.” In.</p>
</div>
<div id="ref-shap_dependence_plot">
<p>Lundberg, Scott M., Gabriel G. Erion, Hugh Chen, Alex DeGrave, Jordan M. Prutkin, Bala Nair, Ronit Katz, Jonathan Himmelfarb, Nisha Bansal, and Su-In Lee. 2019. “Explainable AI for Trees: From Local Explanations to Global Understanding.” <em>CoRR</em> abs/1905.04610. <a href="http://arxiv.org/abs/1905.04610">http://arxiv.org/abs/1905.04610</a>.</p>
</div>
<div id="ref-uplift_dataset_modification">
<p>Rzepakowski, Piotr, and Szymon Jaroszewicz. 2012. “Decision Trees for Uplift Modeling with Single and Multiple Treatments.” <em>Knowledge and Information Systems - KAIS</em> 32 (August). <a href="https://doi.org/10.1007/s10115-011-0434-0">https://doi.org/10.1007/s10115-011-0434-0</a>.</p>
</div>
<div id="ref-book_uplift">
<p>Verbeke, W., and C. Bravo. 2017. <em>Profit Driven Business Analytics: A Practitioner’s Guide to Transforming Big Data into Added Value</em>. Wiley and Sas Business Series. Wiley. <a href="https://books.google.pl/books?id=NCA3DwAAQBAJ">https://books.google.pl/books?id=NCA3DwAAQBAJ</a>.</p>
</div>
<div id="ref-4groups_chart">
<p>Yi, Robert, and Will Frost. 2018a. “Pylift: A Fast Python Package for Uplift Modeling.” 2018. <a href="https://tech.wayfair.com/data-science/2018/10/pylift-a-fast-python-package-for-uplift-modeling/">https://tech.wayfair.com/data-science/2018/10/pylift-a-fast-python-package-for-uplift-modeling/</a>.</p>
</div>
<div id="ref-pylift">
<p>Yi, Robert, and Will Frost. 2018b. “Pylift Package - Documentation.” 2018. <a href="https://pylift.readthedocs.io/en/latest/">https://pylift.readthedocs.io/en/latest/</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="story-uplift-modelling.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="story-meps-explainable-predictions-for-healthcare-expenditures.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/compstat-lmu/iml_methods_limitations/edit/master/05_Uplift_marketing.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["book.pdf", "book.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
