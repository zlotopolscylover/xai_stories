[["index.html", "XAI Stories Preface", " XAI Stories 2020-10-14 Preface This book is the result of a student projects for Interpretable Machine Learning course at the University of Warsaw and the Warsaw University of Technology. Each team has prepared one case study for selected XAI technique. This project is inspired by a fantastic book Limitations of Interpretable Machine Learning Methods created at the Department of Statistics, LMU Munich. We used the LIML project as the cornerstone for this repository. The book chapters are written in the Markdown language. The simulations, data examples and visualizations were created with R (R Core Team 2018) and Python. The book was compiled with the bookdown package. We collaborated using github repository. Cover by kozaka93. Creative Commons License This book is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. References "],["foreword.html", "Foreword 0.1 Why? 0.2 What? 0.3 How? 0.4 About academic partners 0.5 About business partner", " Foreword Author: Przemyslaw Biecek (Warsaw University of Technology and University of Warsaw) 0.1 Why? Machine learning has a number of applications. Very often, however, machine learning predictive models are treated as black boxes which can be automatically trained without worrying about the domain in which they are used. This opaqueness rises many risks that are difficult to foresee during the model building process. Such as the model’s declining performance due to the data drift, poor performance on the out-of-domain problems or unfair biased behaviour learned on historical data. The growing list of examples where black boxes fail spectacularly has led to an increased interest in XAI methods. Such methods allow to x-ray black boxes models for more detailed analysis on the local or global level. According to Gartner Hype Cycle for Emerging Technologies in 2019 Explainable AI is on the verge of Innovation trigger and Peak of inflated expectations. It is a technology with a very high potential, which is talked about a lot in the media and which heats up the imagination as strongly as AI. In the literature there are many articles arguing the need to use XAI methods as well as many ideas for new methods from the XAI family. However, it is much more difficult to find examples of successful implementations of XAI methods that have improved the business. Missing elements are case studies of actual use of XAI methods in machine learning problems. Such case studies would allow a better understanding of what is possible today and what is not possible using XAI methods. 0.2 What? This ebook collects examples of the use of different methods from the XAI family for different real-world predictive problems. In the following chapters, we show example applications of different XAI techniques to problems based on real-world public dataset. These examples are called XAI stories and like every good story, each one has a structure. It starts with a description of the predictive problem, goes on to describe the proposed model or models. The models are x-rays using XAI techniques to finish the chapter with a point. 0.3 How? For XAI stories to be credible they need not only a strong predictive model but also business validation of the proposed modeling and an explanation approach. Each group of students was assigned two mentors from data scientists and experts within McKinsey Digital: a consultant and a data scientist. The mentors, together with the students, searched for the strengths and weaknesses of XAI applications in specific problems. At McKinsey Digital, we help our clients create change that matters—transformation, enabled by technology and sustained through capabilities. We drive transformation and build businesses by bringing together the capabilities needed to help organizations grow and thrive in the digital age. We help our clients harness the power of data and artificial intelligence, modernize core technology and capitalize on new technology, optimize and automate operations, fuel digital growth, create stunning digital experiences, and build digital talent and culture. 0.4 About academic partners The Faculty of Mathematics and Information Science, Warsaw University of Technology The Faculty of Mathematics and Information Science offers studies in data science at the level of the bachelor degree, master degree and doctoral studies. The study program includes a powerful dose of mathematics and programming. This book was prepared as part of the Interpretable Machine Learning 2019/2020 elective course. Find more details about MiNI classes, here and about the faculty, here. The Faculty of Mathematics, Informatics, and Mechanics, University of Warsaw The Faculty of Mathematics, Informatics, and Mechanics Department offers a master’s degree with a specialization in mathematical statistics or a specialization in machine learning. The curriculum includes many interesting subjects related to computational statistics or deep learning. This book was prepared as part of the Interpretable Machine Learning 2019/2020 elective course. Find more details about the MIM classes here and about the faculty, here. 0.5 About business partner McKinsey &amp; Company around the world McKinsey &amp; Company is a global management consulting firm committed to helping organizations create Change that Matters. In more than 130 cities and 65 countries, our teams help clients across the private, public and social sectors shape bold strategies and transform the way they work, embed technology where it unlocks value, and build capabilities to sustain the change. Not just any change, but Change that Matters –for their organizations, their people, and in turn society at large. McKinsey &amp; Company in Poland The Polish office of McKinsey &amp; Company first opened its doors more than a quarter of a century ago. Since then we have become the largest strategic consulting firm in Poland, employing more than 1,500 people. We advise Poland’s biggest companies and public institutions and have played a part in the transformation of key enterprises, contributing to the development of companies that today are leaders in banking and insurance, consumer goods, energy, oil, telecommunications, mining and many other sectors. In total we have carried out almost 1,000 projects for our Polish clients. In 2010 we opened our Polish Knowledge Center in Wrocław, where we currently employ almost 250 top analysts. A year later we established a Shared Services Center in Poznań, where over a thousand of our people now work. A McKinsey Digital Lab has been operating in the Warsaw Office since 2017. Our developers, experts in Big Data and business consultants support companies undergoing comprehensive digital transformation and perform advanced data analytics. For more information, visit www.mckinsey.pl. McKinsey Analytics McKinsey &amp; Company perform many engagements with strong analytics components. Our data scientists and architects, together with our machine learning and data engineers, complement our strategic and operational consulting and provide our clients with advanced and robust data-driven solutions. For more information, visit our Polish website and our global website. Explainable Artificial Intelligence at McKinsey &amp; Company The importance of Explainable Artificial Intelligence (XAI) methods was recognized at McKinsey &amp; Company from the beginning. Whenever needed, XAI methods are extensively employed in our analytical engagements. Moreover, McKinsey &amp; Company contributes to the prevalence of XAI methods with its numerous publications and podcasts on this topic; to name but a few: Burkhardt, Roger, Nicolas Hohn, and Chris Wigley. Leading your organization to responsible AI McKinsey Analytics (2019) Chui, Michael, James Manyika, and Mehdi Miremadi. What AI can and can’t do (yet) for your business. McKinsey Quarterly 1 (2018) Chui, Michael, Chris Wigley and Simon London. AI Ethics in today’s world. The McKinsey Podcast (2019) "],["story-house-sale-prices.html", "Chapter 1 Story House Sale Prices: eXplainable predictions for house sale 1.1 Introduction 1.2 Data 1.3 Model 1.4 Explanations 1.5 Use case of the model 1.6 Summary and conclusions", " Chapter 1 Story House Sale Prices: eXplainable predictions for house sale Authors: Piotr Grązka (SGH Warsaw School of Economics), Anna Kozak (Warsaw University of Technology), Paweł Wicherek (Warsaw University of Technology) Mentors: Mateusz Zawisza (McKinsey &amp; Company), Adam Zmaczyński (McKinsey &amp; Company) ‘’That’s all your house is: it’s a place to keep your stuff while you go out and get more stuff.’’ George Carlin Take-away messages 1.1 Introduction Everybody needs a roof over their heads. It can be a house, a villa, or a flat. Everybody, at some point in life, faces a choice whether to buy a house, and if so, which one. And why are they so expensive? The topic of real estate is not only the topic you just have to deal with. It can also be very interesting. There are plenty of TV Shows, for instance, Property Brothers, of which plot is based on examples of people buying and renovating houses. This particular one is the most famous in the world and has been running already for almost a decade. For many people houses are also an investment that generates profits. Regardless of motives of buying and selling real estate, both sides agree on a price. It is always good to know how much a house is worth, what is the expected transaction price. Furthermore, it may be even more important why is the price like that, what has an impact on it. In this work, we want to find an answer to both questions with a stronger emphasis on the latter. This paper intends to be a comprehensive use case of how to deal with a regression problem for Data Scientists. Let us start with a couple of questions that allow to define and understand problems regarding house pricing. The seller does not know how to increase the value of the apartment so that the investment outlay is lower than the added value (e.g. building a pool may increase the price and renovating the bathroom is not worth it). The seller does not know how much to sell the apartment for (he makes an offer on the portal and does not know if the price is adequate). The buyer does not know how much the apartment is worth (as above, whether the price is adequate). Commercial problem: auction services may be interested in tools to support sellers and buyers (to highlight the sections in the offers that most affect the price). These are just some of the questions we can ask. As a definition of our problem, we set the property valuation, and through explanations we try to get an answer depending on the position we choose. The structure of this paper is as follows. In chapter 1 we introduce the problem of sale house prediction. Chapter 2 shows original data, transformation of variables and external data. Modelling can be found in chapter 3. In chapter 4 we present global and local explanations. Chapter 5 includes a use case for sellers. Chapter 6 summarizes the work. The diagram (Figure 1.1) presents how the research is organized. FIGURE 1.1: Roadmap of the analyses carried out. We started our work with a literature review. The problem of house pricing is typically explained on a basis of hedonic demand theory. It states that each characteristic of a house (such as size or location) has some contribution in its price. Since our data consists of different features of houses, it fits the hedonic theory. Over the years, the problem of property evaluation was solved in many different ways. Statistical tools used by analysts to explain house prices range from simple linear regression to more complex techniques such as artificial neural networks. In the literature we can distinguish two trends, these are publications describing linear models compared to advanced machine learning algorithms (Din, Hoesli, and Bender 2001) and (Selim 2009). In the (Selim 2009) research, can see an artificial neural network prediction errors as compared to linear regression. We can conclude from Figure 1.2 that we reduce the interpretability to an increase in the quality of model fitting. The second trend in articles is the contribution of machine learning to price prediction (Conway 2018) and (Park and Bae 2015). The authors often consider variables that describe the location of a property as an important element of pricing modeling. These include relationships such as postal codes, distances from public transport (bus stops, subways), parks, or cultural sites (Law 2017) and (Heyman and Sommervoll 2019). FIGURE 1.2: Comparison of performance of linear regression model and ANN (artificial neural networks). The models forecast with a logarithm from the property price. On the x-axis we have the prediction measures, and on the y-axis we have the value of this measure on the set divided into linear model and ANN. We can conclude from Figure 1.2 that in referred research it was possible to reduce interpretability in order to increase the quality of model fitting. The next point was data analysis. We work on a dataset which contains house sale prices for King County, which includes Seattle. It includes homes sold between May 2014 and May 2015. Data available on Kaggle and OpenML. 1.2 Data We analyzed the data, more. Data contains 19 house features plus the price and the id columns, along with 21613 observations. Below the Table 1.1 describes the variables in the data set. TABLE 1.1: Description of variables in the dataset. Variable Description id unique ID for each house sold date date of the house sale price price of each house sold bedrooms number of bedrooms bathrooms number of bathrooms, where .5 accounts for a room with a toilet but no shower sqft_living square footage of the apartments interior living space sqft_lot square footage of the land space floors number of floors waterfront apartment was overlooking the waterfront or not view how good the view of the property was condition condition of the apartment grade level of construction and design sqft_above the square footage of the interior housing space that is above ground level sqft_basement the square footage of the interior housing space that is below ground level yr_built the year the house was initially built yr_renovated the year of the house’s last renovation zipcode zipcode area lat lattitude long longitude sqft_living15 the square footage of interior housing living space for the nearest 15 neighbors sqft_lot15 the square footage of the land lots of the nearest 15 neighbors Another idea of how to enrich our solution was to add external data. Our hypothesis is that the location of the property can significantly affect the price. We therefore also took into account the distance from public transport and the number of cultural facilities within a kilometer radius. 1.2.1 Data preperation Original data from kaggle is in good quality at the start, but we needed to preprocess it to suit our needs. In this section we describe how we prepared ready-to-use text files of the train and test data (train.csv, test.csv). This includes variable transformations, joining external data, records processing. Firstly, we discovered that there are houses that were sold twice, and one house that was sold three times. One can assume that it was bought, renovated and then sold for more. But they have the same explanatory variables, without changes. Each pair (or triple) representing the same house we decide to aggregate into a single row, averaging the price. 1.2.2 External data We decided to add external data. We believe most variables describe the house properly. What we were missing is some spatial information. Except for zip code, we have information about longitude and latitude, but we wanted to explain it in more detail. Why do some locations tend to be more expensive? Maybe it is because of public transport availability. That is why we decided to add a variable describing a distance to the nearest bus or subway stop. Data sources can be found here. There might also be another reason. Maybe some houses are more expensive, because of some interesting places around, like museums, galleries or fine restaurants. Let us call them cultural places. Those places are not only standalone facilities, but they are connected to other infrastructure, which generally should increase the price. This time we decided to look in the neighborhood: we searched for a number of such places in an arbitrarily chosen 1km range. Data was obtained from here. Both of these external data we visualize in Figure 1.3. Stops are shown on the left and cultural places on the right. Each point indicates the location of the property (marked in green). The blue and red points respectively indicate the location of public transport stops and cultural sites. There are 7549 bus stops and 1214 cultural places in this data. FIGURE 1.3: Spatial external data. Stops on the left and cultural places on the right. Each point indicates the location of the property (marked in green). The blue and red points respectively indicate the location of public transport stops and cultural sites. On the x-axis we have longitude values, while on the y-axis we have latitude values. Most of the cultural places are located in the city center. So this column also tells some story how much of the city center does this house have. Since not all of those places are in the city center, then those other points should reflect some local centers. Public transport stops are very dense in the city center, so they even cover house dots on the plot. Outside of the city center, one can also notice bus routes. It is quite clear that not every house has a good connection to public transport. That can, for example, force parents to drive their children where they need to. For some people it can be an obstacle, so they rather be more skeptical about that particular house. We also did several variable transformations. Since the authors use metric system, we changed square feet into square meters. Zip code and waterfront are saved as factors. Further, it is easier for us to interpret the age of a building rather than a year when it was built. We also know if and when a house was renovated. We can also analyze relative age, that is the time which has passed since the last renovation (variable since_renovated). We chose natural logarithm of price as target variable, since we want to work on a relative scale - we assume that the random error is multiplicative. The last step was dividing the data into train and test samples randomly with a ratio 70/30. Ready script for processing the original data from kaggle can be found on GitHub. For spatial data analysis, we used a short script geofast. Distances between two arbitrary points on earth can be obtained from the geopy (Esmukov 2020) package for Python. However, general and precise formula is computationally expensive. With a simple trick, it can be adjusted to our case without losing almost any precision. This can be done by providing distances to measure are not exceeding several hundred kilometers. The original idea was published here. 1.3 Model Based on the literature we decided to test linear regression models and machine learning models. Below is a list of models that we are considering. linear regression fixed effects model mixed effects model decision tree random forest gradient boosting xgboost We collected methods to evaluate the performance of the regression model and decided to use RMSE (root mean square for our models’ assessment). 1.3.1 Linear models Inspired by literature, we started our analysis by building a white-box linear model. The aim was not to build an ideal model, but rather to get an insight into the relationships in the data and to have a point of reference for more complex models performance and interpretations. Based on economic interpretation, we chose the natural logarithm of price as the dependent variable. The continuous variables characterizing areas were also transformed with natural logarithm. Variables referring to latitude and longitude were omitted since they are unlikely to have a linear effect on price. Instead, zip codes were used to model geographical effects. To avoid collinearity with years since renovation variable, age variable was omitted. 1.3.1.1 Log-log linear model Three versions of the model were estimated. The first model ignores information about house location almost completely (part of this information is carried only by variables such as distance to the nearest bus stop). It assumes that the price of a house in the city center is driven by the same effects as the price of a house in the suburbs. One could argue that this assumption is almost never true, and instead, the data should be modeled by the panel or spatial techniques. 1.3.1.2 Fixed effects model Taking this into consideration, we developed a second model that allows for prices of houses belonging in different zip codes to have their own intercept. The underlying assumption is that the closest area of houses will have a fixed effect on their price. It is the same model as before but with new binary variables (in number equal to a number of zip codes - in our case: 70) indicating whether a house belongs to a certain zip code or not. 1.3.1.3 Mixed effects model A neighborhood, however, can also have an impact on the effect of the particular variables on price. Increasing an area of a house can have a different impact on its price, depending on whether the house is located in the city centre, or in the suburbs. The final model takes this argument into consideration, allowing for houses in different zip codes to have different slopes coefficients for certain variables. Technically, those differences are modeled as random deviations from the general effects. The model was estimated using lme4 (Bates, Maechler, and Bolker 2020) package in R software. The choice of variables that include random effect was made arbitrarily, to reduce the complexity of the problem. Only variables for which a random deviation of their impact could be easily interpreted were chosen (e. g. view importance can vary between geographical locations, since the views themselves are different). We are aware that one could find different approaches that could better fit the data. However, since our scope was not to maximize fit, and no further analysis yielded considerably different results, we decided to limit the consideration to the three models presented. 1.3.2 Linear models assessment Estimated coefficients are presented in the Table 1.2. All of the estimates (apart from m_2_lot_log in first model) are statistically significant on at least 1% level.Since the dependent variable is the logarithm of price, the coefficients have an interpretation of a percentage change. For variables intercept to since_renovated a 1 unit change results in a coefficient *100% change of dependent variable. For variables that were logarithmized (m_2_lot_log to m_2_lot_15_log) a 1% change results in a coefficient % change of dependent variable. Looking at the estimates, a couple of general observations can be made. Firstly, there are no major differences in the coefficients between models, especially between (2) and (3). This tells us that the models can be considered stable. Basing on RMSE, we should note a significant improvement of fit resulting from introducing zip code-based fixed effects in the model (2). A slight, but noticeable improvement was also made by allowing for coefficients to have a random effects in the model (3). These observations suggest that our hypothesis about neighborhood having a significant impact on a house price, but also about particular variables’ effect on price, was reasonable. TABLE 1.2: Estimated coefficients for linear models. Model Log-loglinear (1) Fixed effects (2) Mixed effects (3) (Intercept) 8.1531 8.8260(RE) bedrooms -0.0304 -0.0096 -0.0079 bathrooms 0.0579 0.0409 0.0379 floors 0.0293 -0.0339 -0.0186 waterfront 0.4605 0.5208 0.4641(RE) view 0.0559 0.0609 0.0543(RE) condition 0.0495 0.0557 0.0586 grade 0.1886 0.0885 0.0876 dist_stop_km -0.0106 -0.0041 -0.0047 ncult 0.0134 0.0016 0.0026 since_renovated 0.0038 -0.0002 -0.0007 m_2_lot_log 0.0043 0.0727 0.0841(RE) m_2_above_log 0.3257 0.4099 0.3844(RE) m_2_basement_log 0.0446 0.0270 0.0271 m_2_living_15_log 0.2877 0.1729 0.1566(RE) m_2_lot_15_log -0.0314 -0.0126 (RE) RMSE(train) 0.3054 0.1797 0.1707 RMSE(test) 0.3061 0.1801 0.1762 Estimated coefficients can be interpreted rather intuitively. It is not surprising that the area of the house has a considerable positive impact on price. The same can be said about variables characterizing the quality of the property (grade, condition) and its surroundings (view, waterfront). Especially we can note how important access to the waterfront is in Seattle, that is related to the city geography. Since it is more convenient to have more bathrooms in the house, bathrooms coefficient is also positive. Higher distance to bus stop results in a slight decrease in house value, which again is correct with intuitive expectations. The number of floors, which impact is also negative, can be associated with lower convenience. One may be wondering why years passing since the last renovation does not have a great impact on price. It can be explained by the fact that we already include variables characterizing the condition of the building, and with those being constant – years become not much more than number. To further assess the model performance, we may take a look into the residual density (Figure 1.4). Most of the residuals being in (-0,5; 0,5) range means our model makes the biggest error of approximate -40% and +66%. FIGURE 1.4: The distribution of the residuals from the mixed effects (3) model. On the x-axis, we have the rest of the model for the natural logarithm of price. Plotting residuals against the explained variable gives us some more insight into what happened in the model. FIGURE 1.5: Plot the residual for the mixed effect model. The residuals correspond to the difference between the value of the target variable and the prediction from the model. On the x-axis we have the value of the target variable (price logarithm), on the y-axis of the residual, each point corresponds to the observation from the test set. The cyan line indicates local smooths. We can note a lot of points being in the bottom left part of the plot. This tells us that the model overestimated prices of low-valued houses. The residuals cannot be considered normally distributed. The analysis of residuals clearly suggests that there are some other effects in the data that we failed to model with linear regression. These may result from too few variables being taken into consideration, or, what is more, interesting for us in this work – from the relationships in data being complex and nonlinear. In the following sections, we focus on machine learning models that can perform better in complex environments. 1.3.3 Machine Learning models Our main goal, as we mentioned before, is to explain the model of choice. Along self-explanatory linear models included as comparison, we considered models including: decision tree random forest gradient boosting xgboost. As mentioned earlier, the variables zipcode and waterfront were introduced as categorical. Additionally, for the zipcode variable, which has 70 levels, we use one-hot encoding and build models again. The models were built using mlr (Bischl et al. 2016) R package with ranger (Wright and Ziegler 2015), gbm (Greenwell 2019), xgboost (Chen and Guestrin 2016) and rpart (Therneau 2019). For the models the RMSE score was calculated on the training and test set using the R auditor (Gosiewska and Biecek 2019) package.The results are presented in Figure 1.6. The smallest RMSE can be observed for random forest model, xgboost, xgboost with one-hot encoding, and gbm with one-hot encoding. Other models have a greater error. Let us take a look at these four models. FIGURE 1.6: Comparison of model performance by RMSE on training and test set. In the plot the trained models are marked with points, on the x-axis we have RMSE measure for the training set, on the y-axis the RMSE score for the test set, the line stands for RMSE equal on training and test sets. TABLE 1.3: Model results on the training and test set. Model RMSE train RMSE test random forest 0.0793 0.1675 xgboost 0.1077 0.1600 By analyzing the estimated models we obtained the following results. The random forest model seems to be overfitted, while the xgboost model is more stable. On the test set, they obtained similar scores. Figure 1.7 shows the density of the residuals, for both models. We see that the xgboost model has greater residuals than the random forest model. FIGURE 1.7: Density of residuals for random forest and xgboost models. On the x-axis, we have the rest of the model for the price without transformation. Comparing the xgboost model with one-hot encoding and gbm with one-hot encoding we see that the RMSE score on the training and test set is very similar. Furthermore, the residual density plot (Figure 1.8 ) is practically identical. TABLE 1.4: Model results on the training and test set with one-hot encoding. Model RMSE train RMSE test xgboost one-hot 0.1208 0.1596 gbm one-hot 0.1303 0.1607 FIGURE 1.8: Density of residuals for gbm and xgboost models. On the x-axis, we have the rest of the model for the price without transformation. 1.4 Explanations In this chapter, wepresent the methods of explainable machine learning models. They allow us to understand the compiled models. Following the plan from Figure 1.1, we continue the analytical approach to the regression problem and show how to apply XAI methods in model evaluation. We want to understand how these models work. At the beginning we start explaining four of them, dropping some along the way. This analysis let us derive the explanations for the three groups (seller, buyer, and ad portal) in the next sections. 1.4.1 XAI for geographical location We want to approach explanations by discovering them. As we write this chapter, there are some ideas on how to organize the explainable machine learning workflow, but they are only emerging. We want to explore XAI tools by experimenting with them. We predict that we may face some dead ends on the way, but that is also informative: one can learn from their mistakes. We not only want to show where we are, but also how we got there. We begin our XAI Story by looking at what kind of tools we have. Some are instance-level, some are dataset-level. Some discuss performance, some discuss predictions. Problem with instance-level tools is that they can be applied to every single instance and there are tens of thousands of them in our dataset. Of course we can choose several ones, but the choice is not obvious. Some suggest analyzing those, in case of which the model has the highest residuals (Biecek and Burzykowski 2019). This to work quite nicely as a bottom-up approach. So why not try to explore the top-down approach in this chapter. Start with four models that had the best scores and see what happens. 1.4.2 Feature importance It is highly unlikely that each of explanatory variables used has the same impact on the prediction. We use Feature Importance to evaluate which variables are important in each model. This measure helps the Data Scientists assess which variables have the greatest influence. Below, in Figure 1.9, we present Feature Importance diagrams for four models that have the best RMSE performance. FIGURE 1.9: Comparison of the importance of the permutation variables for four models with the best RMSE score. Colour indicates the model, each bar shows the difference between the loss function for the original data (dashed line) and the permuted data for a particular variable, the longer the bar the greater the difference. The bars for each model start in a different position on the x-axis, this depends on the value of the loss function for the original data set. The comparison shows that the importance of variables differs across the models. It is reasonable since the method of fitting to the data is different for each model. Regardless of the model, however, variables referring to latitude and area of the house seem to have an important impact on the price. This fact suggests that these two variables are the main components of the house price. We can analyze the impact with more detailed techniques. 1.4.3 Partial Dependence Plots (PDP) The models agree on importance of lat and long variables, which are latitude and longitude (basic knowledge might be memorization resistant: longitude describes horizontal (W-E) position, latitude the vertical (N-S) position). In Figure 1.10 we can see that the models for the long variable are compatible, the partial dependence profiles are very similar. For the variable lat, we can see that the random forest model behaves no differently. Analyzing PDP we can state that the prices of apartments located to the north are, in general, higher than those to the south, and properties located to the west have a higher price prediction than those located to the east. FIGURE 1.10: Partial Dependence Profiles for four models, on the left for the variable lat and on the right for the variable long. Each line corresponds to a PDP for one of the four models. The x-axis shows the values of the variable for lat and long, while the y-axis shows the value of price prediction. The second variable worth investigation is m2_living - house surface in square meters. What we expect is a more or less linear increase. The plot seems to confirm this expectation. With grade, we also expected increasing curves, but not necessarily linear. What is interesting, the price goes much higher, if the grade changes from 5-6 to 8-9. We will discuss this phenomenon in detail in chapter 5. FIGURE 1.11: Partial Dependence profiles for m2_living and grade variables. In both cases we see an increase in the value of the prediction along with an increase in the variable. Each line corresponds to one of the four models. On the x-axis we have values of variables corresponding to m2_living and grade. On the y-axis we see the value of property price prediction. Next, we analyze the zipcode variable, which appears to be crucial for random forest model. In this case, to compare all four models, we need a different approach, since two models used the variable encoded as a categorical variable and the other two with one-hot encoding. For models with the zipcode categorical variable, we can see that for the random forest model there are regions for which price prediction is significantly higher than in the others, while for the xgboost model the zipcode variable has no major impact on the price prediction of immovable property Figure 1.12. FIGURE 1.12: PDP for the zipcode variable. At the top, a comparison of the PDP for models with the zipcode variable as categorical. On the x-axis the value of the zipcode variable, and for the y-axis the value of property price prediction. In the lower chart we have a comparison of PDP for gbm and xgboost models with one-hot coding for three selected zipcodes. On the x-axis the value of the variable (0 when the property is in another zip code area, 1 when it is in that zip code area). On the y-axis the value of the real estate price prediction. Let us continue with models that use one-hot encoding of the zipcode variable. We generated all PDP plots and looked at all of the pairs for xgboost_onehot and gbm_onehot for every zipcode. Since there are far too many of them to present, we decided to select only the interesting ones. It turns out that for most of the pairs we observe similar results, but not for all of them. As an example, let us take a look at zipcodes 98010, 98106, and 98018 in Figure 1.12 and 1.13 – we found them on the map. FIGURE 1.13: On the map of Seattle, the zip codes for which PDP was drawn in Figure 2.12 are marked. As we can see, the first two areas are close to the city center, while the last area is far from the center. After a little bit of investigation, victims reveal: in area 98108 there is a loud airport. On the other hand 98010 is far from the city center, there is more space, so people build bigger houses. For instance, in 98010 one can easily find houses with a living area of more than 300m² which is not so common in zipcodes 98106 and 98108. Remember, we were modeling (log of) the price of the whole house, not the price of 1m². There are more examples of variables for which their PDP plots fit our expectations. We can, however, see problems with such variables as age, since_renovated (how many years have passed since a building or last renovation, whichever is less). Figure 1.14 shows comparison of PDP plots for these two variables. The right plot suggests that freshly renovated houses are more expensive, which is reasonable. However, we observe a strange behavior of the random forest model. The left plot may seem surprise: it suggests that the older a house is, the more it costs. This relation can be explained with the fact that older houses tend to be renovated. The rate of renovated houses starts to increase after houses reach 60 years. Half of a century might be a reason to do renovation for sure. To give some numbers: 11% of houses over 60 years old were renovated, and only 0.1% of houses under 40 years were renovated. What is more, since_renovated was more important for all of the models than age. FIGURE 1.14: Partial Dependence profiles for the age variable on the left and for the variable since_renovated on the right. Each line corresponds to one of the four models. On the x-axis there are values of the age and since_renovated variables respectively, while on the y-axis there are values of the property price prediction. For distance to the nearest bus stop PDP plots are shown at Figure 1.15. We trimmed x-axis to 2000 meters, since 92% of observations fulfill that condition. Interesting is, that the shorter distance indicates lower prediction. This is probably due to the fact that larger properties must be located away from public transport stops. FIGURE 1.15: Partial Dependency profiles for the dist_stop variable. Each line is for one of four models. All models behave similarly, the only exception is the random forest model for which PDP is smoother. For properties close to public transport stops (up to 250 meters), the price prediction is slightly lower than for properties at least 250 meters away. 1.4.3.1 PDP summary Most of the PDP plots match our expectations. But there are also variables, where random forest cracks, such as since_renovated, condition, m2_lot, m2_lot15 to mention a couple of them. We guessed that it put far too much attention on the zipcodes rather than other variables, which were incorrectly estimated. That would also explain the huge difference between RMSE on train and test data, Random Forest was overfitted. The other 3 models seem to agree with each other and with so-called common sense. All models are wrong, but Many are usefull, as statisticians say. If three other models agree on the variable effect, it is hard to believe that the other model, which is saying the opposite, is right. At this point, we drop Random Forest and we will not be examining this model from different perspectives. At this point, we also compare two one-hot encoded models, XGBoost and GBM. Their plots are almost identical and they match the XGBoost model without one-hot encoding. So among all 3, we might choose the one with the best score, which is XGBoost. So far we discussed the model-level explanations. The next subsection will focus more on instance-level contemplations. 1.4.4 New possibilities with PDP We went one step forward in the PDP analysis, we looked at the stability of the explanations and a comparison of two types of profiles for evaluating variables in the model. 1.4.4.1 Confidence interval for PDP In the previous subsection, we base our explanations on PDP. A subset of observations is used to construct the PD profile (due to the calculation time). It was interesting for us whether the selection of a subset of observations influences the shape of the PDP. In order to check it, we tested a bootstrap sample size of equal to 100, based on sampling with 500 observations from the test set. Based on the PDP obtained in this way, we constructed a confidence interval, which we calculated as the mean value plus minus standard deviation. In the plots below the results obtained for the 5 variables indicated by the Feature Importance method for the xgboost model. Figure 1.16 shows 100 PDP profiles. As we can see, these profiles are mostly parallel to each other, but there are some values for which they are closer together. FIGURE 1.16: The plot shows 100 PD profiles generated during the bootstrap sample. On the x-axis, we have values of variables and on the y-axis, we have values of prediction. Each line represents one PDP. Based on the PDP obtained, we calculated the confidence intervals. They are illustrated in the 1.17. The blue line is the average of all PDP values at this point, and the grey area is determined, as an approximation of standard deviation. We can now see more precisely that the ranges are not of a constant width for the whole curve. FIGURE 1.17: The plot shows the average PD profile with the confidence interval. The blue line represents the average PDP, while the grey area is the confidence interval. For the x-axis, we have the value of a variable and on the y-axis, we have the value of a prediction. 1.4.4.2 Comparison of Partial Dependence Profiles and Accumulated Local Effects Profiles (ALE) Below we show a list of PDP and ALE . The estimator for ALE profiles eliminates the effect of correlated variables. Since the plot below the PDP and ALE profiles for most of the variables are parallel to each other, it suggests that the model may be additive. To compare the “similarity” of the curves we can use the calculation of the importance of variables based on profile oscillations. For this, we used vivo R package (Kozak and Biecek 2020). FIGURE 1.18: The plots show PDP and ALE profiles for the 5 variables indicated by Feature Importance (Figure 2.9). On the x-axis, we have the values of variables and on the y-axis, we have the value of prediction. The color of the line represents the corresponding profile type. After calculating the importance of variables based on profiles in Figure 1.18, we obtained the following results (Figure 1.19). FIGURE 1.19: A measure based on profile oscillations. The bars indicate the value of the measure and their color corresponds to the profile type. On the x-axis, we have values of the measure and on the y-axis we have variables for which this measure was calculated. We can observe that the values for each variable and profile type do not differ significantly. There is a comparable difference for each variable. This confirms our assumption of no interactions between these variables in the model. An oscillation measure can be used as a variable importance measure for PDP profiles, but also for Ceteris Paribus (CP) profiles to determine the importance of variables for prediction for a single observation. 1.4.5 Instance level explanations. This subsection focuses on explaining particular houses. It is definitely not clear which observations should be examined. In the previous subsection, we examined PDP plots to assess whether we can trust the model and it worked out well. Here we start by looking at: houses with high misprediction and houses with highest average price for 1 square meter. Note, the error is measured linearly on the log-scale, so after the reverse transformation, we look for real estates that had high relative misprediction. What is more, in an earlier analysis, among others we considered zipcodes 98010, a quiet area of Black Diamond with Lake Sawyer. To this list, we add zipcode 98039, which is Medina – mostly residential city. Villas there are vast: 56% of them have at least 300m². The reason is that we want to analyze significantly larger houses in their natural environment. We present the most interesting observations in those zip codes also remembering to cover all of the items on our list above. Let us begin with zipcode 98010. Here we present a property that was the second expensive one. We decided to examine this one, instead of the most expensive one because it had the greater error and the first one we could not locate on Google Street View. This house built 23 years ago is of high grade, has 300 square meters surface, and a large garden of 2000 square meters. Predicted value is 667 k$, while the true value is 902.5 k$. Break Down (BD) plot for this estate is presented in Figure 1.20. FIGURE 1.20: Break Down created with R iBreakDown package for hugely mispredicted house. From the top, a vertical line represents the average response of the model, the green and red bars correspond to the contribution of the variable to the prediction. The green ones take positive values, i.e. increase the prediction value, while the red ones take negative values, i.e. decrease the prediction value. The violet bar corresponds to the prediction value for the observation. The numerical values next to the bars inform about the impact. On the x-axis we have model prediction value, on the y-axis we have variables and their values for the observation. It loses a lot of value because of its geographical position (far from Seattle), but gains a lot on grade and surface. As we can find on a map, this particular property actually has access to the lake and should have been marked with waterfront = 1. If it was, the prediction would be 787325 k$, according to the XGBoost model, and that halves the relative error. From the Figure 1.20 we could also conclude, that houses with waterfront = 0 are not losing so much, but they would highly gain when waterfront would be equal to 1. Another conclusion is that there are mistakes in the data frame. Next case is a house in Medina. We chose the one with the highest average price for 1 square meter of the building. In the Figure 1.21 we see Break Down plot for this house. All factors are in favor of this house. It is in a good location, top grade, living surface is enormous, it has a beautiful view, access to Lake Washington, and the neighborhood is wealthy. Predicted value is 3,961 k$, while the true value was 3,640 k$. Interesting and counterintuitive is that one variable has negative effect, and that is floors. This particular house has 2 levels. In the same picture we also plot Ceteris Paribus (CP) profile for this variable, which says that having two floors is actually the best choice for this observation. FIGURE 1.21: On top Break Down plot for a villa in 98038 zipcode. All variables except floor have positive impact on the price prediction. The second plot represents Ceteris Paribus profile (cyan line) for floor. The dot indicates our observation. The shape of the profile implies that no greater prediction can be obtained for this variable value. 1.5 Use case of the model Having model trained, tested and explained, here comes the time for use cases. First application might be someone who wants to buy a house and improve it to either sell with income, either move in and live in good standard. With model and support of XAI tools there are several ways one can benefit. First approach is that one can study a BD Plot for a particular house and see the loss caused by low grade value. If the influence is highly negative, then we calculate a prediction for the same house, but after renovation: that means with replaced grade value and since_renovated set equal to 0 or 1. That might be very useful in case a buyer has already selected some area of interest and choice between houses is narrowed to a couple of them. In case we only look for houses to renovate and resell with income and specific location is not an issue, then we present a second approach. Here PDP plot can be used. In the Figure 1.22 PDP is monotonically increasing and the greatest change is between grade &lt; 6 and grade &gt; 8. So we can search for houses with such grade, calculate the prediction for modified data and then search for houses with top uplift. We also see that skipping grades 6-8 we also jump from “below average” to “above average”, what can be seen in the histogram attached. FIGURE 1.22: Partial Dependence Profile for grade for xgboost model on left. The blue line corresponds to PDP, for the x-axis, we have the value of a variable and on the y-axis, we have the value of a prediction. On the right histogram of grade, the x-axis indicates the value of the variable, the y-axis a count of observation in each value of grade. We clearly see that prices change drastically when grade goes up from below 6 to above 8. Here we present both approaches in a case study. Using the second method we found for an 85m² house in Kent, WA 98032: 105 year old building, never renovated. 3 bedrooms, 1 bathroom. Grade is 5. Prediction is quite accurate: true value is 176.5 k$ and prediction is 168 k$, so relative error is 5%. Modification described in the previous paragraph results in prediction for 272 k$, 100 k$ more. Of course this predicted change should be compared to renovation cost. In Figure 1.23 there are presented BD plots for this house before and after renovation. FIGURE 1.23: On top Break Down plot for a house potentially good for renovate-and-resell. The impact of the grade variable is negative, the price of the property is decreasing. The second plot, the grade variable have a greater value and since_renovated variable is equal 0. The impact of these variables is positive on prediction. Break Down plot for a house potentially good for renovate-and-resell. When computing the second plot, the same order of variables was used as for the first picture for better comparison. Note that using Ceteris Paribus profile is not exactly correct. Interpretation is that only grade is changed, but renovation also should trigger since_renovation to set to 0. Another application of this model and XAI is at a portal with sell-buy announcements. Portal might be interested in what are the key features that determine the price (where Feature Importance plot can contribute). Then using those important variables, portal can improve searching tools (filters) on the website. Another use for portal is to predict the value based on the features of the house. Then when an user enters an incorrect value (by mistake) it might warn them. Or, on the other hand, if they enter a price higher than predicted, then portal might offer them to promote the offer. 1.6 Summary and conclusions XAI methods are very useful in the work of Data Scientists. They allow us to assess how black box models work. Thanks to this we can compare values obtained between interpreted and complex models. These methods can show what needs to be corrected or improved in the assessment of the global model. The main message from our analysis is the importance of the property’s location and its usable area when setting the property price. It is also worth focusing on local explanations. This allows us to find out what influenced the decision for this particular observation (property). In case of selling the real estate, we can explain what characteristics of houses determine their valuation. Looking at the local explanations the seller can assess how much he can increase the price of his property after a small renovation (we show in our use case). Additionally, in our article we introduce confidence intervals for Partial Dependence profiles, it is a new branch of XAI, we did not encounter in the literature such an approach to check the stability of global explanations based on these profiles. Looking at the whole project in retrospect, the biggest challenge we faced during our work was planning the next steps of analysis, modelling and explanation. At the beginning, we spent a lot of our time on developing an action plan and planning the work. While working on this chapter, we certainly learned to have a business perspective on the analyses we prepared. We owe this knowledge to our mentors, Mateusz and Adam, thank you. References "],["story-hotel-booking.html", "Chapter 2 Story Hotel Booking: eXplainable predictions of booking cancellation and guests coming back 2.1 Introduction 2.2 Booking Cancellation 2.3 Repeated guests 2.4 Summary and conclusions", " Chapter 2 Story Hotel Booking: eXplainable predictions of booking cancellation and guests coming back Authors: Domitrz Witalis (MIM), Seweryn Karolina (MiNI) Mentors: Jakub Tyrek (Data Scientist), Aleksander Pernach (Consultant) 2.1 Introduction The dataset is downloaded from the Kaggle competition website https://www.kaggle.com/jessemostipak/hotel-booking-demand. This dataset contains booking information for a city hotel and a resort hotel in Portugal, and includes information such as when the booking was made, length of stay, the number of adults, children, babies, the number of available parking spaces, chosen meals, price etc. There are 119 390 observations and 32 features. Below you can find features which were used in modelling. Furthermore, feature arrival_weekday was added. Feature Description hotel Resort hotel or city hotel is_canceled Value indicating if the booking was canceled (1) or not (0) lead_time Number of days that elapsed between the reservation and the arrival date arrival_date_month Month of arrival date arrival_date_week_number Week number of year for arrival date stays_in_weekend_nights Number of weekend nights (Saturday or Sunday) the guest stayed or booked to stay at the hotel stays_in_week_nights Number of week nights (Monday to Friday) the guest stayed or booked to stay at the hotel adults Number of adults children Number of children babies Number of babies meal Type of meal booked is_repeated_guest Value indicating if the booking name was from a repeated guest previous_cancellations Number of previous bookings that were cancelled by the customer prior to the current booking previous_bookings_not_canceled Number of previous bookings not cancelled by the customer prior to the current booking booking_changes Number of changes made to the booking deposit_type Indication on if the customer made a deposit to guarantee the booking. Three categories: No Deposit – no deposit was made; Non Refund – a deposit was made in the value of the total stay cost; Refundable – a deposit was made with a value under the total cost of stay days_in_waiting_list Number of days the booking was in the waiting list before it was confirmed to the customer adr Average Daily Rate as defined by dividing the sum of all lodging transactions by the total number of staying nights required_car_parking_spaces Number of car parking spaces required by the customer total_of_special_requests Number of special requests made by the customer (e.g. twin bed or high floor) market_segment Market segment designation. customer_type Contract - when the booking has an allotment or other type of contract associated to it; Group – when the booking is associated to a group; Transient – when the booking is not part of a group or contract, and is not associated to other transient booking; Transient-party – when the booking is transient, but is associated to at least other transient booking distribution_channel Booking distribution channel. The booking website has information about these reservation characteristics and building models can help this company in better offer management. The most important information could be the prediction of booking cancellation, the prediction if client comes back to the hotel, the prediction whether client orders additional services (eg. meals), customer segmentation. In this project, we have decided to focus on two first issues. 2.2 Booking Cancellation The main aim of this chapter is to build model which predicts whether guest cancels reservation and use some explanation methods to analyze the reasons of customer behavior. 2.2.1 Booking Cancellation: Model In order to predict probability of booking cancellation XGBoost model has been fitted. Table below details the split of dataset. Train Test Number of observations 89542 29848 Number of events 33137 (37%) 11087 (37%) Bayesian optimisation with TPE tuner has been applied in order to improve model performance. Neural Network Intelligence (NNI) package has been chosen for this task, because it provides user-friendly GUI with summary of experiments. List of optimized hyperparameters and chosen values: max_depth - the maximum depth of tree (4), n_esimators - the number of trees (499), learning_rate - boosting learning rate (0.1), colsample_bytree - subsample ratio of columns when constructing each tree (0.78). Figure 2.1 below shows ROC curve of the chosen model. The essential advantages of the model are high AUC and the lack of overfitting. FIGURE 2.1: XGBoost: ROC curve In order to compare blackbox model with an interpretable model a decision tree classifier was trained. It turned out that splits were made by features which are also important in the blackbox model (XGBoost). More details on this are given below. FIGURE 2.2: Decision Tree: ROC curve FIGURE 2.3: “White box” model of booking cancellation: decision tree Let’s take one observation and analyze prediction of two models. We have chosen observation number 187 with features values shown in the table below. Both models predicts high probability of booking cancellation (Decision Tree: 0.9940, Xgboost: 0.9982). We will comment on the readability of the decision tree explanation by plotting the tree later. Feature Value Feature Value hotel 0 arrival_date_month 9 lead_time 321 arrival_date_week_number 36 arrival_date_day_of_month 3 stays_in_weekend_nights 0 adults 2 children 0 babies 0 meal 0 market_segment 4 distribution_chanel 3 is_repeated_guest 1 previous_cancellations 1 previous_booking_not_canceled 0 booking_changes 0 deposit_type 0 days_in_waiting_list 0 customer_type 3 adr 62.8 required_car_parking_spaces 0 total_of_special_requests 0 arrival_weekday 2 FIGURE 2.4: Break down plot explaining prediciton of chosen instance FIGURE 2.5: LIME plot explaining prediciton of chosen instance We can see that explanation of XGBoost model says that features chosen in decision tree have also influence on prediction in XGBoost model. As illustrated in the figure 2.6 if chosen client had not canceled reservation in the past, they would be less likely to cancel this reservation. What is more, if the client had booked hotel later, they would have known their plans better and it would decrease probability of cancellation. Maybe the client canceled booking because of big family event, accident or breaking up with partner (booking for 2 adults). It is impossible to predict those events in advance. FIGURE 2.6: Ceteris Paribus plot explaining prediciton of chosen instance What is the lesson from this example? The performance of the decision tree is worse than XGBoost, so if the explanation of blackbox model is intuitive it is better to use model with higher AUC. 2.2.2 Booking Cancellation: Explanation, dataset level FIGURE 2.7: Feature importance of XGBoost model Figure 2.7 presents the feature importance. The list of five most important features contains deposit_type and previous_cancellations. Intuition suggests that these are important variables in such a problem. There are also variables required_car_parking_spaces, total_of_special_requests, market_segment that will be analyzed later. FIGURE 2.8: Summary of SHAP values of XGBoost model Figure above shows SHAP values. There are some interesting findings which are intuitive: Clients who canceled some reservations in the past are more likely to cancel another reservation. People who buy refundable option cancel reservations more often than others. A lot of days between reservation time and arrival time increases probability of cancelling booking. The longer trip, the higher probability of cancellation. There are also less intuitive findings: Trip personalization (parking spaces, special requests) makes prediction of cancellation be lower. People without any special requests cancel reservation more often than others. If trip starts at the end of the week there is higher probability that customers change their minds. The higher number of adults, the higher probability of cancellation. The probability of cancellation is lower if it is hotel in the city instead of resort hotel. 2.2.3 Booking Cancellation: Explanations, instance level The lowest prediction of cancellation probability FIGURE 2.9: SHAP values and break down plot of XGBoost model for instance with the lowest probability of booking cancellation FIGURE 2.10: SHAP values and break down plot of XGBoost model for instance with the lowest probability of booking cancellation The prediction of probability of cancellation equals 0. The plot of SHAP values shows that client has booked 1 visit and has not canceled it. The values of features previous_cancelations and previous_booking_not_canceled (0 and 1 respectively) make the probability of cancel be lower. The highest prediction of cancellation probability FIGURE 2.11: SHAP values and break down plot of XGBoost model for instance with the highest probability of booking cancellation FIGURE 2.12: SHAP values and break down plot of XGBoost model for instance with the highest probability of booking cancellation The prediction of probability of cancellation equals 1. In the past client canceled one reservation so it is more likely to cancel another one. 440 days between reservation and arrival date makes the probability of resignation be higher. It is intuitive, because the client could have changed plans. Price per night reduces prediction. The value of 75 € per night is cheap compared to the prices in the dataset. We can guess that due to the low price, it may not be important for customers to cancel booking and wait for a refund. 2.3 Repeated guests The main goal of models and explanations in this section is to effectively predict whether the guest will come to the hotel once more, and better understand the factors affecting it. 2.3.1 Repeated guests: Imbalanced dataset The distribution of the answer for the second problem is noticeably imbalanced (the ratio between number of observations with given answer is around 3%). We tested various methods, which are implemented in imbalanced-learn library, in different settings and found the RandomUnderSampler effective and sufficient for our needs as a data balancer for our main model in the second problem and RandomOverSampler as best balancer to use with simple SGDClassifier. The figure below presents the distribution of is_repeated_guest in the dataset. The ratio of this distribution is approximately 30 : 1. FIGURE 2.13: The distribution of guests that are and are not repeated guest in the dataset 2.3.2 Repeated guests: Model This model is meant to predict if the given guest is a repeating guest or not. For this purpose as our main model we chose the XGBClassifier from xgboost package. As mentioned above we have used RandomUnderSampler to balance the training dataset. When explaining various instances with the LIME explainer (the figure below presents the LIME explanation for the best of our first models) for one of the first models we noticed that the model highly relies on previous_bookings_not_canceled and previous_cancellations parameters. We decided to train a model without using those two variables to let the model focus on the other variables. The best models trained without previous_bookings_not_canceled variable had noticeably worse AUC score of 0.9 in comparison to 0.967 AUC achieved by our best models. Because of high influence on the model we decided to keep both variables. FIGURE 2.14: LIME explanation for the best of the first models As a result of the hyper parameter search we have found the optimal set of hyper parameters including: max_depth - the maximum depth of tree (6), n_esimators - the number of trees (100), learning_rate - boosting learning rate (0.33). FIGURE 2.15: ROC curve for the XGBClassifier The model achieved 0.967 AUC, and the figure above presents its ROC curve. We also trained two simpler models - SGDClassifier and DecisionTreeClassifier. While the SGDClassifier (which had the best performance with increased max_iter parameter and when using RandomOverSampler balancer) had significantly worse results than the XGBClassifier, the DecisionTreeClassifier achieved AUC score of 0.94 with the depth bounded by 4. We will focus on the XGBClassifier later, but for the sake of explanation we present the DecisionTreeClassifier tree here. FIGURE 2.16: Plot of the tree of the DecisionTreeClassifier model Unfortunately one can see that the “explainable by design” decision tree model in not easy to understand without usage of model specific methods. While we could use some tree specific explainers, the model agnostic explanations provide quite easy to understand and can be used with a wide range of complex, and often better performing models. 2.3.3 Repeated guests: Explanations, instance level We first inspected the SHAP values for two interesting instances with different correct answer. The first instance showed us that the model learned that guests coming to the hotel in October are less likely to come back and that the lack of booking changes also affects repeating negatively. This explanations are reasonable, because in contrast to the holiday guests, the non-vacation time guests probably are visiting the hotel because of some other, independent reason, that is not as repeatable as the annual vacations. The similar reasoning can be repeated for the changes in the booking and number of special requests - when one comes to some place to relax, they will probably care more about additional attractions provided by the hotel and people who visit a relaxing place, when it met their expectations, probably will come again. The second guest, that is an adult coming to the hotel regularly (previous_booking_not_canceled) for a weekend (arrival_weekday and stays_in_week_nights) probably will come again for one more weekend, for the same reasons as they came before. FIGURE 2.17: Shapley values for a non-repeating customer FIGURE 2.18: Shapley values for a repeating customer 2.3.3.1 Ceteris Paribus plot the same repeating guest From the Ceteris Paribus plot of lead_time variables for the same repeating guest as before we might get even more insight of the model’s reasoning. It clearly shows that the reservation made a year before the visit is an indicator that the guest will more likely come back. It might be a thing that this particular guest has some independent reason to visit the hotel regularly and they knows about it in advance, so because that reason probably is repeating, than they will probably visit the hotel once more. FIGURE 2.19: Ceteris Paribus plot of lead_time for a repeating customer The nonlinearity of the Ceteris Paribus profile of lead_time might be a clue why we were not able to achieve better results with a simple linear model. This result along with more similar ones may lead to effective feature engendering when focusing on creating less complex models. 2.3.4 Repeated guests: Explanations, dataset level The attempt to understand how important are particular variables for the trained model on the dataset level by calculating Permutational Variable Imporatance gave us a clear insight that the previous_booking_not_canceled variable is clearly the most important one, which is very reasonable, because the guest that have visited the hotel before will probably do it once more, in the future. FIGURE 2.20: Permutational variable importance of most important variables for XGBClassifier 2.4 Summary and conclusions Using XAI methods to examine trained models were useful to understand how the trained models work, and see that the explanations are reasonable enough to use the models, along with the explanations, as a great tool for the experts to give them some interesting insights about their customers behaviours. Moreover, even when explaining the complicated models we can get explanations that are easier to read and interpret than easier models, like a single decision tree. Last, but not least, when examining the models we were able to find a dependencies, that might be a partial reason for lower performance of other very simple, but easy to understand, linear model. "],["story-hotel-booking-cancellations-explainable-predictions-for-booking-cancellation.html", "Chapter 3 Story Hotel Booking Cancellations: eXplainable predictions for booking cancellation 3.1 Introduction 3.2 Problem specification 3.3 Target leak detection 3.4 Bias correction 3.5 Offering different conditions 3.6 Conclusions", " Chapter 3 Story Hotel Booking Cancellations: eXplainable predictions for booking cancellation Authors: Miłosz Michta (University of Warsaw), Kazimierz Wojciechowski (Warsaw University of Technology) Mentors: Maciej Andrzejak (McKinsey &amp; Company), Alicja Jośko (McKinsey &amp; Company) Apr–Jun 2020 3.1 Introduction Imagine you are the owner of a portuguese hotel. You notice that some of the reservations are cancelled on a regular basis. To maximize revenue you plan to practice room overbooking strategy. How exactly would you approach this strategy? How many rooms to oversell? Which customers are most likely to cancel their reservation? What is the probability of cancellation? And most importantly: what is the reason behind the prediction? We will make an attempt to answer this question using explainable machine learning. From the standpoint of a machine learning engineer one might want to find a model that not only is high-performing, but is also based on intuitive insights about the data. A persuasive manager of the facility might want to attempt to offer the booking on slightly different conditions to customers that are most prone to cancel their reservation e.g. by offering a non-refundable booking for customers from Portugal and Germany. It will be of crucial importance to determine which features to tweak to make the booking as secure as possible while trying not to make the customer feel too uncomfortable by insisting on too many changes. To solve this interesting problem we propose instance-specific explainable machine learning techniques. 3.2 Problem specification In this chapter, we will use data from Hotel booking demand (Mostipak 2020) The data contains several information about when booking was made, what is the date of an arrival, how long visitors will stay, where are they come from, how many of them will come, etc. In terms of hotel, we know what type of the hotel is, what is the ADR, the deposit type, agent and company that made the booking or are responsible for paying booking, and much more. Our machine learning task will be classification whether client will cancell their bookings or not. From business perspective, model like this might not be explicite useful, since predicted category should not affect decision of cancellation from the side of company, agent or hotel itself. On the other hand, use of explainable machine learning might give us the most important factors of cancellation process and use them to reduce rate of cancelled reservations. To obtain most reliable results, we have used three different models: LightGBM (Guolin Ke 2017), Naive Bayes and Logistic regression. Each of them has distinct learning procedure and structure, thus our conclusions should not be biased by the choosed model. 3.3 Target leak detection At the beginning, we test how baseline models work without any feature engineering. Suprisingly, all models get 100% accuracy score both on training and validation score. This could mean three things: We are awesome! We are lucky! We have a target leakage in the dataset! Firstly, let’s see partial dependence profiles for each feature. If there is some leakage, then average prediction profile should distinguish itself amoung the others. At first glance, the reservation status feature has strange plot. It looks like we ommit the feature represents almost the same as target. Partial dependence profiles for reservation_status feature using three different models: LightGBM, Naive Bayes and Logistic regression. We had to remove this feature from our dataset even if we loose high performance score, because of laking interpretation power. 3.4 Bias correction Since we have already remove leakage feature, lets figure out which variables are the most important. The most important features for LightGBM, Naive Bayes and Logistic regression in according to Permutation Importance. It looks like, the country of origin is the most important and the most impactful for 2 out of 3 models. The others variables looks reasonable, but logically country should not be the most important feature for predicting booking cancellation. Lets figure out what what is the cause if results like that. Dependency between number of observations (angle) and average prediction (radius) for each country. The Portugal seems to be reason of the bias in the dataset. Around 40% of the data comes from Portugal and their average prediction equals 56%, where the average is around 38%. In this case, we split model on 2 parts: One model for portugals One model for other countries. Accuracy score uplift after splitting data for portugals and other countires. After splitting the dataset in each fold and training two distinct models, we get significant uplift in model accuracy for each model and fold. 3.5 Offering different conditions Here we will attempt to use a instance-specific explainable machine learning techniques in order to provide a similar offer that will reduce the probability of cancellation. We will determine which methods, if any, might be applicable for real-time negotiation. 3.6 Conclusions As you probably noticed, explainable machine learning gives a lot opportunities to validate predictive models, find most insightful facts about data and set new directions to improve our results. Explainaible machine learning methods can be compared to the pointing fingers on every model weakness and to the compass guiding where we should go to improve final outcome. Thank to XAI accomapnied by strong analysis and visualtion, we was able to achieve better results of our models. References "],["story-uplift-modelling.html", "Chapter 4 Story Uplift Modelling: eXplaining colon cancer survival rate after treatment 4.1 Introduction 4.2 Data Preprocessing 4.3 Model 4.4 Explanations 4.5 Summary and Conclusions", " Chapter 4 Story Uplift Modelling: eXplaining colon cancer survival rate after treatment Authors: Aleksandra Łuczak (Warsaw University of Technology), Tymoteusz Makowski (Warsaw University of Technology), Kateryna Shulikova (Warsaw School of Economics) Mentors: Miłosz Dobersztyn (McKinsey), Armin Reinert (McKinsey) 4.1 Introduction In this chapter we will present a model for predicting the time remaining for patients after a diagnosis of colon cancer of medium stage (B/C). We have used the uplift method and a number of explanatory methods such as Feature Importance, Ceteris Paribus and Partial Dependence Profiles, Break Down plots and LIME. We will use data about Chemotherapy for Stage B/C colon cancer from survival package in R. The documentation can be found here, the package can be installed with install.packages(\"survival\") command in R console. After the installation dataset can be accessed via survival::colon command. 4.1.1 What is Uplift Modelling? For classical algorithms in machine learning it is hard to predict causal impact of the event because they are more suited for predicting the results after an action. In some cases, such as a marketing campaign or medical treatment, that causal impact might be extremely important. Due to the possibility of using two training sets (treatment and control groups) by uplift modeling this problem was solved. Uplift modeling is one of the techniques or a branch of machine learning that tries to forecast class probability differences between group exposed to some action or therapy and control group (without that action or therapy). This technique also allows to discover in research those groups of patients for which treatment was most beneficial, so it is commonly used not only in marketing campaigns or medical treatments but also in other customer services. References: Uplift modeling with survival data (Jaroszewicz and Rzepakowski 2014), Uplift modeling for clinical trial data (Jaskowski and Jaroszewicz 2012), Uplift Modeling for Multiple Treatments with Cost Optimization (Zhao and Harinen 2019), Linear regression for uplift modeling (Krzysztof and Jaroszewicz 2018), Ensemble methods for uplift modeling (Sołtys, Jaroszewicz, and Rzepakowski 2015). 4.1.2 Dataset Description We use data from one of the first successful trials of adjuvant chemotherapy for colon cancer. There are two type of treatment: Levamisole is a low-toxicity compound previously used to treat worm infestations in animals and its effects on the treatment of colon cancer have been noted; 5-FluoroUracyl(FU) is a moderately toxic (as these things go) chemotherapy agent. This is the “strongest” one treatment. Both of these medications are given after the cancer excision, it’s adjutant chemistry, that means “extra post-operative”. There are two records per person, one for recurrence and one for death. Dataset contains 1858 observations and 16 features which are described in the 4.1 table. TABLE 4.1: Description of variables found in the dataset with values types from data exploration. Variable Type Description id categorical An id. study categorical 1 for all patients. rx categorical Treatment: Observation, Levamisole or Levamisole+5-FluoroUracyl. sex categorical Patient’s sex: Male or Female. age continuous Patient’s age in years. obstruct binary Stenosis of the colon by the cancer, which is blockage by the tumor. perfor binary Perforation of colon - a flag whether there was a hole in the colon. adhere binary Adherence to the surrounding organs (e.g. bladder). nodes continuous Number of lymph nodes with detectable cancer i.e. during the operation the lymph nodes that were attacked by the cancer are cut out. For the operation to be successful there should be at least 12 lymph nodes. time continuous Days until event or censoring. The time of receiving the treatment is considered to be time = 0, the time that passed in the variable time is the time until death or relapse from receiving the treatment. status binary Censoring status. differ categorical Differentiation of tumour cell (1=well, 2=moderate, 3=poor). The more the better because it is more like colon cells. extent categorical Extent of local spread, what cells did he reach (1=submucosa, 2=muscle, 3=serosa, 4=contiguous structures). The less the better. surg categorical Time from surgery to registration (0=short, 1=long). node4 binary More than 4 positive lymph nodes. etype categorical Event type: 1=recurrence, 2=death. Typically, the survival data includes two variables: the observed survival time (time variable in our dataset) and a binary censoring status variable (status variable in our dataset). The status variable indicates whether the event has been observed (typically denoted by status = 1). However, if the event has not been observed (status = 0) then the true survival time has ben censored, i.e. it is only known that the true survival time is at least equal to time (Jaroszewicz and Rzepakowski 2014). Important remark Please note that this dataset contains censored data. This means that the time variable does not provide exact information on survival time and rather a lower limit for survived time. Therefore the problem should be converted into a classification whether a patient survived more than given time \\(\\tau\\) threshold, i.e. modelling \\(\\mathbb{P}(t \\geq \\tau)\\). However, we did not know how to work with censored data at the time of modelling and we stuck with modelling it as a typical regression problem. Therefore this chapter should not be treated as an example of modelling and rather as an example of creating explainations for uplift regression problem. 4.1.3 Ideas There are many ways to use this data: prediction of the patient’s life expectancy depending on whether they received treatment or not, prediction whether the treatment is effective or not, prediction of the life expectancy depending on the medicine administered. We have decided to focus on the last mentioned approach. There are two approaches for modelling this approach. One of them being classification whether the patient will live longer than given threshold (Jaroszewicz and Rzepakowski 2014) and the second one, on whom we will focus, regression which will yield result by how much the treatment will change the life expectancy. 4.1.4 Why is it worth the hassle? When a patient learns about the colon cancer disease they usually ask “How much more time do I have left he has left?”. And now what? What is the treatment? The doctor may indicate a number of therapies that may be effective, but still be unable to tell how much time there is left or what’s the patient’s expectancy to live. The aim of this model is helping to provide more accurate data and answer the patient’s question and how the treatment is going to change their life expectancy. 4.2 Data Preprocessing We removed columns: id, study, etype, study - due to the intent of regression approach to the problem. The dataset has been divided into: X - all features (without time and rx), y - target variable (time), treatment - rx variable. Distribution of the variable rx is as shown in the 4.2 table. This feature has been categorised. TABLE 4.2: Number of observations with given treatment type. Levamisole Levamisole + 5-FU Observation 620 608 630 4.3 Model To predict model we used algorithms from the package causalml in Python 3. To optimize hyper parameters we used algorithms from the package hyperopt also in Python 3. All notebooks and codes can be found on GitHub. The final model is XGBTRegressor with parameters summarised in the 4.3 table. TABLE 4.3: Final set of parameters used in our model. Parameter Value colsample_bytree 0.8336948571372381 gamma 0.5564260515876811 learning_rate 0.9327196556867555 max_depth 6 min_child_weight 0.45533158266464746 n_estimators 200 This gives as Average Treatment(Lev) Effect \\(74.38\\) and Average Treatment(Lev+5-FU) Effect \\(185.69\\). The average treatment effect (ATE) is a measure used to compare treatments in randomized experiments, evaluation of medical trials. The ATE measures the difference in mean outcomes between units assigned to the treatment and units assigned to the control. In a randomized trial the average treatment effect can be estimated from a sample using a comparison in mean outcomes for treated and untreated units. The treatment effect for individual \\(i\\) is given by \\(y_{1}(i)-y_{0}(i)=\\beta(i)\\). In the general case, there is no reason to expect this effect to be constant across individuals. The average treatment effect is given by the equation (4.1). \\[\\begin{equation} ATE = \\frac{1}{N}\\sum_{i}y_{1}(i)-y_{0}(i) \\tag{4.1} \\end{equation}\\] Where the sum in the (4.1) equation performed over all \\(N\\) individuals in the population. 4.4 Explanations The model we have used created a submodel for each type of treatment. In our case we have gotten two models - one for Lev treatment and the other for Lev+5FU treatment. Therefore we are creating explainations two separate sets of explainations with the methods known to us. Additionally, we will try to show how particular explainations could be used by different users of the models. To start of this chapter we have selected feature importance which seems like a natural choice - checking which variables appear to be bear the biggest contribution to the model’s prediction. 4.4.1 Feature Importance The feature importance plot shown on figure 4.1 represents shows the possible loss of permuting values of given variable. This is an indicator of how important is given variable as the bigger drop-out loss is the more information was lost due to fiddling with the variable. The loss is measured with root mean square. For interpreting the importance we have chosen few subjectively interesting variables. FIGURE 4.1: Feature Importance calculated for both types of treatment. The variables are sorted by the mean drop-out loss across the treatments. The loss function is root mean square. The trait which is shared between the two models presented on figure 4.1 is the age being quite important variable. The plot shows that permuting the age column yields big loss. This can be a suggestion for the doctor using model to select the best treatment to take patients age into account when selecting the treatment. On the other hand the companies developing drugs for cancer treatment can look into the age groups and aim for creating drug treating an age group which possibly lacks such treatment or currently used treatments are ineffective. The second important information we can get from this plot is from looking at the node4 variable. This is a binary value whether the number of nodes is greater than 4. According to our domain knowledge the number of nodes positively affects survivability after the surgery treating cancer. As we can see the drop-out of this variable for the stronger treatment (Lev+5FU) is biggest amongst all the variables. This proves that the information about patient’s sickness history is crucial for selecting correct treatment as high enough number of nodes gives us information about treatment’s efficiency. The last observation we would like to make is how the average dropout in the model depicting Levamisole treatment is higher by about \\(3.5\\%\\). Its hard to reason this trend. One of the ideas that we came up is that the stronger treatment has overall better effect thus it values less particular variables. 4.4.2 Ceteris Paribus and Partial Dependence Profiles The Ceteris Paribus profiles and the average Partial Dependence Profile has been plotted for both of our models on figure 4.2. As we can the those subplots for every variable for the most part don’t get too exciting. That is due to large number of binary variables in the dataset. With this in mind we have decided to focus on the two variables which appear to have the most interesting plots at a first glance. These variables are age and nodes. To get clearer picture of the chosen variables we present the plots just for them on the figure 4.3. FIGURE 4.2: Ceteris Paribus and Partial Dependence Profiles for every variable in the dataset with regard to models representing different treatments. The nodes variable’s plots on the enlarged figure 4.3 appear to be more stable compared to the age. For both treatment types we can observe the flat-out for large values of nodes. The flat-out most likely appears due to the redundancy of too big number of nodes. There is a notable increase in prediction value starting at around value of 10. This aligns with our domain knowledge which states that 12 nodes are really decent amount which increases the chances of successful treatment. Therefore if the 12 nodes are good enough then any more than that neither do contribute to the survivability nor to the model’s prediction. FIGURE 4.3: Enlarged plots from the figure 4.2 of the variables chosen for detailed analysis (age and nodes) with regard to applied treatment. For the age variable the spiked tendency appears to span across all the Ceteris Paribus profiles plotted on figure 4.3. This might be due to the fact that the treatment does not rely on the patient’s age or that the age is highly affected by some other variable. From our analysis we are keen on making the assumption that the first statement in previous sentence is true. With that in mind there are two noticeable spikes - one approximately for 35 and the other for 65. This observation can be interesting from various points of view. The first one is from our - the analysts - perspective. Theses spikes can indicate that certain age groups have higher uplift effect. This can be a crucial information for the doctor which is overseeing the patient. If the patient’s age falls into the age group which copes well with one of the treatments then it can make the choice easier. On the other hand if the patient’s age does not overlap with the spikes then it might be a suggestion to look for different type of treatment than the two we have available here. Finally, this information can be used by pharmacy consortiums. Clearly, there are only two age groups for which the treatment appears to be working better than average. This can give a clear direction which age groups’ treatment should be prioritized during development of new drugs and treatments. Grouped Partial Dependence Profiles To perform more detailed analysis on both doctor’s and consortium’s points of view we have decided to group the profiles by the extent variable. This variable gives information about how far has the patient’s disease progressed. As we can see on figure 4.4 the overall shape of subplots for both variables did not change too much between the different groups. This tendency is kept across the two models we have for the treatments. When it comes to the nodes variable there is a quite distinctive difference between the two treatments - it is the fourth group (XGBTRegressor Lev_4 and XGBTRegressor Lev+5FU_4). The stronger treatment (Lev+5FU) does not stand out from the other groups whereas the weaker treatment falls behind the other groups. This leads to following conclusions: for the patients with highly developed cancer and a metastasis the weaker treatment is simply put - too weak - no matter ho much nodes the patient did have. It is not sufficient to treat this advanced stage of disease with the Levamisole. This is the conclusion the doctors would want to see before making a final choice for treatment. Without this information the assigned treatment might have insufficient effect. FIGURE 4.4: Partial Dependence Profiles of variables age and nodes grouped by the extent variable and shown for both types of treatment represented by two different models. On the contrary the age variable does not show such a single strong trend. However, as we have pointed out before, there are two spikes for ages 35 and 65. What the grouped PDP plot shows is that the spike for age = 35 mostly consists of patients with extent = 3 whereas the age = 65 spike appears to span across all levels of extent variable. This is an insight which couldn’t be given by the average partial dependence profiles. From the data scientists perspective it is an important lesson that the correlation between variables do happen and should be examined thoroughly. For the doctor this information can change the decision to supply given treatment. If the patient falls into age = 35 group but does not have the specific extent which appears to be treated well then it can be a suggestion to turn to some other treatment. On the other hand for the pharmacy it can be a clear sign to analyse why given treatment works for such a specific group. This research can then be used for developing new treatments and improving the life expectancy of cancer patients. Overall the partial dependence profiles give a valuable insight into the entirety of the dataset. We believe that in this particular case, which is regression task measuring treatment, both the average and grouped partial dependence profiles give valuable information on how the treatments work for different target groups. In our case, with the colon cancer data, the best use-cases appear to be the doctors office for selecting right treatment and the research condoned by the pharmacy consortiums for targeting groups which don’t have satisfactory response to treatment. 4.4.3 Instance Level Explainations For the instance level explainations we have decided to focus on a limited number of observations. These observations are taken from set which seemed to provide interesting results during the data exploration process. The two observations which we have selected can be found in the 4.4 table. TABLE 4.4: The two observations selected from the dataset for instance level explainations. sex age obstruct perfor adhere nodes differ extent surg node4 865 0 68 0 0 1 2 1 3 0 0 983 1 56 0 0 0 4 2 3 0 0 Both patients have the same severity of the cancer which is denoted by the extent variable. One of them is a female and the other is male. The older patient’s (age = 68) cancer is adhered to surrounding organs whilst the other’s cancer is not — this is denoted by the adhere variable. Finally, the last difference is in differ variable which is difference between colon cells and cancer cells. To summarize, we have a 68-year-old woman whose tumor adheres to the surrounding organs, but it’s medium advanced because the cell differentiation is small and only 2 lymph nodes with detectable cancer have been found. Let’s call her Mrs. Basia for clarification and article. We also have a 56 year old man whose cancer is quite advanced because he has highly differentiated cancer cells and a large number of lymph nodes. For the purposes of explanations and the article, let us call him Mr. Peter. The Explanations plots have been created for both patients Mr. Peter and Mrs. Basia. For each of the patients there are two different plots. The reason for two different plots is the fact that XGBTRegressor model underneath creates a model for every treatment. Hence we have got one plot for every treatment type there is – in our case Levamisole(Lev) and Levamisole+5-FluoroUracyl(Lev+5FU) – as seen on figures below. 4.4.3.1 Break Down The Break Down charts show how the given values of variables influence the model result, i.e. which value influences positively (negatively) and how much positively (negatively). This allows us to examine which aspects of a given patient are crucial in a given treatment or which may disqualify him/her from a given treatment. Understanding these aspects may help the doctor who selects the treatment for the patient, but it may also help to outline the situation in which the patient finds himself, so that he has more knowledge and understanding. In addition, in our case we see a comparison between the two types of treatment, this can also help the decision making process of treatment, and it could be used by pharmaceutical companies when introducing a new drug to the market - by comparing the ‘old’ and ‘new’ drug. Thus, modern treatments could be applied to more patients. FIGURE 4.5: Break Down plots for Mrs. Basia. The left plot represents model using Levamisole treatment and the right one represents model using Levamisole+5-FluoroUracyl treatment. On the figure 4.5 For the treatment of levamisole (left) we can see that age, gender and the fact that Mrs. Basia’s cancer comes to the surrounding organs has a very negative impact on the prognosis. However, a small number of lymph nodes with detectable cancer and the fact that Mrs. Basia wants to start treatment immediately after the operation has a very positive effect. Finally, we can see that if Mrs. Basia decided to treat Levamisole, it would unfortunately harm her, perhaps it would be because the medicine is too weak and would not harm the cancer, but Mrs. Barbara’s general health. To the right of the figure 4.5. we have predictions assuming Levamisole + 5-FluoroUracyl treatment here we see that the variables that negatively influence the result are also age and adhesion to the surrounding organs, but note that here gender and tumor differentiation have a positive influence on the prediction. Besides, the final result is higher than the Levamisole treatment. We can see that using a stronger medication here would have better results. Such an accurate picture can help the doctor to decide which medicine to choose and why. Besides, in conversations with the patient, specific numbers, data and graphs would have a calming effect and the patient would feel more confident and, as we know, mental health is as important as physical health. FIGURE 4.6: Break Down plots for Mr. Peter. The left plot represents model using Levamisole treatment and the right one represents model using Levamisole+5-FluoroUracyl treatment. On the figure 4.6 for the treatment of Levamisole (left) we can see that Mr. Peter’s condition is very serious, because all the variables except for the fact that the tumor does not adhere to the surrounding organs cause such low prediction. From the general description of Mr. Peter’s condition we do not see that he reacts so badly to treatment. The doctor treating the patient, seeing such a chart, immediately knows that Levamisole treatment must be excluded. It also says about it a very poor result of prediction, over 1500 lost days, if the doctor and the patient would decide to treat Levamisole. Now let’s look at the graph on the right, it talks about how the individual attributes of Peter influence the prediction of whether his condition will improve. Seeing the prediction, i.e. more than 800 lost days, we know that this treatment is also not worth using for Mr. Peter. Let’s take a closer look at this chart. Unlike the previous treatment, the influence of age is much more visible, more than 200 times worse will Mr. Peter react to stronger treatment than to weaker one. The fact that Peter’s tumor has not spread to the surrounding organs has a positive effect in both treatments. The positive effect in the treatment of Levamisole+5-FluoroUracyl is the fact that immediately after the operation Mr. Peter came to the treatment and the fact that during the operation at least 4 lymph nodes with detectable cancer were excised. None of the proposed treatments are satisfactory in Mr. Peter’s case. 4.5 Summary and Conclusions Explanation methods help to understand not only the operation of the models that can be used by the data analyst (Feature Importance, PDP, Cateris Paribus), but also indicate which variables influence the result and why they are important (Cateris Paribus, Break Down). The second aspect can be used by the doctors guiding the patient in the treatment, but also by pharmacists launching a new drug on the market, or researchers in clinical trials. These are people who need clear and transparent graphs to understand the essence of prediction and the impact of a specific variable on the model, and the XAI methods provide this possibility. In the Uplifts problem, the model architecture plays an important role. It should be remembered that there are two predictions in one model, and at the end they are subtracted from each other, to know how much we will improve our result if we use a given drug compared to not getting any drug. It is not easy to show the results of such a model and there are many limitations. For example, using the LIME method would not be advisable here, because this method is not additive. Subtraction of the factors returned by LIME would not give any information. It is not enough to use whatever explanations you want, you have to choose the right methods for the problem. In uplift, only the additive methods will bring some value. In this chapter we have dealt with a few selected methods (FI, PDP, CP,BD), but there are still many methods that could be examined, including SHAP values. References "],["story-uplift-marketing1.html", "Chapter 5 Story Uplift Modeling: eXplainable predictions for optimized marketing campaigns 5.1 Introduction 5.2 Dataset 5.3 Model exploration and metrics 5.4 Explanations 5.5 Conclusions 5.6 Summary 5.7 Future works", " Chapter 5 Story Uplift Modeling: eXplainable predictions for optimized marketing campaigns Authors: Jan Ludziejewski (Warsaw University), Paulina Tomaszewska (Warsaw University of Technology), Andżelika Zalewska (Warsaw University of Technology) Mentors: Łukasz Frydrych (McKinsey), Łukasz Pająk (McKinsey) Key points: uplift models thanks to linear definition give wide range of possibilities while using XAI SHAP values can be used to explain model both in local and global aspects - they can be generalized in order to estimate Variable Importance and Dependence Plots in the case of analysed dataset, marketing campaign should be sent two months after last purchase to be the most effective XAI analysis can help in creating personalized marketing campaigns 5.1 Introduction Running a business is a challenge. It involves making a lot of decisions to maximize profits and cut down costs - finding the tradeoff is not a straightforward task. Here come Machine Learning and uplift models that can help in optimizing marketing costs. It is widely believed that it is a good idea to send marketing offer to all company’s customers. From one point of view, we think the probability that the customer will buy our product is higher - in fact it is not always the case (the matter will be described in details later). On the other hand, making a large-scale campaign is costly. Therefore, it is important to consider in decision-making what is the Return on Investment (ROI). Is it true that by sending the marketing offer we only increase the chance for the customer to buy our product and therefore extend our profit? The issue was already investigated (Verbeke and Bravo 2017) and it was pointed out that customers of any company can be divided into 4 groups (Figure: 5.1). FIGURE 5.1: Customer types taking into consideration their response to treatment (Yi and Frost 2018a) The matrix (Figure: 5.1) was created based on customer decision to buy a product depending on the fact that they were addressed by a marketing campaign or not. The action used for triggering in customers the particular behaviour is called treatment. In the 4 groups we distinguish: ‘persuadables’*: the customers that without being exposed to marketing campaign would not buy a product ‘sure things’: the customers that irrespective of the fact that they experienced treatment or not are going to buy a product ‘lost causes’: the customers that irrespective of the fact that they experienced treatment or not are NOT going to buy a product ‘sleeping dogs’: the customers that without being exposed to marketing campaign would buy a product but in case they receive a marketing offer they resign It can be then observed that in case of ‘lost causes’ and ‘sure things’, sending a marketing offer makes no impact therefore it doesn’t make sense to spend money on targeting these customers. As the company, we should however pay more attention to the groups ‘persuadables’ and ‘sleeping dogs’. In the case of the first group, bearing the costs of the marketing campaign will bring benefits. In the case of the latter, we not only spend money on targeting them but as a result, we will also discourage them from buying the product therefore as a company we loose twice. The case of ‘sleeping dogs’ may seem irrealistic, therefore we present an example. Let’s imagine there is a customer that subscribed to our paid newsletter. He forgot that he pays each month fixed fee. He would continue paying unless a company sends him a discount offer. At this moment, the customer realizes that he doesn’t need the product and unsubscribes. By understanding the structure of the customers, company can target its offer more effectively. 5.1.1 Approaches towards uplift modeling In (Akshay Kumar 2018) it was pointed out that the problem of deciding whether it is profitable to send an offer to a particular customer, can be tackled from two different perspectives: predictive response modeling (it is common classification task where model assigns a probability to each of the classes) uplift modeling (where the ‘incremental’ probability of purchase is modeled) The latter is tailored to this particular task and is more challenging. Uplift modeling is a technique that helps to determine probability gain that the customer by getting the marketing materials will buy a product. The field is relatively new. The two most common approaches are (Lee 2018): Two Model In this method two classifiers are built. The one is trained on observations that received treatment (called model_T1) and the second is trained on observations that didn’t receive treatment (called model_T0). Later, the uplift for particular observations is calculated. If the observation experienced treatment then it is an input to the model_T1 and the probability that the customer will buy a product is predicted. Next, it is investigated what could happen if the customer didn’t receive treatment. In that case, the treatment indicator in observation’s feature is changed to ‘zero’. This kind of modified record is an input to the model_T0 that predicts the probability that particular customer will buy a product. The uplift is calculated as the difference between the outputs of the model_T1 and model_T0. The higher the difference, the more profitable it is to address marketing campaign to a particular customer. Analogically, uplift is computed for the people that didn’t experienced treatment. One Model This approach is similar conceptually to the Two Model method with such a difference that instead of building two classifiers only one is used. Therefore, every observation is an input to the model that generates prediction. Later, the indicator in the treatment column is changed into the negation and such a vector is used as input to the model that once again outputs probability that the customer buys a product. The uplift is the difference between the two predicted probabilities. FIGURE 5.2: Two Model vs One Model approach (own elaboration), where P1=P(purchase|T=1) and P0=P(purchase|T=0) As uplift modeling is an emerging field there isn’t a clear evidence what method is better to use. 5.2 Dataset There is a scarcity of well-documented datasets dedicated to uplift modeling. Therefore, in (Rzepakowski and Jaroszewicz 2012) in order to extract information about treatment, artificial modifications to available datasets were proposed. As the purpose of this story is to investigate XAI techniques in the domain of uplift modeling, we decided to use real-life dataset. We chose Kevin Hillstrom’s dataset from E-Mail Analytics And Data Mining Challenge (Hillstrom 2008). The dataset consists of 64000 records reflecting customers that last purchased within 12 months. As a treatment, an e-mail campaign was addressed: 1/3 of customers were randomly chosen to receive an e-mail campaign featuring Men’s merchandise 1/3 were randomly chosen to receive an e-mail campaign featuring Women’s merchandise 1/3 were randomly chosen to not receive any e-mail campaign (‘control group’) The following actions were determined as an expected behavior: visit the company’s website within 2 weeks after sending to the customers a marketing campaign purchase a product from the website within 2 weeks after sending to the customers a marketing campaign In the challenge, the task was to determine whether the men’s or women’s e-mail campaign was successful. In order to simplify the problem, we reformulated the task - we have focused on answering the question of whether any e-mail campaign persuaded customers to buy a product. The features about customers in the dataset are specified in Figure 5.3: FIGURE 5.3: Customer features in the dataset (own elaboration) In the dataset, there is also information about customer activity in the two weeks following delivery of the e-mail campaign (these can be interpreted as labels): Visit: 1/0 indicator, 1 = Customer visited website in the following two weeks Conversion: 1/0 indicator, 1 = Customer purchased merchandise in the following two weeks Spent: Actual dollars spent in the following two weeks 5.2.1 Explanatory Data Analysis First, we decided to investigate variables that have more than 3 unique values. At the same time, these variables (recency and history) intuitively seem to be the most important while predicting whether someone will buy a product or not. FIGURE 5.4: Histograms of recency (left) and history (right) It can be seen that history variable has heavy-tailed distribution therefore it may be reasonable to use Box-Cox transformation. However, we decided to keep the variable without any preprocessing for easier interpretation. FIGURE 5.5: Count plots In the case of mens, womens and newbie variables the proportion of 0’s to 1’s is almost equal. There is much fewer records of people living in the countryside than in urban or suburban areas. Most of the company customers buy via phone or web. It is rare that someone uses a mulitchannel option. In the dataset, most of the customers received treatment in the form of marketing E-mail. 5.2.2 Feature engineering The dataset is largely imbalanced - there are only about 15% of positive cases in column Visit and 9% in column Conversion. In such a situation, we decided to use column Visit as a target for the classifier. As the number of columns is small, therefore, we decided to use one-hot encoding for transforming categorical variables instead of target encoding. 5.3 Model exploration and metrics There are not many packages dedicated to uplift modeling in python. We investigated the two: pylift (Yi and Frost 2018b) and pyuplift (Kuchumov 2018). The latter enables usage of 4 types of models - one of those is the Two Model approach. In the pylift package there is the TransformedOutcome class that generates predictions. However, the model itself is not well described and uses XGBRegressor underneath that is not intuitive. Fortunately, the package offers also the class UpliftEval that allows uplift metrics visualization. In the scene, we decided to create own classifier (as in the One Model approach) and use UpliftEval class from the pylift package for metric evaluation. In our project, we used XGBoost classifier. In order to optimize its parameters, we applied the area under the cumulative gain chart (described below) as score function. In the Figure 5.6, we show the cumulative gain chart for train and test sets. FIGURE 5.6: Cumulative gain chart: (left) train set, (right) test set The Qini curve is not suggested for performance evaluation of uplift models as it is vulnerable to overfitting to the treatment label. Therefore, the Cumulative gain chart is used. It is the least biased estimate of the uplift. In the pylift package, it is implemented based on the formula: \\(Cumulative\\ gain(\\phi) = (\\frac {n_{t,1}(\\phi)}{n_{t,1}}-\\frac {n_{c,1}(\\phi)}{n_{c,1}})(\\frac{n_t(\\phi)+n_c(\\phi)}{N_t+N_c})\\) where \\(n_{t,1} (\\phi)\\) is the number of observations in the treatment group at cutoff level \\(\\phi\\) with label 1 \\(n_{c,1} (\\phi)\\) is the number of observations in the control group at cutoff level \\(\\phi\\) with label 1 \\(n_{t,1}\\) is the total number of observations in the treatment group with label 1 (analogically \\(n_{c,1}\\)) \\(N_t\\) is the total number of observations in treatment group (analogically \\(N_c\\)) The theoretical plot is created according to the following scheme: First, the customers are sorted in descending order based on predicted uplift. Later, some fraction of data is taken for the analysis (e.g. 10% of the people with the highest score). This cutoff is represented as \\(\\phi\\) in the formula. Next, the uplift gain is verified for the subset. At the beginning of the curve, the gain is the biggest as it refers to the ‘persuadables’ group. Later, the curve stabilizes as it depicts the groups: ‘lost causes’ and ‘sure things’. At the end the curve decreases as there are ‘sleeping dogs’ with negative uplift. 5.3.1 Model It can be seen that our model is better than random choice but much worse than the practical/theoretical maximum possible. It is also worse than the case without ‘sleeping dogs’. Comparing to uplift modeling in different domains, i. e. medical applications, treatment in marketing has generally smaller impact on individual, therefore dataset itself is more noisy and cumulative gains are smaller. It is also worth noting, that due to small number of features, there are multiple cases in the dataset where two observations with same features have different answers. This kind of noise in data also tremendously impacts the score and requires caution when training models. Also, since uplift itself is an interaction, our model do have to take them into consideration. Considering previous observations, model was found using so called local search procedure, which means that we choose some meta-parameters of the model and iteratively, for every meta-parameter approximate derivative by sampling the local neighborhood of current value and follow the ascending gradient. Local search stops naturally, when in previous iteration, we did not change any parameter, hence we hit one of the local minima. To be clear, if meta-parameter is discrete, by approximating local neighborhood we mean just checking close values. For our score function, we’ve chosen cross-validation on cumulative gains. This kind of procedure should seek for highly robust models. Therefore, it is worth noticing that our model didn’t experience any overfitting as its quality on the train and test sets is similar. The resulting major parameters were: maximum depth of 5, high learning rate of 0.7 and only 12 estimators. 5.3.2 Comparing metrics We tried to employ the same local search procedure (as described in Model section) using accuracy as score function. However, it failed to converge with any decent quality, because this metric is much less informative in case of largely imbalanced dataset. Since only a small number of customers actually made a purchase, it’s hard to correctly predict a positive case using non-overfitted model. Therefore within the local search with accuracy function, starting local neighborhood was always flat. This might be because in the dataset there is more noise than positive cases. But fortunately, only important factor, from our perspective is probability of the purchase, since uplift is an increase of purchase probability after treatment, and it directly transfers into money gain. To visualize it in a straightforward manner, we present a table comparing our current robust XGBoost model with overfitted one (deep trees, 100 estimators). TABLE 5.1: Metrics comparison Model Train accuracy Valid accuracy Train cummulative gain Valid cummulative gain Overfitted XGBoost 0.8755 0.8473 0.7190 0.0204 Robust XGBoost 0.8532 0.8532 0.0398 0.0425 As we can see (Table 5.1) for the overfitted model, cumulative gain drops by 97% while the overfit gap in accuracy scores is only around 2%. 5.4 Explanations The Cumulative gain chart (Figure 5.6) shows that the proposed model brings additional value as its performance is always above random system. Here comes the question of whether the model is reliable. Does it make the decision based on the features that are important from an expert perspective? Such judgment can be done using XAI tools. We decided to investigate model interpretability from instance-level and dataset-level perspective. 5.4.1 Instance-level In order to explain model output for a particular customer, we employed SHAP (SHapley Additive exPlanations) values (Lundberg and Lee 2017). Before we move to the investigation of SHAP values, let’s get to know customers that got the highest and the lowest uplift prediction. In this section, we will analyse the reliability of predictions for these particular instances. In the table 5.2, there is all the information provided to the system about the customers. TABLE 5.2: Customer with the highest and the lowest uplift - features Column.name customer_with_biggest_uplift customer_with_lowest_uplift recency 2.0 5.0 history 228.93 243.95 mens 1.0 0.0 womens 1.0 1.0 zip_code_Surburban 1.0 0.0 zip_code_Rural 0.0 1.0 zip_code_Urban 0.0 0.0 newbie 0.0 1.0 channel_Phone 0.0 1.0 channel_Web 1.0 0.0 channel_Multichannel 0.0 0.0 segment 0.0 1.0 As can be seen (Table 5.2) the customers spent almost the same amount of money during the last 12 months on our company’s products. The person with the highest uplift did last shopping 2 months ago whereas the person with the lowest uplift did it 5 months ago. In the dataset, some people purchased the product for the last time even 12 months ago so the person with the lowest uplift is not the edge case in that sense. Apart from many other differences among the two customers, the key is that the person with the highest uplift received treatment whereas the second customer didn’t. Below we present SHAP values for the customer described in Table 5.2. The values were computed directly on uplift model 5.7. FIGURE 5.7: SHAP values: (left) customer with the lowest uplift, (right) customer with the highest uplift In can be seen that in both cases, big contribution to the final result has information about customer history (about 235 USD) and the fact that the customer bought products from women’s collection. What is interesting, is the fact that the customers have almost the same values of these two attributes but opposite sign of its contribution (SHAP value). 5.4.2 Difference - approach We can benefit from additive feature attribution property of SHAP values to model the uplift: \\(uplift=P(purchase|\\ T=1) - P(purchase|\\ T=0))\\) \\(SHAP(uplift)= SHAP(P(purchase|\\ T=1)) - SHAP(P(purchase|\\ T=0))\\) This property gives us a great opportunity to evaluate these two vectors of SHAP values independently. For example, if we use any tree-based model, we can make use of tree-based kernel for SHAP value estimation (faster and better convergent) instead of modeling it directly as a black-box (uplift) model. In a table 5.3 there is a comparison of SHAP values obtained using two methods for the customer with the lowest uplift. TABLE 5.3: SHAP values obtained using two methods Column_name Uplift_approach Diff_approach recency -0.00593 -0.00535 history -0.27282 -0.27270 mens -0.00961 -0.00928 womens -0.05628 -0.05692 zip_code_Surburban 0.00076 -0.00055 zip_code_Rural -0.03313 -0.03257 zip_code_Urban -0.00148 -0.00179 newbie 0.00365 0.00351 channel_Phone 0.00024 -0.00036 channel_Web 0.00188 0.00200 channel_Multichannel -0.00067 0.00029 segment 0.00010 0.00043 Experimental results proved that these two ways of calculating SHAP values provide similar estimations with precision to numerical errors. There are few features, that depending on the method, have a small positive or negative value. This is caused by the fact that for the estimation of SHAP values directly using uplift model the KernelExplainer was used. The source of randomness is the fact that we took subset of records instead of whole dataset as such behavior is recommended in documentation due to algorithm’s complexity. Also, KernelExplainer is by nature less precise. Nevertheless, we proved that in the case of our example the two methods lead to similar values. The specificity of uplift models in terms of the possibility to analyse them through additivity of SHAP values gives room for another valuable inspection. Below we present how SHAP values differ depending on the fact that the customer was or wasn’t addressed by treatment. On x axis, there are SHAP values in case T=0 and on y axis in case T=1. In each chart, there is SHAP value referring to one variable. In situation when the SHAP values are the same irrespective of the presence or absence of treatment, they would lie on identity line. Moreover, there is color used as third dimension indicating the group that the particular customer belongs to. We decided to merge two groups (‘sure things’ and ‘lost causes’) as they have uplift almost equal to zero, therefore now we can distinguish 3 groups: ‘sleeping dogs’, ‘persuadables’ and ‘sure things and lost causes’. The division was based on the predicted uplift. ‘Sleeping dogs’ have considerable negative uplift, ‘sure things and lost causes’ have uplift in \\([-0.01,0.01]\\) and ‘persuadables’ have uplift greater than 0.01. The group ‘sure things and lost causes’ should have zero uplift, but due to numerical issues we decided to set \\(\\epsilon\\) equal to 0.01. As almost all customers were categorized to ‘persuadables’, we decided to show on the plot only 1000 records from this group to maintain chart readability. FIGURE 5.8: SHAP values on variable recency in case T=0 and T=1 It can be seen that ‘persuadables’ are slightly above and below identity line. FIGURE 5.9: SHAP values on variable history in case T=0 and T=1 In Figure 5.9 the three customer groups are distinctive. It would be interesting whether the result of clustering methods would be similar. We also investigated binary variables. Most of them looked similar as Figure 5.9 but there was one exception - variable womens. FIGURE 5.10: SHAP values on variable womens in case T=0 and T=1 The customer groups on Figure 5.10 are overlapping. They constitute very homogeneous groups. Note: In the case of our model, there is no need to apply LIME as its main advantages - sparsity - is not important when there are only few variables. 5.4.3 Dataset- (subset-) level In order to compute Variable Importance, most of the time the Permutation Feature Importance method is used. Unfortunately, it’s impossible to use this approach directly in our case, because of the previously mentioned problem with lack of full information. We don’t know if the client would purchase product after treatment or he would buy without treatment as well. Because of having in disposal only historical data (not an oracle), we have only one of these two pieces of information. However, we can make use of the previously computed SHAP values of uplift to calculate the same value of permutational feature importance as an average of local SHAP importance (defined in a permutational way itself, however, calculated more smartly (Lundberg and Lee 2017)). We decided to evaluate feature importance not from the well-known dataset-level but from the subset-level perspective. As the subsets we mean 3 customer groups: ‘sleeping dogs’, ‘sure things and lost causes’ and ‘persuadables’. Below we present the Variable Importance plots. The correlations between SHAP values of particular variable and variable itself were highlighted in colors. The red color means a positive correlation whereas blue means negative correlation. FIGURE 5.11: Variable Importance - ‘sleeping dogs’ FIGURE 5.12: Variable Importance - ‘sure things and lost causes’ FIGURE 5.13: Variable Importance - ‘persuadables’ Conclusions: Regardless of the customer groups, always history and womens are among three most important features. For observations with considerable negative uplift (‘sleeping dogs’) both history and womens have negative correlation with their SHAP values. In the case of ‘sure things and lost causes’, womens has positive correlation whereas history has negative. The same variables among ‘persuadables’ (considerable positive uplift) have positive correlation with SHAP values. Correlation changes gradually with uplift value. What is interesting is the fact that regarding zip code only the information whether someone is from rural area is important. Note that this category of dwelling place was the least popular among customers. Information about purchase channel in general has relatively small predictive power. 5.4.3.1 Dependence plots Another tool to investigate model are the dependence plots. There are two options. The most common method is the Partial Dependence Plot (PDP)/ Accumulated Local Effects (ALE) and the other one is the SHAP dependence plot. The Partial Dependence Plot shows the marginal effect that one or two features have on the predicted outcome of a machine learning model (Friedman 2000). It tells whether the relationship between the target and a feature is linear, monotonic or more complex. In the SHAP dependence plot, we can show how a feature value (x axis) impacted the prediction (y axis) of every sample (each dot) in a dataset (Lundberg et al. 2019). This provides richer information than the traditional Partial Dependence Plot, because we have at least two additional information: density and variance of observations. The Partial Dependence Plots reflect the expected output of the model if only one feature value is changed and the rest stays the same. In contrast, the SHAP value for a feature represents how much that feature impacted the prediction for single sample, accounting for interaction effects. So while in general you would expect to see similar shapes in a SHAP dependence plot and a Partial Dependence Plot, they will be different if your model has multi-variable interaction effects (like AND or OR). A PDP has no vertical dispersion and so no indication of how much interaction effects are driving the models predictions (Lundberg 2018). We generated the Partial Dependence Plot for all features and the SHAP dependence plot based on 1000 observations only for history and recency features due to large processing time. FIGURE 5.14: History (left) Partial Dependence Plot / Accumulated Local Effects plot, (right) The SHAP Dependence Plot based on 1000 observations For our model the SHAP Dependence Plot reflects the shape of the Partial Dependence Plot. Contribution of history to the final uplift prediction differs among people with the same value of history. It can be seen that there is a considerable peak on the chart for history value of about 230 USD. However, people that spent such amount of money have various SHAP values - some positive, some negative. This observation is not contradictory to PDP as in case of PDP, we compute the average. Note that on SHAP dependence plot we displayed a sample of size 1000. FIGURE 5.15: Recency (left) Partial Dependence Plot / Accumulated Local Effects plot, (right) The SHAP Dependence Plot based on 1k observations Due to the fact that recency can have only one of 12 values, only 12 ‘clusters’ can be seen on the SHAP Dependence Plot. Dispersion within the ‘clusters’ shows how much the observations in our dataset differ. FIGURE 5.16: Gender PDP It is surprising that the disproportion between the results shown in Figure 5.16 is so significant. In the PDP of mens feature, the lines are almost flat meaning that regardless of the fact whether someone bought or not a product from mens collection the uplift prediction stays the same. FIGURE 5.17: Newbie PDP According to the Figure 5.17, if a person is a newbie, it is harder to encourage him/her to buy a product through marketing campaign. FIGURE 5.18: Dwelling place PDP It can be seen that PDP of zip_code_Suburban and zip_code_Urban look very similar. They both have decreasing trend, whereas PDP of zip_code_Rural has increasing trend. In this case, it can be seen that ALE and PDP crosses. As they aren’t parallel, it means there is a slight interaction in model. FIGURE 5.19: Channel PDP The biggest gain in terms of uplift can be seen in case when the person uses Web channel. The PDP of Phone_channel is flat. 5.5 Conclusions Since Partial Dependence Plots are generally parallel to Accumulated Local Effects, we can safely assume that our model does not have (major) interactions. However, this does not mean that we can use some classifier without interactions, because here we model directly the uplift, which is the difference between predictions and it is an interaction itself. 5.5.1 Sweet-spot The most important observation here, should be that while at first glance we can only manipulate the treatment variable, dependence plots also give us the opportunity to choose best time to contact the customer. Intuitively, recency function should be concave, aiming to find some ‘sweet-spot’ between time when customer ‘just went out from the shop’ and ‘forgot about this’. The Figure 5.15 is indeed concave but only for recency values between 1 and 4. For larger recency there is sinusoidal noise observed. These fluctuations can be interpreted as small overfitting. The key message is that the sweet-spot appears to be two months after the last purchase. 5.5.2 Bigger influence Based on Figure 5.16, bigger influence can be made on customers who bought women’s products than the ones who bought products from men’s collections. Initially we removed from the dataset information about treatment type (Woman’s/Man’s e-mail). But based on Variable Importance analysis (Figures: 5.11, 5.12, 5.13), we can reason about the type of e-mail that maximizes uplift for particular person. Considering how important is womens variable, we propose a following policy: in the case when someone buys from men’s and women’s collections we should send e-mails dedicated to women. 5.5.3 Influence from other factors Other PDPs can be used for better understanding of the customer persuadability. Since the only variable considerably reducing estimated uplift is newbie, we can safely conclude, that marketing campaigns have better impact on regular customers, which is quite an intuitive conclusion. Analysing other factors, one-hot encoded area of living (zip_code_Rural, zip_code_Suburban, zip_code_Urban) do not have influence bigger than statistical error maybe except zip_code_Rural. Customers living on the countryside are more likely to be persuaded. Surprisingly it is the only factor that may have some interactions. Referring to the purchase channel, it is best to target customers who bought only by web in past months. It may be connected to the fact that our treatment is conducted via e-mail. We suspect that in some cases the following situation can happen: someone buys via phone as he doesn’t use the internet often. In such cases e-mail campaigns will not be effective. 5.6 Summary Using XAI for uplift modeling helps to understand its complex models better. The analysis goes beyond just assessing whether the model is reliable. 5.6.1 Individual perspective In the case of our task, individual perspective doesn’t seem to be vital. The situation when a customer writes an e-mail to the company asking why he didn’t receive an e-mail with marketing campaign is highly unlikely. Even if he does, he wouldn’t change his feature like the dwelling area only in order to get the e-mail. The things that the customer can rather easily change are his value of recency or history variable. 5.6.2 Data scientist’s perspective From the data scientist’s perspective the most important thing to check is whether the model is overfitted. The tool that can help in verifying model sensitivity is the Partial Dependence Plot. In the case of our model it can be seen that the model is slightly overfitted as there is a peak on PDP of history. 5.6.3 Executive perspective XAI techniques can help the executives to understand better the company’s customers behavior without paying for some extra surveys to investigate their attitude towards the company. Key findings: The campaign e-mail should be sent two months after last purchase in order to be more effective. The most important variables in the model seem to be reasonable, e.g. history and recency (Figures: 5.11, 5.12, 5.13). The only surprising thing is the high importance of zip_code_Rural feature. In the case when someone buys from men’s and women’s collections we should send e-mails dedicated to women. In the case of bigger number of treatment variants, it would be possible to create personalized marketing campaign. A vital part of our work was adjusting XAI techniques for the particularities of uplift modeling. We found out that thanks to its additivity, SHAP values are well suited for uplift modeling - we showed two methods of using it. We identified limitations of well-known Permutation Feature Importance in terms of explaining uplift models. It is caused by the fact that unlike the other supervised models, here we do not have exactly labels. Therefore. we used the generalization of SHAP values that converge to Permutation Feature Importance. Also, we analysed the SHAP Dependence Plots as an alternative to PDP. We employed the analysis for the three groups of customers based on the corresponding uplift. 5.7 Future works During initial feature engineering, we simplified our problem by merging women’s treatment and men’s treatment into one. By analysing PDP, we were able to propose a policy for choosing the optimal treatment type. However, it is not the only possible approach. We can try going beyond standard uplift modeling and model directly uplift with 2 possible outcomes i.e. create purchase prediction, and then check if sending women’s or men’s e-mail is more profitable, resulting in the following equation: \\(uplift=max{(P(purchase\\ |\\ w\\_T=1) - P(purchase\\ |\\ w\\_T=0,m\\_T=0), \\\\ P(purchase\\ |\\ m\\_T=1) - P(purchase\\ |\\ w\\_T=0,m\\_T=0))}\\) where: w_T is treatment dedicated to women m_T is treatment dedicated to men However, this leaves us with several open-ended questions i.e.: can we now implicitly calculate SHAP values, using the previously presented efficient technique (based on additivity)? Surely the max function breaks the additivity of uplift function, but maybe it is possible using some other method? References "],["story-meps-explainable-predictions-for-healthcare-expenditures.html", "Chapter 6 Story MEPS: Explainable predictions for healthcare expenditures 6.1 Introduction 6.2 Model 6.3 Model 6.4 Model Level Explainations 6.5 Instance Level Explanations 6.6 Summary and conclusions 6.7 References", " Chapter 6 Story MEPS: Explainable predictions for healthcare expenditures Authors: Anna Kozioł (Warsaw University of Technology), Katarzyna Lorenc (Warsaw University of Technology), Piotr Podolski (University of Warsaw) Mentors: Maciej Andrzejak (McKinsey &amp; Company), Alicja Jośko (McKinsey &amp; Company) 6.1 Introduction Perhaps the most urgent problem with the current health care system in the United States is its high cost. According to the Centers for Disease Control and Prevention, during 2017 health care spending per capita averaged nearly $11,000 and total spending was $3.2 trillion, or 17.9% of GDP. This raises the natural question of the causality of high expenses and the estimation of them for a particular person. One of the objectives of this chapter is to forecast annual spending on the health care of individuals in the United States. There is no doubt that these forecasts are of interest to people directly related to medical expenditure, for example, insurance companies, employers, government. How to deal with a situation when the model works well but is a so-called black box and we do not know what affects a specific result? What if the proposed models return non-intuitive results and we want to know why they are wrong? The next and main purpose of this chapter is to address these concerns using Explanatory Model Analysis. We will try to identify not only which features are most predictable for the results, but also the nature of the relationship (e.g. its direction and shape). We will focus on understanding the behavior of the model as a whole, as well as in a specific instant level (for specific person). The data set comes from a study called Medical Expenditure Panel Survey (MEPS), which is sponsored by the Healthcare Quality and Research Agency. About 15,000 households are selected as a new panel of surveyed units, regularly since 1996. Data set used for analysis is available for free on the MEPS website. The MEPS contains a representative sample of the population from the United States with two major components: the Household Component and the Insurance Component. Household Component collects data about demographic characteristics, health conditions, health status, medical history, fees and sources of payment, access to care, satisfaction with care, health insurance coverage, income, and employment for each person surveyed. The second component - insurance - collects data about the health insurance from private and public sector employers. The data include the number and types of private insurance schemes offered, premiums, employers’ and employees’ health insurance contributions, benefits associated with these schemes, and employer characteristics. The data processing and analysis were carried out in Python 3.7.3 and R 3.6.1. 6.2 Model 6.2.1 Data Agency of Healthcare Research and Quality provides an extensive database of medical expenses. Consequently, dataset selection on which we will make further analysis was an important first step. We decided to choose the two latest panels. Expenditures for treatment that we will examine in the following chapter apply to the years 2015/2016 and 2016/2017. The selected dataset contains information on over 32,000 patients, and each of them is described by 3,700 variables. We attached great importance to choosing features that would be appropriate for the prediction. The most important criterion adopted is that the variable cannot relate to expenditure associated with any treatment. For this purpose, we looked through several hundred of them and selected 387 most suitable. As a part of the preprocessing, we removed records that were marked as Inapplicable in the expenditure column. The number of people who didn’t incur expenses is 5504, while the number of patients with “inapplicable” is 407, the percentage respectively are 17% and 1%. The following figures show the distribution of the explained variable. FIGURE 6.1: Distribution of medical expenses 6.3 Model 6.3.1 Data Agency of Healthcare Research and Quality provides an extensive database of medical expenses. Consequently, data set selection on which we will make further analysis was an important first step. We decided to choose the two latest panels. Expenditures for treatment that we will examine in the following chapter apply to the years 2015/2016 and 2016/2017. The selected dataset contains information on over 32,000 patients, and each of them is described by 3,700 variables. We attached great importance to choosing features that would be appropriate for the prediction. The most important criterion adopted is that the variable cannot relate to expenditure associated with any treatment. For this purpose, we looked through several hundred of them and selected 387 most suitable. As a part of the preprocessing, we removed records that were marked as Inapplicable in the expenditure column. The number of people with such markings was 407, which is about 1% of the whole data set. The following figures show the distribution of the explained variable. FIGURE 6.2: Distribution of medical expenses 6.3.2 Model Among the models we have trained, the best results were achieved by Gradient Boosting. Due to the characteristics of the explained variable, we decided to check the behavior of the model after applying the logarithmic transformation to expenses. In the case of modelling the expenditure logarithm, we also used translations by 1 to avoid undesirable values of the variable. We used NNI toolkit to find the best hyperparameters To choose the best model, we compared the determination coefficient values. The table below shows the results of the experiments. To calculate the determination coefficient in column \\(R^2\\) (log), we transformed logarithmically the values of expenses, and after training the model we returned to the original scale. Values of the determination coefficient. Model \\(R^2\\) \\(R^2\\) (log) Gradient Boosting 0.43 0.44 Tuned Gradient Boosting 0.49 0.46 The best fit relying on the determination coefficient was demonstrated by a Gradient Boosting. Then, as a compromise between the size of the model and its quality, we chose the 7 most important variables. For this purpose, we ranked the significance of the variables in the model and extracted those with the highest coefficient. Obtained variables mainly concern the number of visits to specialists. For a more diverse and interesting analysis, we have also taken into account demographic variables such as age, gender, educational background, and race, as well as some disease units. FIGURE 6.3: Scheme of conduct with a specification of origin of variables A review of selected variables Variable New Name Description IPNGTDY1 hospital_nights number of nights associated with hospital discharges OBDRVY1 phys_visits number of office-based physician visits HHAGDY1 home_days agency home health provider days DSFTNV5 feet_checked indicate whether the respondent reported having his or her feet checked for sores or irritations OBOTHVY1 non-phys_visits office-based non-physican visits PSTATS2 disposition person disposition status OPOTHVY1 outpatient_visits outpatient dept non-dr visits AGE2X age age of patient RACEV2X race race of patient SEX sex patient’s gender HIDEG edu the highest degree of education attained at the time the individual entered MEPS diab_disease diab_disease indicates whether the patient suffered from a diabetes disease art_disease art_disease indicates whether the patient suffered from a arthritis disease ast_disease ast_disease indicates whether the patient suffered from a asthma disease press_disease press_disease indicates whether the patient suffered from a high pressure disease heart_disease heart_disease indicates whether the patient suffered from a heart disease In the following section we will explain the Gradient Boosting model based on 16 variables presented in the table above. The coefficient of determination of the final model is 0.5 6.4 Model Level Explainations 6.4.1 Permutation Variable Importances In order to find out about the influence of individual variables on the prediction for each patient, we present a Permutation Variable Importances graph. FIGURE 6.4: Permutation Variable Importances for Gradient Boosting Regressor In the figure 6.4 we present the 6 most relevant variables. Features for which the median of Permutation Variable Importances was less than 0.01 were omitted. Undoubtedly, the most important is the variable that indicates the number of nights spent in the hospital by the patient. An interesting observation seems to us that the demographic variable - age, which initially did not have a significant impact on the prediction, on the reduced model is in the top five most important variables. The remaining demographic variables, as well as those relating to diseases, do not show a gain in relevance in a model reduced to several variables. 6.4.2 Partial Dependence Profiles Based on previous analyzes, the number of nights spent in the hospital turned out to be the most important variable. To understand the nature of its impact on prediction in our model, it’s worth looking at the Partial Dependence Profiles. Below we present the PD plots broken down by gender. FIGURE 6.5: Partial Dependence Profiles for number of nights spent in the hospital broken down by gender Among patients who spent a few nights in the hospital, gender is not important for the amount of prediction. This rule begins to change after exceeding 30 nights. The PD profile for men has significantly higher values compared to the women’s profile, despite the fact that variable age doesn’t show much influence on the model. After exceeding 70 nights in the hospital, this variable does not affect the result returned by the model on average. 6.5 Instance Level Explanations 6.5.1 Business approach In this subsection we will try to show the application of explanatory methods in the business approach. Selected observations are: the person with the best estimated cost among people with results greater than 3000, the person for whom the model predicted the highest cost of all. Finding the value of characteristics that increase or decrease the final result, diagnostics of the direction of changes or oscillations of the result in case of change of characteristics describing a person may be valuable information for insurance companies or other payers for medical services. Such conclusions may also be useful for the patients, who have decided to pay for medical care themselves. In further consideration, the selected observations will be called Patient 1 and Patient 2. Values of explanatory variables for patients. Variable Patient 1 Patient 2 hospital_nights 0 52 phys_visits 4 6 home_days 0 0 feet_checked -1-inapplicable -1-inapplicable non-phys_visits 1 0 disposition household household outpatient_visits 0 1 age 58 59 race 1-white 1-white sex 2-female 1-man edu other bachelor’s degree diab_disease 1-yes 0-no art_disease 1-yes 1-yes ast_disease 0-no 1-yes press_disease 0-no 0-no heart_disease 1-yes 1-yes real expenses 3882$ 143457$ prediction 3886.8$ 147178.5$ 6.5.1.1 XIA for the best prediction XIA for the best prediction using Break Down Plots Break-down plots show how the contribution of individual variables change the average model prediction to the prediction for observation. The patient has 58 age, which alone increase average total cost by 574.177$ and the gender is female which decreases average total cost by 140. 72$. Her total number of office-based visits is 4, which increase average total cost by 574.177$. She suffers from arthritis what increase average total cost by 677.868$ but she is not diagnose to diabets, astma or high blood preasure which decrease final result. Her status of education is unknown, what increase total cost. The fact that she didn’t spend any night in the hospital decrease average total cost by 1343.271$. And also, she didn’t benefit from home medical services decrease average total cost by 386.772$. XIA for the best prediction using Shapley Values To remove the influence of the random ordering of the variables in brake down results we can compute an average value of the contributions. The plot shows that the most important variables, from the point of view of selected observation is number of days in home protected by medical servises, asthma disease or arthesis disease. For this observation number of days in home protected by medical servises equals 0 decreases average total cost by 158.37$. A similar effect is achieved by the fact of not using outpatient visits, what decreases final medical cost by 134.79$.This woman hasn’t spent any night in the hospital, which reduces average total cost prediction by 47.11$. Unfortunately, the patient suffers from arthesis disease which increases average medical costs by 80.9 $, but fact, that she has no disease like asthma, decreases average response by 137.77$. As said before, analised patient is a woman, what decreases average response by 77.37$. Her age is 58 what has positive impact on prediction and increase average total cost by 53.54$. XIA for the best prediction using LIME The key idea behind this method is to locally approximate a black-box Gradient-Boosting model by a K-lasso interpretable model. According to the LIME method, the plot suggests that spending any night in hospital reduces the estimated cost by 725.64$. Much greater, also the negative impact has a variable which telling that that patient didn’t benefit from home medical services, which total cost by 14072.46$. Having no outpatient visits also reduces final result by 4342.74$. Patient analysed is not diagnose the diabetes disease,which decrease response by 1518.18$. Variables that increase the cost of medical services are the total number of office-based visits greater than 3 and the age of the analyzed person greater than 54. The first explanation concerns the observation for which the expenditure was small and the model overestimated it. Brake Down plot and Shap Values plot returns results that are intuitive. Below is a diagnostic plot model. For large cost values the rest is positive and for small ones negative, which suggests that the model in general works well, but it pulls the predictions to average. FIGURE 6.6: Model diagnostic plot 6.5.1.2 XIA for for the highest prediction XIA for the prediction with the largest cost using Break Down Plots The patient spending 52 nights in hospital, which increase average total cost by 65749.48$. Having 59 age, increase average total cost by 16986$ and the fact that gender is male increase average total cost by 15105$. His status of education is bechelor degree, what increase total cost 1887$. Despite he is not diagnose to diabets and high blood preasure which decrease final result, he suffers from heart disease which also decrese avarage response. XIA for the prediction with the largest cost using Shapley Values As we expected, for the observation that generated the highest predictions, most of the variables have an additive effect on the final result. The graph shows that the greatest influence on the final value of the average prediction is race, disposition and number of night in hospital. For this patient, the fact that he’s a white man raises the average estimates by 21213.64$. Living in a household increases the average prediction by 17353.7$. Spending 52 nights in hospital increase average response by 16483.7$, likewise number of physical visits equals 6, raises average total prediction by 4518$. XIA for the prediction with the largest cost using LIME The LIME method also returns a positive influence on the final prediction for most variables. The chart shows that spending 52 nights in hospital increases treatment costs by 38817 $. The total number of office-based visits greater than 3 also has a positive impact, increasing the prediction by 6866.85 $. The age of a patient over 54 also significantly increases medical costs. Among the variables reducing treatment costs ,was the total number of days in home health care equal to 0. 6.5.1.3 XIA for both predictions using Ceteris Paribus Profiles In this chapter we will use Ceteris-paribus profiles for instance level explanations. Ceteris-paribus profiles show how the model response would change if a single variable is changed. So here we will be checking how would the model prediction change, if we change only one property of the patient and how it influences our model In the plot below we have selected features that behave differently between those two patients. Those features are sex, age, hosp_nights, phys_visits, feet_checked and outpatient_visits. FIGURE 6.7: Ceters Paribus plot for selected 6 features What can be observed is that the plots for Patient 2 are higher on the expenses axis, because of the fact that Patient 2 has higher costs, but the curvature of both curves is quite similar with some small differences like for the feet_checked variable. In later subsections we will dive more into those differences. Comparing differences between patients based on sex FIGURE 6.8: Ceters Paribus plot for SEX As we can see, our explanation model tries to predict what would have happened if the patient would have a different sex. For patient 1 there would be no difference in the predicted value, but for patient 2 the change of sex implicates reduction or an increase in predicted costs. This means, that if there would exist a different patient with similar as patient 2 symptoms and attributes but with different sex, the predicted cost would be different. Comparing differences between patients based on age FIGURE 6.9: Ceters Paribus plot for AGE In this section we will investigate age. Here both patients are almost the same age, 58 and 59 respectively for Patient 1 and Patient 2. For patient 1 there is no influence of age on the expenses, but for patient 2 there is an influence of this variable on predicted expenses. For patient 2 being around age of 60 and below age of 10 implicates a rise in predicted costs and for different possible ages it is almost constant. This means that for a patient with similar attributes as Patient 2, being around age 60 and below age of 10 implicates higher medical expenses, according to our model. Comparing differences between patients based on number of nights associated with hospital discharges FIGURE 6.10: Ceters Paribus plot for hosp_nights On the plot above for variable hosp_nights, both patients behave similarly, but with a different sensitivity. Patient 2, because of higher costs, is more sensitive in changes of the number of nights associated with hospital discharges. We can observe here, that hosp_nights equal to 0 implicates that the expenses are also equal to 0. With the increase of hosp_nights the expected expenses also rise until value of hosp_nights equal to 100, then expenses are constant. It is worth mentioning that not always hosp_nights equal to 0 means that there are no expenses. 6.5.2 Instance Level Explanations - instance specific approach Here we will try to show the results of explanatory analysis methods for selected instances of data, that is for specifically selected different people with different backgrounds, races, age and sex. The main idea behind this is to see how the model responses are different for different gender, race and age and which variables influence the model for each patient. A review of selected variables Variable Patient 1 Patient 2 hospital_nights 0 3 phys_visits 12 8 home_days 0 0 feet_checked 2-yes -1-inapplicable non-phys_visits 0 6 disposition household household outpatient_visits 0 3 age 71 34 race 2-black 1-white sex 1-man 2-female edu no degree no degree diab_disease 1-yes 0-no art_disease 1-yes 0-no ast_disease 0-no 0-no press_disease 1-yes 0-no heart_disease 1-yes 0-no real expenses 2263$ 16268$ prediction 8779$ 24373$ So as in table above we will investigate 2 patients, where one is of age 71 and with several illnesses, where the second one is of age of 34, different sex and without illnesses. 6.5.2.1 XIA for Patient 1 For this patient our model had predicted expenses equal to 8779$, where the real expenses were 2263$. This means that for this observation our model overestimated the expenses by 6516$. XIA for Patient 1 using Break Down Plots Here we will be showing explanations using Break-down plots and explain the contribution of individual variables on the prediction. The first patient is of age 71. The age variable in comparison to previous explanations should have significant impact on the prediction but not in this case. For this case, patients age increased the predicted expenses only by 141$. The biggest influence on the prediction has variable phys_visits, which is the number of office-based physician visits. It alone was responsible for 4300$ of expenses. Also diabetes and an feet_checked (indicator whether the respondent reported having his or her feet checked for sores or irritations) have positive influence on the predicted expenses. These two observations increased the predicted cost bo 6000$. Variables hospital_nights, non-phys_visits and edu have most significantly negative influence on the prediction and lowered the predicted expenses by 2400$. The reason behind this, might be that our observation has 0 hospital_nights. XIA for Patient 1 using Shapley Values We can run explanatory analysis using shapley values for those patients. For Patient 1, all observations apart from home_disease_days have positive influence on the predicted value. Top three variables with the highest influence are diseases, and 3 after them are number of vists related variables. These top 3 diseases alone increased the predicted cost by 1800$. Next 3 variables which indicated the number of visits, increased the expected cost by 1100$. This is very interesting observation that is telling us, that diseases are the most important reasons why our medical expenses rise. XIA for Patient 1 using LIME Here we are using the LIME method for the explanations by approximating a complex model by a simpler one, which is easier to interpret. In the plot above, we can observe that for Patient 1, the prediction is heavily influenced by hosp_nights, which is the number of nights in a hospital. It influences negatively the prediction, thus lowering the expected costs. The same is for home_disease_days variable, which also negatively influenced the prediction. The reason behind such a result could be that our patient has 0 nights in a hospital and 0 home days. On the other hand, number of office-based physician visits has a positive impact on the models prediction, causing the expenses to be higher. 6.5.2.2 XIA for Patient 2 For this patient our model had predicted expenses equal to 24373$, where the real expenses were 16268$. This means that for this observation our model overestimated the expenses by 8105$. XIA for Patient 2 using Break Down Plots Here we will be showing explanations using Break-down plots and explaining the contribution of individual variables on the prediction. The second patient is of age 34. In this case the most significant influence on the prediciton have variables hospital_nights and outpatient_visits which are responsible for almost 17k of expenses. Other variables that also influence the prediction are phys_visits and non-phys_visits. Other variables have very small or small but negative influence on the prediciton. This is quite interesing, because the variables that are making the expenses to go higher are pure number of visits in hospital or by some medical employees. Here in comparison with patient 1, hospital_nights variable has positive influence on predicted cost, where for patient 1 it was negative. This paient has hospital_nights greater then 0, which could be the reason behind such a change. XIA for Patient 2 using Shapley Values We can run explanatory analysis using shapley values for those patients. For Patient 2, all observations have positive influence on the predicted value. Here just as for the first patient, top two most important variables are diseases. There are also 2 other diseases with slightly smaller influence, but still a significant one. What is interesting here, diab_disease and art_disease being 0 influenced the result the most, where for patient 1 they were equal to 1 and were also in top influencial variables. XIA for Patient 2 using LIME For Patient 2, the explanations received using LIME method show us, that number of nights in a hospital have the highest positive influence on the prediction. It means that number of nights in a hospital for this patient is making the medical expenses higher for him, while home_disease_days variable is making the expenses lower. Other variables like phys_visits, non-phys_visits and outpatient_visits influence the prediction making the expenses to rise. Such results are very natural and are easy to understand by anyone investigating such a prediction. We can also see a difference in comparison to the first patient, where number of nights in a hospital were making the expenses lower, because he had 0 of them. 6.5.2.3 XIA for Patient 1 and Patient 2 using Ceteris Paribus Profiles In this chapter we will use Ceteris-paribus profiles for instance level explanations and see how would the model prediction change, if we change only one property of the patient and how it influences our model. We will see if there are any clear differences between patients and how our model is treating each one of them. Comparing differences between model predictions for Patient 1 and 2 for diffenret properties Here we present a plot, on which we list all variables that are interesting to investigate. We will try to investigate, how the model behavior changes for each patient, when their properties change. One thing to be aware of, both patients have different predicted expenses, so we will be mainly interested in the curvature of the plots. FIGURE 6.11: Ceters Paribus plot for six variables As shown on the plot above, each value of the patient property influences a bit differently the outcome of our model. Patient 2, who has higher expenses, has higher values on our plots, but the dynamics of those plots for both patients are very similar. Comparing differences between patients for number of nights associated with hospital discharges Here we have chosen the variable that describes the number of nights the patient has spent in a hospital. FIGURE 6.12: Ceters Paribus plot for hosp_nigths For this property of our patients, we would like to show how the model responds, when values of the number of nights associated with hospital discharges influences the predicted costs. The number of nights influences the expenses for patient 1 and 2 similarly, but with different power. Patient 2, due to having a higher prediction of expenses is being influenced more than patient 1, but with the same dynamic. This shows that our model treats both patients similarly. Comparing differences between patients for variable of number of office-based physician visits. Here we have chosen the phys_visits variable which is the number of office-based physician visits. FIGURE 6.13: Ceters Paribus plot for phys_visits In this case we can notice an interesting influence of the variable phys_visits. For patient 1, the higher the number of office-based physician visits, the higher would be the predicted outcome of our model. This is different for patient 2, for whom the predicted value is not changing, sometimes it is even declining. This is very interesting, because it tells us, that Patient 2, which is younger is almost not influenced by the number of office-based physician visits, while the older patient 1 has higher expenses with higher number of those vists. 6.6 Summary and conclusions Undoubtedly, explanatory methods open up new opportunities in the business sector as well as in the diagnostic model and exploration. The data on which the analysis has been carried out covers the entire population of the United States of America. Depending on age, education, gender, and many other agents, people take different approaches to looking after their health. The analyses presented in the above chapter have provided conclusions that may be useful in various areas. Model-level exploration showed that it is worthwhile to study the impact of variables on each other, as this may show more complex relationships. In our case, the SEX variable, which doesn’t show much impact affects the most important variable almost twice. Explainability methods can certainly work in the business sector. Case analysis at the instance level allowed to compare the behavior of the model for people with different characteristics. An interesting observation is undoubtedly the fact, that the total medical cost was strongly influenced by a variable of the number of days in the hospital, rather than the patient’s demography or medical history itself. Perhaps, it would be worthwhile for financial institutions to make a two-stage analysis to estimate the final result. First is to estimate the number of days spent in hospital or at home with illness based on demographic factors and medical history. The second is, to use these results for further calculations. It could contribute to a more accurate assessment of the costs generated and be more beneficial for companies. Explanation methods have helped to understand why the model often overestimates observations and to diagnose that the model pulls observations to average. This has facilitated further interpretation of the results. We also paid attention to people who differ in their state of health and age. In this case too, the number of visits to the hospital turned out to affect the outcome. Nevertheless, for these observations, the health condition also had a strong impact, both for the young and the elderly. The explanatory methods at the instance level gave the picture that people care about their health differently. 6.7 References Przemysław Biecek, Tomasz Burzykowski, Explanatory Model Analysis: Explore, Explain and Examine Predictive Models, https://pbiecek.github.io/ema/preface.html \\begin{document} \\begin{markdown} "],["story-meps-healthcare-expenditures-of-individuals.html", "Chapter 7 Story MEPS: Healthcare expenditures of individuals 7.1 Introduction 7.2 Data set 7.3 Models 7.4 Analysis with XAI methods 7.5 Conclusion 7.6 Appendix", " Chapter 7 Story MEPS: Healthcare expenditures of individuals Authors: Dominika Bankiewicz (University of Warsaw), Jakub Białek (Warsaw University of Technology), Agata Pałdyna (Warsaw University of Technology) Mentors: Michał Borowik (McKinsey &amp; Company), Tomasz Kaczmarczyk (McKinsey &amp; Company) 7.1 Introduction This chapter provides an analysis of models predicting annual healthcare expenditure of individuals based on result from large-scale surveys prepared by MEPS (see Data set below). Selected XAI algorithms were employed in order to perform model diagnostics and improve understanding of relationship between healthcare expenditures of an individual and set of factors describing demographics and socio-economics factors as well as self-reported health status. While the model performance is mainly important from data scientist perspective, the above-mentioned relationship is particularly interesting from the point of view of the subject that is financially responsible for the healthcare cost – insurance company, government, healthcare provider or individuals. With respect to all the stakeholders mentioned, following observations were made: Healthcare expenditures of about 14 % of respondents is equal to 0. However, survey answers provided by some of these respondents (e.g. diagnosed cancer) suggest otherwise. This may indicate errors in the data collection. Self-reported health status data may be misleading. The methodology of gathering and evaluation of such data should be therefore carefully designed. While for most of the time the relationship between age and health expenditures is monotonously growing, there are some specific points (corresponding to patient’s age) at which the growth is rapid. This might be particularly interesting for insurance companies. Applying SHAP to complex model can be a way of encoding and grouping categorical variables. Transformed variables can be then successfully fed into simpler (e.g. linear) models. While reducing dimensionality, it can improve model performance, stability and interpretability. 7.2 Data set The data set analyzed is called MEPS (Medical Expenditure Panel Survey) and it is freely accessible at their website. The data comes from large-scale surveys of families, individuals, medical providers and employers from the United States of America. Each observation of the data set contains total expenditures of an individual as well as number of other variables describing his or her demographic and socio-economic status. This allows to create models predicting the expenditure based on other factors. For this reason it is particularly interesting for every subject that is financially responsible for the healthcare cost – insurance company, government, healthcare provider or individuals. The data analyzed in the following sections was not downloaded directly from MEPS website. Instead, it was obtained through IBM’s AIX360. The dataset provides 18350 observations and it contains variables that describe: demographics (age, gender, marital status), socio-economics (education, income, insurance coverage), self-reported health status (self-evaluation of physical and mental health status), diagnoses (stroke, cancer, heart disease, diabetes), health limitations (cognitive, activity, sensory). The following section describes the development of three different models for predicting the transformed total health expenditure of an individual. Once developed, these models are compared in terms of their quality and one of them is selected and analyzed using XAI methods. Explanations provided by different methods are discussed. 7.3 Models In the following subchapters the development of three different models is briefly described. Full details on the implementation together with the code itself can be found on github repository. First of all, since the distribution of the predicted variable is strongly skewed, it was transformed with logarithm base 3 (see Figure below). Typically in such cases, natural logarithm is chosen, but having in mind that impact of input variables on the prediction will be analyzed, the decision was made to use base 3 instead (when we see that some input variable affected the prediction increasing it by one, then we can say that it increased the total expenditures by the factor of three, not factor of Euler number). Percentile distribution before and after log3 transformation. In order to ensure that results from all three models can be directly compared, models are trained and evaluated on the same, arbitrarily chosen, test and validation subsets. These can also be found github repository. The evaluation metrics are RMSE, MAE and R^2. 7.3.1 Model 1: Ridge regression Ridge regression model was created with sklearn package. Following operations were performed to prepare the data: logarithm change of the explainable variable (as described before) min and max scaling of variables RTHLTH31, MNHLTH31, POVCAT15. This variables describe the state of general health, mental health and poverty status in values (decoded to: poor, fair, good, very good, excellent). addition of a new column which counts for how many diseases/health issues patient was tested positive. The ridge regression was performed with GridSearchCV. This allowed to perform 5-fold cross-validation with a range of different regularization parameters in order to find the optimal value of alpha parameter. The final results of the ridge regression model are shown in the Results section. 7.3.2 Model 2: Artificial Neural Network The second model evaluated was a multilayer perceptron. The input data was preprocessed with use of scikit-learn (scikit-learn 2020) tools: numerical features were standardized categorical features were one-hot encoded The data was fed into ANN with 4 hidden, fully-connected layers. The ANN model itself was created with Keras (Keras 2020). Alltogether, the preprocessing steps and the model, was wrapped into scikit-learn pipeline so it can be easily use with XAI methods. The results are shown in the Results section. 7.3.3 Model 3: Gradient Boosting Gradient Boosting regression model was developed using scikit-learn package (scikit-learn 2019a). For this model, data was prepared in the following way: as was mentioned in Introduction, target variable was transformed with logarithm base 3, categorical features (i.e. features with 10 or less unique values, except variables “POVCAT15”, “RTHLTH31”, “MNHLTH31” which can be treated as continuous) were transformed with OneHotEncoder (scikit-learn 2019c), numerical features were transformed with StandardScaler (scikit-learn 2019d). Hiperparameters tuning was done with GridSearchCV (scikit-learn 2019b). Following parameters were optimized: n_esimators - the number of trees, max_depth - the maximum depth of tree, min_samples_split - the minimum number of samples required to split an internal node, min_samples_leaf - the minimum number of samples required to be at a leaf node. The results for best hyperparameters are shown in the Results section. 7.3.4 Results Table below presents results for all developed models. RMSE (train) MAE (train) R^2 (train) RMSE (test) MAE (test) R^2 (test) RR 2.27 1.72 0.33 2.25 1.70 0.30 ANN 2.14 1.59 0.40 2.17 1.61 0.37 XGB 2.04 1.51 0.45 2.17 1.61 0.37 Due to its recent popularity and complexity, XGB model was selected for further analysis. Let’s have a look at scatter plots of predicted and true values for both - training and testing subsets. Predicted values vs real values of target variable. We can clearly see a non negligible contribution to the error of observations for which the true value is equal to zero while the predicted one is higher than that. This will be investigated in the following section. 7.4 Analysis with XAI methods 7.4.1 Analysis of patients with zero expenditures As it was mentioned above, a part of the error are observations for which true value is zero but model predict values larger than zero. Let’s have a look at an observation like that. Selected observation is a 76 years old woman. She is a widow and has a GED or high school degree. She complains about poor health status and fair mental health status. She has ever been diagnosed with high blood pressure, coronary heart disease, emphysema, chronic bronchitis, high cholesterol, cancer, rheumatoid arthritis and joint pain last 12 months. She has social and cognitive limitation and limitation in physical functioning. She doesn’t smoke and has serious difficulty see or wears glasses. Her health insurance coverage indicator is public only. Total health expenditure of this woman is equal to zero but model predicted that it is equal to about 12005.68 (3 to the power of 8.55). The question is why model predicted such value. Let’s have a look at Figure presenting Shapley values for our observation (see Figure below). Figure presents Shapley values for an observation selected in this subchapter. From data scientist point of view, it seems to be weird that differences between successive contributions are very small and contribution for ‘all other factors’ is about 6 times bigger than for the first feature, so it can be hard to tell which factors have the biggest impact on that prediction. Therefore, in order to find out which variables have the most significant influence, we can use LIME (see Figure below). Figure presents the most important features for selected observation according to LIME. As we can see, the biggest impact for this prediction have the following factors: poor perceived health status (RTHLTH31 = 5), self-evaluation of health - inapplicable (PCS42 = -1), high family income (POVCAT15 = 5), 76 years old (AGE31X = 76), white race (RACE3 = 0). Let’s check distributions of these features for observations for which true value of total health expenditure is zero but model predict values larger than zero. Distribution of the most important features according to LIME for observations for which true value is zero but model predict values larger than zero. As we can see, the values of the variables RTHLTH31, PCS42 and AGE31X for this observation constitute a definite minority. According to results of LIME and above distributions, let’s check distribution of target values for observations at age greater than 57 with perceived health status fair or poor, high family income and white race. As can be seen in the Figure below, there is only one observation with total health expenditure equal to zero and the mean value is about 8, so we can assume that the model behaved correctly. Figure presents distribution of target values for observations at age greater than 57 with perceived health status fair or poor, high family income and white race. Let’s get back to our patient. Out of all the diagnoses of diseases that appear in these data (13), 6 diagnoses are positive for this woman. Let’s take a look then at how it looks like for other patients with zero expenditures. As we can see in the Figure below, patients with zero expenditure who have ever been diagnosed with more than 2 diseases are a definite minority. Figure presents distribution of number of positive diagnoses for observations with zero expenditures. 7.4.2 Interpretation of self-reported health status and survey questions design Evaluation of one’s health status seems to be an obvious indicator of what can we expect in terms of health expenditure. One should be cautious though - the methodology of this measurement is crucial here. Let’s have a look at profiles of variables PCS42 and RTHLTH31 - both are self-evaluation of ones health. PCS42 was created based on set of concrete questions about specific pain, limitations in activities etc. The higher the value, the better the health. On the other hand, RTHLTH31 just describes the overall health condition in one word, corresponding to the scale from 1 to 5 (“excellent”, “very good” “good” “fair” and “poor”). In this case, the higher the value, the worse the health. Both plots show the expected behaviour of the model. It is interesting to see though, that there is not much difference between “excellent” and “very good”. Similarly - the difference is very small between “fair” and “poor”. This is primarily caused by the subjective matter of these answers. First of all the understanding of the words their selves - something which is very good for one person, might be just good for other. Second thing is that we usually compare our current health to the recent past. If one feels tired every day, he might say that his health is fair. But if he feels a little tired every day but he just recovered from flu, he will say he feels very good, or excellent (in comparison to how he felt a week ago). Finally, people tend to get used to their diseases. It is proven, that people feel very bad at the beginning - when they are diagnosed, but when the time goes by they care less and less - they just get used to living with a disease. Nevertheless, it is important to say that insurance providers should be very careful while pricing their services partially basing on surveys. It is crucial to ask specific questions that cannot be biased by subjective feelings of the respondent. One more interesting example of counter-intuitive results caused by wrong design of the survey is question regarding smoking status. Similarly to previous yes or no questions, following answers may be chosen: 1 - currently smoking, 2 - currently not smoking, -1 - NA. It is widely known that smoking has substantial, negative impact on our health and thus. Yet it seems, that the model says otherwise. The reason for that may be the fact that question that is being asked considers only current status. If someone has any kind of health problems due to smoking - he or she is most likely not smoking anymore (so not smoking currently). In order to obtain full information, additional question should be asked, e.g. - Have you been smoking in the past? * PDP and ALE for variable answering whether patient is currently smoking. * 7.4.3 The relationship between age and health expenditure Intuitively, the age of the patient should be a very good predictor. Even non-experts can tell that usually the older the person is, the more issues with health it has and thus - the more money will be spend on healthcare. Let’s have a look at PDP and ALE profile for age in our XGB model: ALE and PDP profiles of age variable The first interesting thing that can be noted in here is the relatively high starting point for newborns. The ANN model, which is more regularized, seems to confirm the general U-shaped relationship: ALE and PDP profiles of age variable for ANN model This is most likely caused by early childhood health issues as well as large expenses on hygiene products (diapers etc.) Another important point to mention is the sharp increase at the age between 17-19 years. It is clearly noticeable in PDP, but it is insignificant in the ALE plot. This puts in question the relevance of trusting PDP plots here. There are several periods in ones life that are characterized by different needs in terms of healthcare. Simplest division include three groups - newborns and children, youth and young adults, mid-aged and elderly people. The last group dominates the others in terms of both - age scope and number of observations. Since, PDP are simply averaged Ceteris Paribus curves, thus the shape of the curve at the age of 17 is more affected by the model outputs for people at age of 30-80 (with only age variable changed) than for people at age 10-30. Since age is non-linearly correlated with other variables (like probability of diagnosing diabetes), one should be cautious with inferring from PDP in this case. Unlike the first sharp increase, the other one at the age of about 50 years, seems to be more credible - it is noticeable in both plots. At this age a lot of diseases are getting more probable thus people are taking part in screening programs, diagnose and start to cure. From now on, health status becomes worse and health expenditures are usually getting higher every year. From the model developer perspective - this relation seems to be a little raged. One would expect to be more smooth and monotonic. For example, there is no particular reason why medical expenditures should decrease at once we turn 60, but the plot shows otherwise. This suggests that it might be a good idea to discretize the age variable into number of groups. While there is very small probability that your health status will get worse next year, it is highly likely that it will get worse 10 years from now. It is worth investigation whether this transformation of the variable will improve the results. From the perspective of the medical provider and patient itself - we can clearly see that there is a point at which the expenditures sharply increase. It might be good idea for a patient to buy additional insurance once he or she approach that age. On the other hand, insurance provider should take that into account while preparing his offer. If the agreement time is couple of years and it includes that specific time when health sharply worsens, this should be included in price. This increase may be also interesting from another perspective - if it does indeed come from national screening initiatives, then it can provide some kind of measure of relevancy of these screening programs at particular age of a patient. If the rate of positive diagnoses is too high, maybe the screening programs should be recommended at the age of 45, rather then 50. 7.4.4 Using SHAP for encoding and grouping of categorical variables In this part, the explanations obtained with SHAP were used to encode and group variables. The XGB model is composed of 43 variables where 13 of them indicate if the patient was diagnosed with a given disease. In order to reduce the input size and improve the stability, the 13 was aggregated into one variable. Because different diseases had a different impact on explanatory variables (‘HEALTHEXP’) the weights were assigned to them. Permutation feature importance mean score for diseases variables in XGB model As shown on a figure above, the average permutation feature importance of variables describing disease differs. The most important is the variable ‘HIBPDX’ (high blood pressure diagnosis) and ‘CHDDX’ (coronary heart disease diagnosis). The weights were calculated with the help of Shapley additive explanations values. Due to long computation time, 50 random positive tested patients were chosen for each disease. Then the patient’s SHAP value was calculated. To obtain the weight of a given disease the mean effect of the SHAP results was calculated. Averaged SHAP values for diseases variables Figure above shows rounded up to 3 decimal points mean SHAP values for variables describing diseases. These values based only on positive tested patients are higher for diseases such as ‘DIABDX’ (diabetes diagnosis), ‘ADHDADDX’ (ADHDADD diagnosis) and ‘ASTHDX’ (asthma diagnosis). They are long-term diseases that require constant treatment. Patients who suffer from diabetes must apply insulin treatment. Asthmatics must carry the inhalers all time around them in case of a sudden attack. ADHD requires medications or behavior therapy. On the other hand, the heart diseases had a low value – variables ‘CHDDX’ (coronary heart diagnosis), ‘OHRTDX’ (other heart diseases) and ‘MIDX’ (heart attack). For each patients in dataset the weighted sum of disease variables impact was assigned to the new variable called “POSVT” (from POSitiVe Tested). Then new XGB model was trained on the modified variables. The results obtained were better than on a previously developed XGB model. Table below presents rounded up to the 2 decimal points results for the previously described original XGB model (called in a table full XGB) and new aggregated model (called in a table aggregated XGB). RMSE (train) MAE (train) R^2 (train) RMSE (test) MAE (test) R^2 (test) full XGB 2.04 1.51 0.45 2.17 1.61 0.37 aggregated XGB 2.02 1.50 0.46 2.16 1.6 0.38 New modified variables were also applied to the simpler model - ridge regression model. Results were almost the same as in ridge regression model without aggregation of disease variables. The biggest difference is between the R^2 score on the test and the training set. Test set had a better score in an aggregate model. The table below shows rounded up to 2 decimal points results for ridge regression models: RMSE (train) MAE (train) R^2 (train) RMSE (test) MAE (test) R^2 (test) full RR 2.27 1.72 0.33 2.25 1.70 0.30 aggregated RR 2.27 1.72 0.32 2.25 1.70 0.33 The figure below shows the variables coefficients in the aggregated ridge regression model only for variables whose coefficient was greater than 0.1. The aggregated variable (‘POSVT’) had the biggest positive value. Variables coefficients in the aggregated ridge regression model. 7.5 Conclusion While some of the conclusions drawn in the analysis seem to be expressed with high level of certainty, in fact it is really difficult to judge whether the knowledge revealed with XAI methods is actually there, or maybe that’s just an artifact in a model or data, especially when model performance is not very high. To take that into account, the final conclusions are more generalized. The performed analysis has shown that: XAI methods can be particularly useful in identifying outliers in the data set that may affect the performance of the model. In this particular case, reported healthcare expenditures of about 14 % of patients was equal to 0, which is in many cases questionable. Model analysis with PDP and ALE can help to reveal insights that may be counterintuitive at first, but seem to be reasonable when thought through. At the beginning it seems obvious that people who smoke should have worse health status and therefore higher expenditures. However, if someone has any kind of health problems due to smoking - he or she is most likely not smoking anymore. Therefore, question about smoking history seems to be much more informative in this case. XAI algorithms can be useful to transform non-linear relationships derived from complex models into simpler, self-interpretable models. Using shap for encoding and grouping diseases based on XGB model allowed to improve performance of Ridge Regression model. Compution time might be sometimes limiting though. What the analysis did not show however, is the fact that trying to explain instances and models will not always provide you with correct answers. Yet, in most cases, it will provide you with the right questions. 7.6 Appendix 7.6.1 Additionall plots 7.6.2 Variables descriptions Name Meaning Values Values meaning PANEL PANEL NUMBER 19 20 Panel 19 Panel 20 REGION CENSUS REGION -1 1 2 3 4 INAPPLICABLE NORTHEAST MIDWEST SOUTH WEST AGE31X AGE - R3/1 0 - 85 Patient age GENDER GENDER 0 1 MALE FEMALE RACE3 RACE 0 1 MARRY31X MARITAL STATUS 1 2 3 4 5 6 7 8 9 10 MARRIED WIDOWED DIVORCED SEPARATED NEVER MARRIED UNDER 16 - INAPPLICABLE MARRIED IN ROUND WIDOWED IN ROUND DIVORCED IN ROUND SEPARATED IN ROUND EDRECODE EDUCATION RECODE -1 1 2 13 14 15 16 INAPPLICABLE OR UNDER 5 LESS THAN/EQUAL TO 8TH GRADE 9 - 12TH GRADE, NO HS DIPLOMA OR GED GED OR HS GRAD BEYOND HS,COLLEGE(NO 4YR DEG),ASSOC DEG 4-YEAR COLLEGE DEGREE, BACHELOR’S DEGREE MASTER’S, DOCTORATE, OR PROFESSIONAL DEG FTSTU31X STUDENT STATUS IF AGES 17-23 -1 1 2 3 INAPPLICABLE FULL-TIME PART-TIME NOT A STUDENT ACTDTY31 MILITARY FULL-TIME ACTIVE DUTY 1 2 3 4 YES - ACTIVE DUTY NO - NOT FT ACTIVE DUTY UNDER 16 - INAPPLICABLE OVER 59 - INAPPLICABLE HONRDC31 HONORABLY DISCHARGED FROM MILITARY 1 2 3 4 YES - HONORABLY DISCHARGED NO - NOT HONORABLY DISCHARGED 16 OR YOUNGER - INAPPLICABLE NOW ACTIVE DUTY RTHLTH31 PERCEIVED HEALTH STATUS -1 1 2 3 4 5 INAPPLICABLE EXCELLENT VERY GOOD GOOD FAIR POOR MNHLTH31 PERCEIVED MENTAL HEALTH STATUS -1 1 2 3 4 5 INAPPLICABLE EXCELLENT VERY GOOD GOOD FAIR POOR HIBPDX HIGH BLOOD PRESSURE DIAG (&gt;17) -1 1 2 INAPPLICABLE YES NO CHDDX CORONARY HRT DISEASE DIAG (&gt;17) -1 1 2 INAPPLICABLE YES NO ANGIDX ANGINA DIAGNOSIS (&gt;17) -1 1 2 INAPPLICABLE YES NO MIDX HEART ATTACK (MI) DIAG (&gt;17) -1 1 2 INAPPLICABLE YES NO OHRTDX OTHER HEART DISEASE DIAG (&gt;17) -1 1 2 INAPPLICABLE YES NO STRKDX STROKE DIAGNOSIS (&gt;17) -1 1 2 INAPPLICABLE YES NO EMPHDX EMPHYSEMA DIAGNOSIS (&gt;17) -1 1 2 INAPPLICABLE YES NO CHBRON31 CHRONC BRONCHITS LAST 12 MTHS (&gt;17)-R3/1 -1 1 2 INAPPLICABLE YES NO CHOLDX HIGH CHOLESTEROL DIAGNOSIS (&gt;17) -1 1 2 INAPPLICABLE YES NO CANCERDX CANCER DIAGNOSIS (&gt;17) -1 1 2 INAPPLICABLE YES NO DIABDX DIABETES DIAGNOSIS (&gt;17) -1 1 2 INAPPLICABLE YES NO JTPAIN31 JOINT PAIN LAST 12 MONTHS (&gt;17) - RD 3/1 -1 1 2 INAPPLICABLE YES NO ARTHDX ARTHRITIS DIAGNOSIS (&gt;17) -1 1 2 INAPPLICABLE YES NO ARTHTYPE TYPE OF ARTHRITIS DIAGNOSED (&gt;17) -1 1 2 3 INAPPLICABLE RHEUMATOID ARTHRITIS OSTEOARTHRITIS NOT SPECIFIED ASTHDX ASTHMA DIAGNOSIS -1 1 2 INAPPLICABLE YES NO ADHDADDX ADHDADD DIAGNOSIS (5-17) -1 1 2 INAPPLICABLE YES NO PREGNT31 PREGNANT DURING REF PERIOD - RD 3/1 -1 1 2 INAPPLICABLE YES NO WLKLIM31 LIMITATION IN PHYSICAL FUNCTIONING-RD3/1 -1 1 2 INAPPLICABLE YES NO ACTLIM31 ANY LIMITATION WORK/HOUSEWRK/SCHL-RD 3/1 -1 1 2 INAPPLICABLE YES NO SOCLIM31 SOCIAL LIMITATIONS - RD 3/1 -1 1 2 INAPPLICABLE YES NO COGLIM31 COGNITIVE LIMITATIONS - RD 3/1 -1 1 2 INAPPLICABLE YES NO DFHEAR42 SERIOUS DIFFICULTY HEARING-RD 4/2 -1 1 2 INAPPLICABLE YES NO DFSEE42 SERIOUS DIFFICULTY SEE W/GLASSES-RD 4/2 -1 1 2 INAPPLICABLE YES NO ADSMOK42 SAQ: CURRENTLY SMOKE -1 1 2 INAPPLICABLE YES NO PCS42 SAQ:PHY COMPONENT SUMMRY SF-12V2 IMPUTED -1 4.41 - 72.07 INAPPLICABLE values - MCS42 MNT COMPONENT SUMMRY SF-12V2 IMPUTED -1 0.05 - 75.51 INAPPLICABLE values - K6SUM42 SAQ 30 DAYS: OVERALL RATING OF FEELINGS -1 0 - 24 INAPPLICABLE RATING OF LAST 30 DAYS PHQ242 SAQ 2 WKS: OVERALL RATING OF FEELINGS -1 0 - 6 INAPPLICABLE RATING OF LAST 2 WEEKS EMPST31 EMPLOYMENT STATUS RD 3/1 -1 1 2 INAPPLICABLE EMPLOYED AT RD 3/1 INT DATE JOB TO RETURN TO AT RD 3/1 INT DATE POVCAT15 FAMILY INC AS % OF POVERTY LINE - CATEGO 1 2 3 4 5 POOR/NEGATIVE NEAR POOR LOW INCOME MIDDLE INCOME HIGH INCOME INSCOV15 HEALTH INSURANCE COVERAGE INDICATOR 2015 1 2 3 ANY PRIVATE PUBLIC ONLY UNINSURED INCOME_M PERSON TOTAL INCOME HEALTHEXP TOTAL HEALTH CARE EXP 15 PERSONWT FINAL PERSON WEIGHT, 2015 References "],["story-lungs.html", "Chapter 8 Story Lungs: eXplainable predictions for post operational risks 8.1 Introduction 8.2 Data set 8.3 Models 8.4 Explanations 8.5 Summary and conclusions", " Chapter 8 Story Lungs: eXplainable predictions for post operational risks Authors: Maciej Bartczak (UW), Marika Partyka (PW) Mentors: Aleksandra Radziwiłł (McKinsey &amp; Company), Maciej Krasowski (McKinsey &amp; Company) 8.1 Introduction Science allows us to understand the world better. New technologies, data collection solves the problems not only of large companies but also of ordinary people. Especially if human life is at stake. They say that cancer is the killer of the 21st century. That’s why even small attempts to subdue this problem are important. In our work, we deal with lung cancer. We try to analise the chances of survival of a patient who has had a tumor removal surgery by explaining predicitve models. Note that we do not generally anticipate the chances of survival here, but only consider a particular group of patients who have cancer and have been qualified for surgery. Therefore, along the way we may encounter many non-intuitive conclusions, we may encounter here the survivorship bias. That is why the role of explaining the model in this case is so important, as we will show in the next parts of this chapter. But let’s focus on the data for a moment. 8.2 Data set The data set consists of the following varaibles. Numerical Variable Unit date_birth date date_start_treatment date date_surgery date tumor_size_x cm tumor_size_y cm tumor_size_z cm years_smoking years age years time_to_surgery years (“today” - date_surgery) Categorical Variable Decription Values sex subject sex male/female histopatological_diagnosis type of cancer Rak płaskonabłonkowy, pleomorficzny, …* symptoms whether symptoms were observed yes/no lung_cancer_in_family whether family member had cancer yes/no stadium_uicc severity of tumor IA1, IA2, IA3, IB, IIA, IIB, IIIA, IIIB, IVA, IVB* alive whether subject is alive yes/no (the target variable) About 1/3 af values of varaibles annotated with * was missing. Survivability was registered in a certain point of time - December 2016. That’s why we transform all the date varriables to number of years to December 2016. There are two reasons: - by changing dates to ages, i.e. date_surgery to age_when_surgery_was_performed we wouldn’t capture the time between the surgery and “today”. The longer it is the “more time patient has to die”, - similar analysis could be easily performed for different value of “today”. Following encoding strategy was employed: - binary variables were encoded as 0s and 1s, - categorical variable histopatological_diagnosis was one-hot encoded, - categorical variable stadium_uicc was encoded by increasing integers as there is natural order to this variable. 8.3 Models We have tried out several models as well as different preprocessing strategies. However, no model yielded better results than scikit-learn’s logistic regression with hyperparameters cross validation. In order to further refine our model we tried adding some features as well as pruning irrelevent ones. We have added following variables: - tumor_volume = tumor_size_x * tumor_size_y * tumor_size_z, - log_tumor_volume = log(tumor_volume + 1e-4) and considered two, equally well performing, versions of the data set: - full - with added tumor_volume and log_tumor_volume - pruned - with no histopatological_diagnosis and only log_tumor_volume with regard to the tumor This is the receiver operating curve for the final model. FIGURE 8.1: ROC for final model. 8.4 Explanations The explanations are based on logistic regression model. We base our analysis on 3 methods of explaining models, mainly Ceteris Paribus as well as Shap and Variable Importance. Let’s start by explaining at the dataset level. Let’s see how Variable Importance behaves. FIGURE 8.2: Variable Importance for Logistic Regression model. Under the date_surgery variable is the number of years that have elapsed between that date and the end of the study. As the explanation shows that this variable is the most important, we will look at it in more detail later in this chapter. The second most important is the UICC stage. This variable tells us how advanced the cancer we cut out is. You can guess that the more advanced the stage, the bigger and harder the tumor is to cut out. We may wonder why the third most important variable is date of birth, not age. In fact, these two variables are obviously very correlated and the above results are the result of the distribution of importance between the two variables. Interestingly, the period of time the patient smoked cigarettes does not affect the outcome too much. Of course, if we were to consider the chances of getting lung cancer, or overall survival, this variable could be much more important. However, let’s remember that our study involves patients who are already in advanced disease and undergoing surgery anyway, so how many years they have smoked doesn’t have to be so important at this point. After a general look at the significance of variables, it is time to go into details. It would be useful if we could explain to the patient why his chances of survival after surgery are as high as our model predicted and show him what would increase or decrease his chances. For example, let’s take a patient with the following variable values: - date_start_treatment 4.4 - sex K - years_smoking 0 - lung_cancer_in_family No - symptoms No - stadium_uicc IIIB - age 72 - time_to_surgery 0 - log_tumor_volume 5.8 Our most recent model indicated that the chances of survival after surgery for such a patient are \\(43\\%.\\) Here we have an explanation of this result by SHAP. FIGURE 8.3: Shap method for choosen patient. We see that, according to the conclusions of the previous method, variables stadium_uicc and date_surgery have the greatest impact. The SHAP method allows us to see whether individual variables have a negative or rather positive impact on predictions. Our patient’s stadium_uicc is quite advanced, so it reduces the chances of survival after surgery quite drastically. The date_surgery variable, on the other hand, increases the probability, but we do not know whether a smaller value could further improve our prediction or the opposite. To find out, we use another Ceteris Paribus method. First we’ll look at the date variables. If we look at the age variable, i.e. the age at the time of surgery, we can see that it behaves quite intuitively. The younger the patient, the better he is able to recover from surgery, so his chances for survival are higher. FIGURE 8.4: Ceteris Paribus for age variable. The date_surgery variable is interesting. It indicates the number of years that have passed from surgery to the end of the study. It would seem that the earlier we do surgery, the better our prognosis will be. The charts show the opposite. This may be because if the surgery was done a long time ago, the patient has been getting older since then and has little chance of survival. FIGURE 8.5: Ceteris Paribus for date_surgery variable. Now let’s look at the stadium. As mentioned earlier, the more advanced the stage of cancer the worse for the patient. Our patient’s stadium is quite advanced, which has a big influence on the predictions, but if she had a more benign stage her chances of survival would increase strongly. FIGURE 8.6: Ceteris Paribus for stadium_uicc variable. The variable log_tumor_volume indicates that if we cut out a smaller tumor, our postoperative survival increases. This conclusion coincides with our intuition, the removal of a smaller tumor is much safer, because perhaps with a larger one we could damage certain structures and thus increase mortality. FIGURE 8.7: Ceteris Paribus for the volume of the tumor, but after transformation as a logarithm. Using model explanations not only helps to explain the result of the prediction, it can also give a hint how to improve our model. When we built the model on all variables, the explanations allowed us to find highly dependent variables. Let’s compare the CeterisParibus results for the full model and the pruned one. The image below shows the date_birth variable in its original version, i.e. as date. FIGURE 8.8: Selected model with correlated variables left. In the picture above you can see that the influence of two correlated variables was distributed between them, but after leaving only one of these variables, the influence accumulated on it (picture below). FIGURE 8.9: Model after removing correlated variables, you can see a big difference in the explanation. At this stage we can already conclude that the techniques of model explanations are not only useful at the end of our journey. They can give us tips on how to transform data or which variables should be deleted. 8.5 Summary and conclusions XAI methods legitimised employed approach of pruning the dataset. XAI methods yielded explainations consistent with biological intuintion, what builds up trust in the model. As variety of modelling and preprocessing approaches resulted in similar predicitive performance we conclude there is not much more to squeeze out of the dataset. "],["story-heloc-credits.html", "Chapter 9 Story HELOC Credits 9.1 Introduction 9.2 Model 9.3 Explanations 9.4 Summary and conclusion", " Chapter 9 Story HELOC Credits Authors: Tomasz Kurzelewski (University of Warsaw), Tomasz Radzikowski (Warsaw University of Technology) Mentors: Marta Gajewska (McKinsey &amp; Company), Amadeusz Andrzejewski (McKinsey &amp; Company) 9.1 Introduction A home equity line of credit, or HELOC, is a loan in which the lender agrees to lend a maximum amount within an agreed period (called a term), where the collateral is the borrower’s equity in his/her house (akin to a second mortgage). Because a home often is a consumer’s most valuable asset, many homeowners use home equity credit lines only for major items, such as education, home improvements, or medical bills, and choose not to use them for day-to-day expenses. Since amount of such credit is not small, banks carefully review financial situation of applicants. Utmost care is taken so the whole process is transparent and decision is easily explainable to the client. Because of that any automated process also has to be explainable, and in this XAI methods may be helpful. 9.1.1 Dataset Our dataset - Home Equity Line of Credit (HELOC) - originally comes from Explainable Machine Learning Challange organized by FICO company. The data contains anonymized credit applications of HELOC credit lines, which are a type of loan, collateralized by a customer’s property. There are 23 predictors in the dataset, which describe following features: ExternalRiskEstimate - consolidated indicator of risk markers (equivalent of polish BIK’s rate) MSinceOldestTradeOpen - number of months that have elapsed since first trade MSinceMostRecentTradeOpen - number of months that have elapsed since last opened trade AverageMInFile - average months in file NumSatisfactoryTrades - number of satisfactory trades NumTrades60Ever2DerogPubRec - number of trades which are more than 60 past due NumTrades90Ever2DerogPubRec - number of trades which are more than 90 past due PercentTradesNeverDelq - percent of trades, that were not delinquent MSinceMostRecentDelq - number of months that have elapsed since last delinquent trade MaxDelq2PublicRecLast12M - the longest delinquency period in last 12 months MaxDelqEver - the longest delinquency period NumTotalTrades - total number of trades NumTradesOpeninLast12M - number of trades opened in last 12 months PercentInstallTrades - percent of installments trades MSinceMostRecentInqexcl7days - months since last inquiry (excluding last 7 days) NumInqLast6M - number of inquiries in last 6 months NumInqLast6Mexcl7days - number of inquiries in last 6 months (excluding last 7 days) NetFractionRevolvingBurden - revolving balance divided by credit limit NetFractionInstallBurden - installment balance divided by original loan amount NumRevolvingTradesWBalance - number of revolving trades with balance NumInstallTradesWBalance - number of installment trades with balance NumBank2NatlTradesWHighUtilization - number of trades with high utilization ratio (credit utilization ratio - the amount of a credit card balance compared to the credit limit) PercentTradesWBalance - percent of trades with balance Features containing data about delinquency are coded to numeric scale and missing values are labeled with negative integer number. The majority of features are monotonically decreasing or increasing. Dataset has 10459 observations, 5000 of which belong to class ‘Good’, what means that clients repaid their HELOC account within 2 years, and 5459 belong to class ‘Bad’. This gives us distribution of 48% ‘Good’ individuals, and 52% ‘Bad’ individuals. Although not all rows are unique. There is only 9871 unique rows in this set, with same distribution of result classes as in whole dataset. 9.2 Model Since credit decision takes into account many variables related to the customer’s financial situation, and many of them were not included into dataset, accuracy of built models was not as good as we would want. Best results available in papers are around 0.84 AUC, while our model based on XGBoost scored around 0.80 AUC, ROC curve is visible on figure 9.1. We experimented with different models, such as based on SVM, Random Forest and XGBoost. The last two gave best results, both around 0.80 AUC, but we have chosen XGBoost since available implementation allowed us to reinforce monotonicity bounds arising from business interpretation of variables. It provided us with model better describing decision process. We have also experimented with variable ‘ExternalRiskEstimate’. This variable representing external credit scoring must be based on other variables from the dataset, and because of that many trained models were relying almost exclusively on this single variable, marginalising importance of other ones, and oversimplifying explanation. Such explanation wouldn’t be in any way meaningful to potential applicant. What’s more, ExternalRiskEstimate can be explained with other variables with mean absolute percentage error 5.5% FIGURE 9.1: XGBoost model ROC curve 9.3 Explanations 9.3.1 Model explanations Model explanation techniques were very useful in our work. As was mentioned in section Model, we experimented with variable ExternalRiskEstimate and effects this variable had on trained model. We trained two XGBoost models, one with ExternalRiskEstimate variable, and one without this variable. Then we used Permutation Variable Importance to estimate variable importance in each model. In first model, with ExternalRiskEstimate variable, we observed that this variable clearly dominates others, with weight almost 9 times greater than weight of the second most important variable. On the other hand, in the second model three most important variables had similar weights of importance. Importance of variables in models with and without ExternalRiskEstimate variable Model with ExternalRiskEstimate Model without ExternalRiskEstimate Weight Variable Weight Variable —— ———————————- —— ———————————- 0.0857 ExternalRiskEstimate 0.0250 NetFractionRevolvingBurden 0.0094 NetFractionRevolvingBurden 0.0168 PercentTradesNeverDelq 0.0047 PercentTradesNeverDelq 0.0130 MSinceMostRecentDelq 0.0044 MSinceMostRecentInqexcl7days 0.0076 AverageMInFile 0.0036 MSinceMostRecentDelq 0.0072 NumBank2NatlTradesWHighUtilization 0.0025 PercentTradesWBalance 0.0042 MaxDelq2PublicRecLast12M 0.0021 NumSatisfactoryTrades 0.0013 MSinceMostRecentInqexcl7days 0.0016 AverageMInFile 0.0007 NumRevolvingTradesWBalance 0.0014 NumTotalTrades 0.0004 NumInqLast6M 0.0013 NumBank2NatlTradesWHighUtilization 0.0003 NumTotalTrades Using this technique we can also discover which variables are most significant in our model, deepening our understanding of trained model. To better understand our model we also attempted to use Partial Dependency Plots. Unfortunately in our case these plots didn’t give us any more information. It confirmed that our model has correct monotonicity with respect to business interpretation of variables, but that was all. Finally, this information wasn’t in any way helpful since we used a XGBoost model which reinforced monotonicity of variables according to their’s business interpretation. On following graphs 9.2, 9.3 we can see PDP plots for variable AverageMInFile in two XGBoost models, one with monotonicity constraints, and other without constraints. As we can see both plots are quite similar. Plot 9.3 in some point is slightly decreasing, but in general we can say that is increasing, as it should be. FIGURE 9.2: PDP graph of variable AverageMInFile of XGBoost model with monotonicity constraints FIGURE 9.3: PDP graph of variable AverageMInFile of XGBoost model without monotonicity constraints 9.3.2 Explanation for clients As a main goal we have chosen valuable explanations for clients, because of two factors: in many countries, including Poland, only explainable models are allowed to be used for customer credit scoring. Furthermore it is vital to provide clear and understandable responses for clients doubts concerning their financial rating, since it may increase an overall level of satisfaction with customers service. 9.3.2.1 SHAP values: In order to ensure flexibility of the explanations system we have decided to use SHapley Additive exPlanations (SHAP). This method is model-agnostic, which means it provides explanations for various types of machine learning models. It increases a versatility of the technique that is an advantage for companies. Moreover SHAP is based on the game theory, where every observation from a dataset is another game. Therefore this technique is designed for local interpretation e.g. of every client’s score. Again, we have tested model including ExternalRiskEstimate feature and without them, comparing results. Eventually we decided to use model without ExternalRiskEstimate, because in many observations that variable has significant or even the greatest impact for an explanation. However ExternalRiskEstimate is synthetic, which means it is computed from other features and as such it is not providing any advice for customer, how they can increase a chance of getting a loan. Results of both models for one observation are shown below: With ExternalRiskEstimate without ExternalRiskEstimate During the work we divided dataset into 3 clusters, using K-means algorithm. It showed a certain interesting remark: observations from first cluster often contained a lot of special or missing values, which are labeled in dataset. Results of summary plot for those data are different from two others. We can observe that second and third cluster are similar, thus their explanations are consistent. Cluster 0: Cluster 1: Cluster 2: Clustering dataset helped us to understand better SHAP plots for several observations, which was the main goal of this task. Thanks to force plot every client is able to understand his credit scoring upon one chart. For the purpose of this chapter we created three people: John, Grace and Frankie. If John comes to his consultant he doesn’t receive any valuable information, because his record contains no usable data. One and only information for him is that he have to prepare more proofs of his positive credit situation. Jonh’s SHAP plot: In case of Grace and Frankie things are different. Grace’s situation is clear - she never had a delinquency and length of her credit history is quite long, which improves her situation. Unfortunately she still has a large amount of her loans to repay. Frankie is the opposite of Grace. Probably she never took care of her financial situation and only 6 of 10 her loans were repaid without delinquency. Her credit score is lower and the greatest positive impact has the fact, that for the last 6 months she did not try to get a loan. For both of them, SHAP explanation provides valuable information about reasons of the credit decision. Grace’s SHAP plot: Frankie’s SHAP plot: 9.3.2.2 Application for clients While working on this project we tried to use SHAP values to change the particular feature in the observation, what should increase or decrease probability of a positive credit decision. Results were surprisingly bad. In some cases changing the most important feature in a reasonable range did not affect the output. In others, even a small change disrupted the whole SHAP model. Moreover some features are connected, for example if a client wants to improve percent trades without delinquency, he can get a new loan but it changes another features, such as number of months since last inquiry. An exemplary result of Ceteris Paribus plot, which shows change’s range for one variable is shown below. 9.4 Summary and conclusion Our results show that explainable artificial intelligence could be helpful for banking industry and could provide a valuable explanation for clients, what is necessary in many countries, including Poland. Unfortunately there are some drawbacks of those techniques, what was shown in previous sections. Although SHAP values present current client’s situation, it is not possible to modify values of a certain feature causing a monotonical increase of probability of a positive credit decision. "],["story-compas.html", "Chapter 10 Story COMPAS: recidivism reloaded 10.1 Introduction 10.2 Data 10.3 Models 10.4 Explanations 10.5 Fairness 10.6 Summary and conclusions", " Chapter 10 Story COMPAS: recidivism reloaded Authors: Łukasz Grad (University of Warsaw), Katarzyna Koprowska (Warsaw University of Technology) Mentors: Michał Miktus (McKinsey &amp; Company) Take-away messages Based on limited publicly available data COMPAS scores can only be reconstructed approximately. Direct recidivism modelling provides better results than both raw COMPAS scores and models trained on COMPAS. Race is an influential factor when predicting recidivism. Removing bias from a model is a complex task. Our efforts to mitigate the racial bias resulted in a relatively fair model, but at the cost of decreased model performance, suggesting that some trade-offs are inevitable. 10.1 Introduction The study covers the problem of assessing the likelihood of a defendant becoming a recidivist. One of the best known solutions currently used on a daily basis is COMPAS, an acronym for Correctional Offender Management Profiling for Alternative Sanctions, created by a for-profit company Northpointe. COMPAS is a widely popular commercial algorithm used by judges and parole officers for scoring a criminal defendant’s likelihood of recidivism. It was designed to help judges identify potentially more dangerous individuals and award them with longer sentences. It is easy to notice that COMPAS results have fundamental consequences for the lives of many United States residents. However, the algorithm is, due to its proprietary nature, still a black-box for the wide audience – meaning that we cannot easily identify which factors did it consider when classifying an individual as a person with a high or low likelihood of reoffending. Consequently, many questions have arised about the fairness of the algorithm. In this study, we try to answer the following questions: Can we reconstruct COMPAS scores given our limited data about defendants? What are important factors contributing to the COMPAS score? Can we improve on the COMPAS by using a more complex model? Is our model fair or does it show racial bias? How can we remove racial bias and what is the impact of such operation on model accuracy? The rest of the article is organized as follows. Next subsection briefly discusses previous attempts at both analyzing COMPAS algorithm in the context of racial bias, as well as the COMPAS scores reconstruction. In section 2 we describe the data we used for modelling along with variable description. In section 3 we present the estimated models and detailed description of model fitting approach. Moreover, it contains results for direct recidivism modelling as well as attempts at COMPAS score reconstruction. In section 4 we show global and instance level explanations in order to assess the degree of racial bias present in our models. Section 5 contains quantitative fairness analysis augmented with an attempt to remove bias from our best-performing model. Lastly, we briefly mention potential next steps and finish with a summary of our results. 10.1.1 Previous work on COMPAS algorithm One of the first and most known investigators aiming to validate COMPAS results was ProPublica group Larson et al. (2016). They have provoked a vigorous discussion about the fairness of black-box models with their 2016 study, which attempted to reconstruct COMPAS methodology. They have collected criminal records from Broward County FL for several thousand people, as well as reports about their offenses in a two-year follow-up period. The overall accuracy of ProPublica’s reconstructed model was only 61%, but their main discovery was a racial bias in favour of defendants of Caucasian origins over those of African-American origins. According to the study, black defendants were particularly likely to be falsely flagged as future criminals almost twice as often as white ones, who were also more often mislabeled as low risk. The researchers believed that the aforementioned disparity cannot be explained by either defendant’s prior crimes, their type, gender or age. The ProPublica study was, however, heavily criticized for its flawed methodology. One of the critics was Northpointe, the creator of the COMPAS algorithm, who defended the accuracy of its test, because the results from ProPublica do not precisely reflect their model. After ProPublica’s publication, confusion and doubts whether COMPAS should still be relied on, began to appear among researchers, leading several of them to propose their own validations of the algorithm, based on data provided by ProPublica. One of the most reliable work seems to be the study “The age of secrecy and unfairness in recidivism prediction” by Rudin et al. (2018), which verified the analysis conducted by ProPublica, indicating cases where the results given by COMPAS may be non-intuitive and possible explanations. The authors believe that ProPublica has drawn conclusions from incorrect assumptions and lack of knowledge of all data. For instance, they assumed linearity in age (as stated in official COMPAS documentation from Northpointe described by Rudin et al.), which appeared to be untrue; they also did not have access to the answers from questionnaires given to defendants (also introduced by the Northpointe as predictors for their model), which can be highly correlated with race and, thus, shift the outcome. Disproving ProPublica’s study was not, however, the main objective of Rudin et al. They described what they believed was the real problem of COMPAS: its proprietary nature, which, along with over a hundred of (manually-entered) variables collected from questionnaires not publicly accessible, does not allow to identify data entry errors, data integration errors, missing data and other types of inaccuracies. The researchers even identified some individuals with a rich criminal history and low probability of recidivism given by model, highly suggesting that their scores were based on flawed data. The main conclusion of this analysis was to replace black-box machine learning models by interpretable models, which, as Rudin et al. suggested, can be equally accurate for predicting recidivism. 10.2 Data Data we used was mainly derived from the “The age of unfairness” study dataset combined with several factors extracted from the raw Broward County FL database used by ProPublica for their analysis. We gathered information about \\(5727\\) subjects from Broward County FL, whose likelihood of recidivism and violent recidivism we were trying to predict. We have used \\(29\\) variables in total: personal (\\(6\\)) such as current age, age at first offence, sex, race, marital status, custody status criminal involvement (\\(20\\)) consisting of number and types of previous charges and arrests, as well as those leading to COMPAS screening history of non-compliance (\\(3\\)) concerning behaviour while on probation. In addition, the data also contained COMPAS scores for both recidivism and violent recidivism, together with ground truth about future offenses and violent offenses made by a person. Description of variables in the dataset. Variable Description current_age current age of offender age_first_offence age of offender at first offense charge_count number of charges against offender jail30_count number of times in jail at least 30 days long prison_sent_count number of prison sentences prob_count number of times on probation race race of offender gender gender of offender offense30_count number of offenses within 30 days before screening fel_count number of felonies misdem_count number of misdemeanours charge_viol_count number of violent charges against offender juvfel_count number of juvenile felonies prop_viol_count number of felony property violent arrests murder_arrest number of murder arrests felassault_arrest number of felony assault arrests misdem_arrest number of misdemeanours assault arrests famviol_arrest number of family violence arrests sex_arrest number of sex crime arrests weapon_arrest number of weapons arrests onprob_count number of offenses on probation onprob_current current offence on probation prob_revoke number of probation violation arrest_count total number of arrests prison30_count number of times in prison at least 30 days long scale_set scale set for COMPAS screening marital_status marital status custody_status custody status, e.g. pretrail defendant 10.3 Models We focused on both direct and indirect modelling of recidivism. As in original work by Northpointe, we distinguish between recidivism and violent recidivism, giving rise to a total of \\(4\\) problems to tackle. Our first approach focused on direct modelling of recidivism and violent recidivism in a two-year follow-up period after screening. Therefore, we modelled both problems as binary classification tasks. In the second approach we focused on the prediction of raw COMPAS scores, again concerning both recidivism and violent recidivism. We model it as a regression task with mean squared error as a loss function. In all experiments we split our data set randomly into train set with \\(4588\\) instances and separate test set with \\(1139\\). All results presented below are calculated on the test set only in order to provide fair performance analysis. In order to find well-performing models for each task, we have tried three different approaches: Lasso Regression Random Forest Extreme Gradient Boosting (XGBoost) We focused on tuning the XGBoost model, as it provides state-of-the-art results on many tabular datasets, and wanted to compare it with a white box logistic regression model along with out-of-the-box Random Forest. Comparison with a linear model can give us insights on whether the relationships between recidivism and given predictors is highly nonlinear or not. On the other hand, comparison with Random Forest model will reveal how important careful parameter tuning and control for overfitting are. In next subsections, we briefly describe the fitting process of all models. 10.3.0.1 XGBoost Since the volume of our datasets is not substantial, we performed XGBoost tuning with exhaustive grid search method in a coarse-to-fine manner. With a coarse parameter search we assessed the relative importance of each parameter and narrowed down its potential range of values. Next, with a much finer search we obtained out final sets of parameters. As a metric during parameter tuning we used AUC for recidivism classification and MSE for COMPAS score prediction. Both metrics were calculated on the full training set with out-of-fold scores within a 5-fold CV scheme. In our analysis, we used xgboost package in R. Below we show top performing models for both COMPAS score regression and recidivism binary classification. Selected final parameter values for recidivism and violent recidivism XGBoost models Model Tree Number Max Depth Eta Colsample Subsample Min Child Weight Alpha Lambda XGB 12 3 0.3 1 0.8 3 1 1 XGB Violent 19 3 0.3 0.8 0.8 10 1 0 We can see that in case of recidivism and violent recidivism classification XGBoost was prone to the overfitting as the best models had very limited tree counts. Selected final parameter sets for COMPAS score and violent COMPAS score XGBoost models Model Tree Number Max Depth Eta Colsample Subsample Min Child Weight Alpha Lambda XGB 62 3 0.3 1 0.8 10 3 0 XGB Violent 57 3 0.3 0.8 0.8 1 3 0 In case of COMPAS score regression we see a substantial increase in tree count, but still the chosen models have limited max tree depth to control for overfitting. 10.3.0.2 LASSO regression Since we had strong suspicions about collinearity between predictors, we used Regression with L1 penalty (Lasso) as our linear model of choice. In case of recidivism classification we fit a Logistic Lasso model - a generalized linear model with binomial distribution. In case of COMPAS regression we utilize a standard Lasso with linear activation function (gaussian distribution). The penalty term \\(\\lambda\\), similarily to XGBoost, was tuned with 5-fold CV on the training set. We utilized a well known glmnet package in R to efficiently find optimal penalty terms using the Lasso path. Below we present the Lasso path for recidivism model (on the left) and COMPAS scores (on the right). We can notice that the selected model for recidivism prediction is simpler and that even simple linear models with more predictors lead to overfitting. On the other hand, we observe little to no overfitting for COMPAS regression. This is in line with parameter tuning for XGBoost models, where models selected for COMPAS score regression were more complex. Left: Lasso path for recidivism model. At the top we see the number of non-zero weights. We can see the optimal penalty term chosen to be close to \\(e^{-5}\\). Best model had 17 non-zero weights, although models with less than 10 chosen predictors also perform well. Right: Lasso path for COMPAS regression. Optimal model selected with 26 predictors, but simpler models with less than 18 features perform similarily 10.3.0.3 Random Forest As for the Random Forest model, we relied on the default implementation in RandomForest R package, without any fine tuning. We set the number of trees to \\(50\\) observing that the chosen XGBoost models were also sparse in tree count. 10.3.1 Results - COMPAS Regression Below we present COMPAS regression results. In both cases of recidivism and violent recidivism tuned XGBoost models achieved highest Coefficient of determination (R-Squared). Random Forest models performed only a little worse, followed by Lasso models. One may have expected higher results than \\(0.643\\) and \\(0.711\\) of the variance explained, for recidivism and violent recidivism respectively. Information available about the underlying COMPAS models suggest that they are most likely quite simple, statistical models. However, as disclosed by Nortpointe, their model has a substantially more information about the defender, e.g. from on-site questionnaires. Summary of COMPAS regression results Model R-Squared MSE RMSE MAD XGB 0.643 0.259 0.509 0.329 Lasso 0.573 0.310 0.557 0.384 RF 0.625 0.272 0.522 0.336 XGB Violent 0.711 0.228 0.478 0.275 Lasso Violent 0.644 0.281 0.531 0.336 RF Violent 0.693 0.242 0.492 0.296 Looking more closely at the histograms of residuals, we observe a much higher amount of instances with under-valued than over-valued predictions. This observation is consistent for both recidivism and violent recidivism COMPAS scores, and for all our models. Left: Histogram of residuals for COMPAS recidivism regression. Right: Histogram of residuals for violent COMPAS recidivism regression. 10.3.2 Results - Recidivism Classification Below we present recidivism classification results. We decidecied to compare our models using a receiver operating characteristic or ROC curve in short, along with a couple other diagnostic metrics. Summary of recidivism classification results Model AUC Accuracy Precision Recall XGB 0.721 0.66 0.51 0.71 Lasso 0.707 0.65 0.50 0.68 RF 0.671 0.63 0.48 0.64 XGB Violent 0.718 0.63 0.26 0.68 Lasso Violent 0.697 0.65 0.27 0.66 RF Violent 0.674 0.63 0.24 0.63 As it turned out, the most accurate algorithm was XGBoost with AUC of \\(0.721\\) for both recidivism and violent recidivism prediction. Left: ROC curve for recidivism. Right: ROC curve for violent recidivism. In both cases, ROC AUC was much higher than ProPublica score and also significantly higher than the ROC AUC produced by raw COMPAS scores. Surprisingly, our models trained on the COMPAS scores (COMPAS model in the table below) achieved higher AUC on the test set than the raw COMPAS scores. This may suggest, that the additional variables extracted from e.g. questionnaires, may in fact harm the COMPAS predictions. Comparison of predictive performance of our XGBoost classification models and raw COMPAS scores Our model raw COMPAS score COMPAS model ROC AUC 0.721 0.692 0.708 ROC AUC Violent 0.718 0.673 0.688 In the following analyses we will focus only on the models predicting recidivism. 10.4 Explanations In order to evaluate results, as well as test for potential biases, we examined both COMPAS scores and our model for recidivism prediction using several explanation techniques. Before we begin with explanations, however, several terms should be clarified. Jail or prison? For many, especially non-English natives, jail and prison are interchangeable terms. It is, however, incorrect: jails are for people awaiting trial and those serving short (a year or less) sentences, while prisons are for long term (more than a year) convicts. Misdeameanor or felony? A felony is a more serious crime than a misdemeanor. There are more levels within these groups and each level differs in terms of consequences, but the rule of thumb is the following: felonies involve long prison sentences, large fines, or permanent loss of freedoms, while misdemeanors usually result in smaller fines and short jail time. 10.4.1 Model specific In order to identify the effect of features on prediction we used Permutation Variable Importance. Permutation Variable Importance – our XGBoost model for predicting recidivism Not surprisingly, the most relevant variable for predicting recidivism turned out to be number of previous arrests. Another factor that is greatly affecting prediction is age and age at first offense, followed by the number of previous misdemeanors. In the picture below we can see a little more detailed description of most important variables acquired with SHAP. Positive SHAP value indicates larger probability of recidivism, negative – the opposite. SHAP summary plot ordered by variable importance – our XGBoost model for predicting recidivism Several interesting conclusions can be drawn. Quite intuitively, the higher the number of previous arrests, the more likely is the defendant to reoffend. Features standing for current age and age at first offence indicate that younger people tend to be much more likely to commit crime again, especially if their criminal history has started early. Higher number of previous misdemeanors affects “positively” the prediction, on the contrary to the features related to felonies (number of felony assault arrests and number of felonies), suggesting that people commiting lesser crimes are more likely to do it again, unlike those with more severe ones. Unfortunately, sensitive information such as race and sex is very high on the list suggesting bias in favour of women and against African-Americans. A little more digging reveals another interesting information – an interaction between race and two of the three most important variables shows the opposite direction of feature’s influence on prediction for black vs non-black defendants. Left: SHAP interactions for African-American race and age of first offense variables. Right: SHAP interactions for African-American race and current age variables. Based on our XGBoost model for predicting recidivism The figure above suggests that younger age (both at first offence and currently) generally increases the probability of recidivism among African-Americans, while lowering it for people of Caucasian origins and vice versa. This insight is particularly disturbing considering the official documentation of COMPAS algorithm stating that COMPAS scores are linearly dependent on these two variables (scaled by combination of other factors). It can also mean something entirely different –particular characteristics of non-black defendants in Broward County, Florida are the reason why some of the previous analyses found COMPAS biased. It is impossible to prove any of the above with the information we currently possess, thus we leave these hypotheses for further investigation. Average prediction for race variable grouped by gender based on XGBoost model for recidivism prediction Our model predicted African-Americans to be, on average, more likely to re-offend than individuals of any other race. In order to identify, whether it is not caused by other factors correlated with race, we used Partial Dependence Plots and Accumulated Local Effects for binary variables associated with races. PDP for two race variables for regular model and model fitted on data without sex ALE for two race variables for regular model and model fitted on data without sex 10.4.2 Instance specific To further verify our claims we have performed an instance level analysis using Ceteris Paribus on observations with the most accurate predictions. Left: Ceteris Paribus plots for race and sex variables for a selected true positive instance. Right: Ceteris Paribus plots for race and sex variables for a selected true negative instance. Based on our XGBoost model for predicting recidivism Our model has been fitted on real world data full of systematic bias, making it unfair towards African-Americans, as Ceteris Paribus freezes all the other factors. Another question arises whether we observe a gender bias, because both models - ours and COMPAS - seem to drastically change their predictions for some of the male subjects when controlling for other factors. From the perspective of a data scientist it might seem that bias is not such an important issue: if data shows that certain individuals are more likely to be classified as reoffending, then our models should include that information. We do not know, however, how existing racial bias influenced the actual data: what if white people were simply less often arrested, had fewer charges and more let go with a warning? This scenario is not very difficult to imagine. Since COMPAS is widely used by judges and parole officers, we need to include their viewpoint: they need a reliable, unbiased tool to help them determine the likelihood of individuals reoffending. It is therefore our social duty to attempt at creating such a tool and do our best to make sure no existing biases are further propagated. 10.4.3 Models without protected attributes One way of dealing with the sensitive information is to remove it from a dataset. In order to examine whether this practice is of any use, we analyzed three versions of models without sensitive information: without race, without sex, and without both race and sex. Results in terms of mean cross-validational ROC AUC are very similar, which might suggest that we not much information is lost by dropping these sensitive variables. ALL NO RACE NO SEX NO RACE NO SEX ROC AUC 0.7162 0.7154 0.715 0.714 How is this possible since race was so high in the importance ranking? In the following analysis we will try to identify potential spots where this information could be hidden. 10.4.3.1 Model without race An XGBoost model with the same hyperparameters has been fitted to the data with race variables removed. SHAP summary plot for model predicting recidivism without race variables The most influencial attributes remain the same, but with no race present other variables like number of prison sentences (prison_sent_count) become much more important than before (6th position vs 11th in previous model), suggesting an association between them and race. Similar conclusion comes from looking at the Partial Dependence Plot (left) and Accumulated Local Effect of this feature: its impact skyrockets for model without race. PDP (left) and ALE (right) plots for number of prison sentences 10.4.3.2 Model without sex Another XGBoost model with the same hyperparameters has been fitted to the data without sex variables. SHAP summary plot for model predicting recidivism without sex variables One of the variables potentially “hiding” the impact of sex is marital status, but the effect is much harder to notice since the dataset is very imbalanced with the majority of male defendants. PDP (left) and ALE (right) plots for marital status: Significant Other 10.4.3.3 Model without both race and sex In this model, apart from the variables described above, a feature that suddenly got important is the number of times in prison at least 30 days (prison30_count). In the PDP (left) and ALE (right) plots below we can see another strange behaviour: models without sensitive information have strikingly different predictions for defendants with high values of this feature. 10.4.3.4 Summary Removing each of the sensitive variables from the training dataset altered a little the model structure – new features climbed up the feature importance ranking. More detailed analysis revealed potential spots in which sensitive information could have “hidden”\", as models drastically changed behaviour after dataset modifications. Although some of them can be harmless or even valuable adjustments, model’s creator should always have in mind potential consequences of downright removal of the attributes. In the following section we will try a different approach to bias mitigation, which does not include discarding any variables. 10.5 Fairness 10.5.1 Overview The topic of fairness in machine learning has been widely studied and has progressed intensively in recent years. One of the tools that emerged was AIF360, described in Bellamy et al. (2018) – an IBM package that assembles together the most important fairness metrics, explanation, and bias mitigating techniques, that will be used in the following analysis. 10.5.2 Models In order to mitigate bias in our model, we used an algorithm called Prejudice Remover, described in Kamishima et al. (2012). According to the authors, “prejudice means a statistical dependence between a sensitive variable, S, and the target variable, Y, or a non-sensitive variable, X.” We analyzed the results using the following fairness metrics: Average Odds Difference \\[ \\frac{(FPR_{unpriv}-FPR_{priv})+(TPR_{unpriv}-TPR_{priv})}{2}\\] Statistical Parity Difference, which stands for probability of favorable outcome for unprivileged instances subtracted by probability of favorable outcome for privileged instances Equal Opportunity Difference, also called true positive rate difference: true positive rate on unprivileged instances minus true positive rate on privileged instances) Theil Index which is a special case of generalized entropy index with alpha = 1 1-min(DI, 1/DI) where DI stands for Disparate Impact – probability of favorable outcome for unprivileged instances divided by probability of favorable outcome for privileged instances. All metrics definitions are from AIF360 documentation. For all of them, the value close to zero indicates a fair model. Model performance was measured with balanced accuracy defined as the average of recall (ratio of true positives / (true positives + false negatives) obtained on each class. Most of the metrics were significantly lowered by the Prejudice Remover. Model best balanced acc AOD SPD EOD TI 1-min(DI, 1/DI) before PR 0.696725 0.245144 0.273759 0.276377 0.159040 0.4581 after PR 0.630832 0.022063 0.051394 0.013318 0.223687 0.1240 What does it mean for the defendants? The following analysis of mismatch was conducted using thresholds with the best balanced accuracy for both of the models on the test set with 1146 randomly chosen observations. PR – model after using Prejudice Remover, XGB – regular XGBoost model ALL PR ALL XGB BLACK PR BLACK XGB WHITE PR WHITE XGB Correctly classified as reoffending 30 293 9 198 19 73 Correctly classified as innocent 720 499 343 195 281 226 Incorrectly classified as reoffending 17 238 3 151 10 65 Incorrectly classified as innocent 379 116 229 40 97 43 As a result of prejudice removal we observe a large shift in classification: number of black people incorrectly classified as reoffending dropped from 151 to 3 (drop from 65 to 10 for white people), suggesting that the algorithm did in fact remove the negative bias towards them. Unfortunately, it is largely caused by PR’s aversion to classify anyone as risky of recidivism, resulting in an increase of those misclassified as innocent from 116 (for regular model) to 379. Is saving potentially innocent people from being wrongfully misjudged more important than defending their community from possible future reoffences of those mistakenly classified as unlikely to reoffend? An answer to this question should be based on a careful evaluation of potential risks of propagating biases and prejudice and gains coming from model accurately predicting likelihood of recidivism, contributing to the safer society, it is, therefore, much beyond the scope of this analysis. 10.6 Summary and conclusions In this paper we focused on COMPAS scores modelling and developing our own solutions for predicting recidivism. We explored model explanations in search of potential racial and gender biases present in our model along with potential ways to guarantee model fairness. Based on results, we conclude that the publicly available data is not rich enough to properly reconstruct COMPAS scores. However, our experiments show that our recidivism classification models yield better results not only than our models trained on COMPAS, but also the raw COMPAS scores, according to ROC AUC calculated on test set. We also showed that the best-performing XGBoost models do indeed show racial bias, but using a Prejudice Remover approach we were able to significantly increase model fairness at the cost of reduced accuracy. 10.6.1 Next steps Potential next steps involve further research focused on identifying and mitigating biases – AIF360 offers several debiasing algorithms that can be applied to this problem. It would also be very beneficial to acquire new, preferably larger datasets and use them to perform all of the analyses conducted previously on data from Broward County. References "],["acknowledgements.html", "Acknowledgements", " Acknowledgements This project is inspired by a fantastic book Limitations of Interpretable Machine Learning Methods created at the Department of Statistics, LMU Munich. We used the LIML project as cornerstone for this reopsitory. This book would not have been written without openness to cooperation of three Warsaw universities: Warsaw University of Technology, University of Warsaw and SGH Warsaw School of Economics. Students from these three universities collaborated (remotely due to the Covid-19 epidemic) on their chapters. My biggest thanks go to two people from McKinsey, who have been supporting my classes on UoW and WUT for years, inspiring it with ideas for new challenges, ideas and solutions. Mateusz Zawisza and Amadeusz Andrzejewski, thank you very much! Przemysław Biecek, June 2020, Warsaw "],["references-1.html", "References", " References Akshay Kumar, Rishabh Kumar. 2018. “Uplift Modeling : Predicting Incremental Gains.” 2018. http://cs229.stanford.edu/proj2018/report/296.pdf. Bates, Douglas, Martin Maechler, and Ben Bolker. 2020. Linear Mixed-Effects Models Using ’Eigen’ and S4. https://cran.r-project.org/web/packages/lme4/index.html. Bellamy, Rachel K. E., Kuntal Dey, Michael Hind, Samuel C. Hoffman, Stephanie Houde, Kalapriya Kannan, Pranay Lohia, et al. 2018. “AI Fairness 360: An Extensible Toolkit for Detecting, Understanding, and Mitigating Unwanted Algorithmic Bias.” http://arxiv.org/abs/1810.01943. Biecek, Przemyslaw, and Tomasz Burzykowski. 2019. Explanatory Model Analysis. https://pbiecek.github.io/ema/. Bischl, Bernd, Michel Lang, Lars Kotthoff, Julia Schiffner, Jakob Richter, Erich Studerus, Giuseppe Casalicchio, and Zachary M. Jones. 2016. “mlr: Machine Learning in R.” Journal of Machine Learning Research 17 (170): 1–5. http://jmlr.org/papers/v17/15-066.html. Chen, Tianqi, and Carlos Guestrin. 2016. “XGBoost: A Scalable Tree Boosting System.” CoRR abs/1603.02754. http://arxiv.org/abs/1603.02754. Conway, Jennifer. 2018. “Artificial Intelligence and Machine Learning : Current Applications in Real Estate.” PhD thesis. https://dspace.mit.edu/bitstream/handle/1721.1/120609/1088413444-MIT.pdf. Din, Allan, Martin Hoesli, and Andre Bender. 2001. “Environmental Variables and Real Estate Prices.” Urban Studies 38: 1989–2000. Esmukov, Kostya. 2020. “Python Geocoding Toolbox.” https://geopy.readthedocs.io/en/latest/#. Friedman, Jerome. 2000. “Greedy Function Approximation: A Gradient Boosting Machine.” The Annals of Statistics 29 (November). https://doi.org/10.1214/aos/1013203451. Gosiewska, Alicja, and Przemysław Biecek. 2019. “auditor: an R Package for Model-Agnostic Visual Validation and Diagnostics.” The R Journal 11 (2): 85–98. https://doi.org/10.32614/RJ-2019-036. Greenwell, B., B. &amp; Boehmke. 2019. Gbm: Generalized Boosted Regression Models. https://cran.r-project.org/web/packages/gbm/index.html. Guolin Ke, Thomas Finley, Qi Meng. 2017. “LightGBM: A Highly Efficient Gradient Boosting Decision Tree.” https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf. Heyman, Axel, and Dag Sommervoll. 2019. “House Prices and Relative Location.” Cities 95 (September): 102373. https://doi.org/10.1016/j.cities.2019.06.004. Hillstrom, Kevin. 2008. “The Minethatdata E-Mail Analytics and Data Mining Challenge Dataset.” 2008. https://blog.minethatdata.com/2008/03/minethatdata-e-mail-analytics-and-data.html. Jaroszewicz, S., and P. Rzepakowski. 2014. “Uplift Modeling with Survival Data.” In ACM Sigkdd Workshop on Health Informatics (Hi-Kdd’14). New York City, USA. Jaskowski, Maciej, and Szymon Jaroszewicz. 2012. “Uplift Modeling for Clinical Trial Data.” In. Kamishima, Toshihiro, Shotaro Akaho, Hideki Asoh, and Jun Sakuma. 2012. “Fairness-Aware Classifier with Prejudice Remover Regularizer.” In Machine Learning and Knowledge Discovery in Databases, edited by Peter A. Flach, Tijl De Bie, and Nello Cristianini, 35–50. Berlin, Heidelberg: Springer Berlin Heidelberg. Keras. 2020. Keras Website. https://keras.io/. Kozak, Anna, and Przemyslaw Biecek. 2020. Local Variable Importance via Oscillations of Ceteris Paribus Profiles. https://cran.r-project.org/web/packages/vivo/index.html. Krzysztof, Rudaś, and Szymon Jaroszewicz. 2018. “Linear Regression for Uplift Modeling.” Data Min. Knowl. Discov. 32 (5): 1275–1305. Kuchumov, Artem. 2018. “Pyuplift Package - Documentation.” 2018. https://pyuplift.readthedocs.io/en/latest/index.html. Larson, Jeff, Surya Mattu, Lauren Kirchner, and Julia Angwin. 2016. “How We Analyzed the Compas Recidivism Algorithm.” Edited by ProPublica.org. hhttps://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm. Law, Stephen. 2017. “Defining Street-Based Local Area and Measuring Its Effect on House Price Using a Hedonic Price Approach: The Case Study of Metropolitan London.” Cities 60 (February): 166–79. https://doi.org/10.1016/j.cities.2016.08.008. Lee, Josh Xin Jie. 2018. “Simple Machine Learning Techniques to Improve Your Marketing Strategy: Demystifying Uplift Models.” 2018. https://medium.com/datadriveninvestor/simple-machine-learning-techniques-to-improve-your-marketing-strategy-demystifying-uplift-models-dc4fb3f927a2. Lundberg, Scott. 2018. “Interpretable Machine Learning with Xgboost.” 2018. https://towardsdatascience.com/interpretable-machine-learning-with-xgboost-9ec80d148d27. Lundberg, Scott, and Su-In Lee. 2017. “A Unified Approach to Interpreting Model Predictions.” In. Lundberg, Scott M., Gabriel G. Erion, Hugh Chen, Alex DeGrave, Jordan M. Prutkin, Bala Nair, Ronit Katz, Jonathan Himmelfarb, Nisha Bansal, and Su-In Lee. 2019. “Explainable AI for Trees: From Local Explanations to Global Understanding.” CoRR abs/1905.04610. http://arxiv.org/abs/1905.04610. Mostipak, Jesse. 2020. “Hotel Booking Demand.” https://www.kaggle.com/jessemostipak/hotel-booking-demand. Park, Byeonghwa, and Jae Bae. 2015. “Using machine learning algorithms for housing price prediction: The case of Fairfax County, Virginia housing data.” Expert Systems with Applications 42 (April). https://doi.org/10.1016/j.eswa.2014.11.040. R Core Team. 2018. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/. Rudin, Cynthia, Caroline Wang, and Beau Coker. 2018. “The Age of Secrecy and Unfairness in Recidivism Prediction.” http://arxiv.org/abs/1811.00731. Rzepakowski, Piotr, and Szymon Jaroszewicz. 2012. “Decision Trees for Uplift Modeling with Single and Multiple Treatments.” Knowledge and Information Systems - KAIS 32 (August). https://doi.org/10.1007/s10115-011-0434-0. scikit-learn. 2019a. GradientBoostingRegressor Documentation. https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html. ———. 2019b. GridSearchCV Documentation. https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html. ———. 2019c. OneHotEncoder Documentation. https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html. ———. 2019d. StandardScaler Documentation. https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html. ———. 2020. Scikit-Learn Website. https://scikit-learn.org/stable/. Selim, H. 2009. “Determinants of House Prices in Turkey: Hedonic Regression Versus Artificial Neural Network.” Expert Systems with Applications 36: 2843–52. Sołtys, Michał, Szymon Jaroszewicz, and Piotr Rzepakowski. 2015. “Ensemble Methods for Uplift Modeling.” Data Mining and Knowledge Discovery 29 (November). https://doi.org/10.1007/s10618-014-0383-9. Therneau, B., T. &amp; Atkinson. 2019. Rpart: Recursive Partitioning and Regression Trees. https://cran.r-project.org/web/packages/rpart/index.html. Verbeke, W., and C. Bravo. 2017. Profit Driven Business Analytics: A Practitioner’s Guide to Transforming Big Data into Added Value. Wiley and Sas Business Series. Wiley. https://books.google.pl/books?id=NCA3DwAAQBAJ. Wright, Marvin N., and Andreas Ziegler. 2015. “Ranger: A Fast Implementation of Random Forests for High Dimensional Data in C++ and R.” https://doi.org/10.18637/jss.v077.i01. Yi, Robert, and Will Frost. 2018a. “Pylift: A Fast Python Package for Uplift Modeling.” 2018. https://tech.wayfair.com/data-science/2018/10/pylift-a-fast-python-package-for-uplift-modeling/. ———. 2018b. “Pylift Package - Documentation.” 2018. https://pylift.readthedocs.io/en/latest/. Zhao, Zhenyu, and Totte Harinen. 2019. “Uplift Modeling for Multiple Treatments with Cost Optimization.” http://arxiv.org/abs/1908.05372. "]]
